{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f91338",
   "metadata": {},
   "source": [
    "# EDA ‚Äî Proyecto Asistente Coreogr√°fico\n",
    "Celdas extra√≠das autom√°ticamente del notebook original."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e501946",
   "metadata": {},
   "source": [
    "\n",
    "## üîß 0. Configuraci√≥n para Colab (rutas, utilidades)\n",
    "Ejecuta estas celdas **tal cual** en Google Colab. Ajusta las rutas solo si tus archivos est√°n en otra carpeta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83735116",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Si est√°s en Colab, descomenta estas dos l√≠neas para montar Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "import os, glob, json, math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "\n",
    "def safe_read_csv(path, **kwargs):\n",
    "    try:\n",
    "        return pd.read_csv(path, **kwargs)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è No se pudo leer {path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c7088",
   "metadata": {},
   "source": [
    "\n",
    "## üìÇ 1. Rutas habituales del proyecto\n",
    "Se buscar√°n **features** en `asistente_coreografico` dentro de tu Google Drive. Cambia `CANDIDATES` si es necesario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e1a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CANDIDATES = [\n",
    "    \"/content/drive/MyDrive/asistente_coreografico/artifacts/features_coreograficos.csv\",\n",
    "    \"/content/drive/MyDrive/asistente_coreografico/data/features_coreograficos.csv\",\n",
    "    \"/content/drive/MyDrive/asistente_coreografico/data/features/*.csv\",\n",
    "    \"/content/drive/MyDrive/asistente_coreografico/artifacts/*.parquet\",\n",
    "    \"/content/drive/MyDrive/asistente_coreografico/artifacts/features/*.parquet\",\n",
    "]\n",
    "\n",
    "csv_paths = []\n",
    "for pat in CANDIDATES:\n",
    "    csv_paths.extend(glob.glob(pat))\n",
    "\n",
    "print(\"Posibles archivos encontrados:\", len(csv_paths))\n",
    "for p in csv_paths[:10]:\n",
    "    print(\" -\", p)\n",
    "\n",
    "FEATURES_PATH = csv_paths[0] if csv_paths else None\n",
    "FEATURES_PATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0907223",
   "metadata": {},
   "source": [
    "\n",
    "## üì• 2. Carga de datos de features\n",
    "Detecta de forma autom√°tica si el archivo es `.csv` o `.parquet`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ce991",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if FEATURES_PATH is None:\n",
    "    raise FileNotFoundError(\"No se encontraron archivos de features. Ajusta CANDIDATES en la celda anterior.\")\n",
    "\n",
    "if FEATURES_PATH.endswith(\".csv\"):\n",
    "    df = safe_read_csv(FEATURES_PATH)\n",
    "else:\n",
    "    try:\n",
    "        df = pd.read_parquet(FEATURES_PATH)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"No se pudo leer {FEATURES_PATH}: {e}\")\n",
    "\n",
    "print(\"Ruta:\", FEATURES_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a1a449",
   "metadata": {},
   "source": [
    "\n",
    "## üß≠ 3. Vista general r√°pida\n",
    "Tipos, `describe` y valores perdidos/duplicados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed537b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(df.dtypes.to_frame(\"dtype\").T)\n",
    "display(df.describe(include=[np.number]))\n",
    "display(df.describe(include=[object]))\n",
    "\n",
    "nans = df.isna().sum().sort_values(ascending=False)\n",
    "display(nans.to_frame(\"n_nans\").T)\n",
    "print(\"Duplicados exactos:\", df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92392bed",
   "metadata": {},
   "source": [
    "\n",
    "## üìä 4. Balance de clases (si existe etiqueta)\n",
    "Busca columnas t√≠picas de etiqueta: `label`, `etiqueta`, `clase`, `y`, `target`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d88fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_candidates = [c for c in df.columns if c.lower() in (\"label\",\"etiqueta\",\"clase\",\"y\",\"target\")]\n",
    "if label_candidates:\n",
    "    ycol = label_candidates[0]\n",
    "    print(\"Usando etiqueta:\", ycol)\n",
    "    display(df[ycol].value_counts(dropna=False).to_frame(\"conteo\"))\n",
    "else:\n",
    "    print(\"No se detect√≥ columna de etiqueta com√∫n. Ajusta manualmente si procede.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf9a644",
   "metadata": {},
   "source": [
    "\n",
    "## üîó 5. Correlaci√≥n y primeras relaciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1069ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "if len(numeric_cols) >= 2:\n",
    "    corr = df[numeric_cols].corr(numeric_only=True)\n",
    "    display(corr.iloc[:12,:12])\n",
    "else:\n",
    "    print(\"No hay suficientes columnas num√©ricas para correlaci√≥n.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddfd651",
   "metadata": {},
   "source": [
    "1. Problema / Motivaci√≥n\n",
    "\n",
    "En la creaci√≥n coreogr√°fica, los core√≥grafos trabajan con m√∫ltiples variables al mismo tiempo:\n",
    "- calidad de movimiento,\n",
    "- ocupaci√≥n del espacio,\n",
    "- din√°mica r√≠tmica,\n",
    "- coordinaci√≥n grupal,\n",
    "- est√©tica esc√©nica.\n",
    "Actualmente, no existe una herramienta inteligente que les d√© retroalimentaci√≥n objetiva en tiempo real o a partir de un v√≠deo grabado.\n",
    "\n",
    "El problema:\n",
    "- El proceso creativo depende √∫nicamente de la percepci√≥n subjetiva del core√≥grafo y carece de m√©tricas autom√°ticas o sugerencias asistidas por IA.\n",
    "\n",
    "Objetivo:\n",
    "- crear un asistente coreogr√°fico basado en visi√≥n por computador y machine learning que analice v√≠deos (subidos o en directo por c√°mara) y proporcione sugerencias de mejora en t√©rminos de est√©tica, t√©cnica y composici√≥n espacial.\n",
    "\n",
    "2. Obtenci√≥n de Datos\n",
    "- Fuentes de datos abiertas y espec√≠ficas:\n",
    "- Datasets de movimiento humano:\n",
    "- AIST++ (Google Research): dataset de danza contempor√°nea y urbana con m√∫sica sincronizada.\n",
    "- Pose Estimation Pretrained Datasets:\n",
    "- COCO, MPII (pose humana general).\n",
    "- Videos propios / capturados:\n",
    "- Posibilidad de grabar muestras de ensayos o fragmentos de repertorio cl√°sico y contempor√°neo.\n",
    "- Herramientas para anotaci√≥n:\n",
    "- OpenPose, MediaPipe para generar puntos clave (skeletons).\n",
    "- Enriquecer con metadatos: tiempo, nivel de energ√≠a, calidad espacial.\n",
    "\n",
    "3. Procesamiento y Limpieza de Datos\n",
    "\n",
    "- Conversi√≥n de v√≠deos a frames.\n",
    "- Extracci√≥n de poses humanas (skeletons 2D o 3D con OpenPose/MediaPipe).\n",
    "- Normalizaci√≥n de las secuencias (longitud, fps).\n",
    "- Anotaci√≥n de variables relevantes:\n",
    "  - amplitud del movimiento,\n",
    "  - simetr√≠a,\n",
    "  - alineaci√≥n corporal,\n",
    "  - sincronizaci√≥n grupal,\n",
    "  - desplazamiento espacial.\n",
    "\n",
    "4. An√°lisis Exploratorio (EDA)\n",
    "- Visualizaci√≥n de trayectorias de movimiento (plots de keypoints).\n",
    "- Distribuci√≥n de amplitud y velocidad en diferentes estilos.\n",
    "- Comparaci√≥n entre int√©rpretes y patrones.\n",
    "- Extracci√≥n de m√©tricas:\n",
    "  - rango de movimiento,\n",
    "  - fluidez (velocidad y aceleraci√≥n),\n",
    "  - nivel espacial (alto/medio/bajo),\n",
    "  - balance entre simetr√≠a/asimetr√≠a.\n",
    "\n",
    "5. Feature Engineering\n",
    "- Dise√±ar features coreogr√°ficas a partir de las poses:\n",
    "- T√©cnicos: alineaci√≥n postural, equilibrio, extensiones.\n",
    "- Espaciales: uso del espacio, direcciones, niveles.\n",
    "- R√≠tmicos: tempo, sincronizaci√≥n con m√∫sica (opcional).\n",
    "- Est√©ticos: fluidez, originalidad de trayectorias.\n",
    "- Los features ser√°n el input del modelo de ML.\n",
    "\n",
    "6. Modelado (Machine Learning / Deep Learning)\n",
    "- Modelos candidatos:\n",
    "  - Clasificaci√≥n / recomendaci√≥n:\n",
    "    Red neuronal recurrente (LSTM/GRU) para secuencias de poses ‚Üí sugiere patrones alternativos.\n",
    "    SVM o Random Forest para evaluar calidad t√©cnica.\n",
    "  - An√°lisis en tiempo real:\n",
    "  - Pose estimacion + m√©tricas evaluadas frame a frame.\n",
    "- Sistema de sugerencias:\n",
    "  - Basado en similitud con patrones de repertorio (ej. Giselle, Lago de los Cisnes) o movimientos de datasets.\n",
    "  - Basado en reglas est√©ticas (ejemplo: sugerir m√°s uso de diagonales si todo est√° frontal).\n",
    "\n",
    "7. Evaluaci√≥n de Resultados\n",
    "- M√©tricas de clasificaci√≥n: accuracy, F1-score (para calidad t√©cnica).\n",
    "- M√©tricas cuantitativas: rango de movimiento, simetr√≠a, velocidad promedio.\n",
    "- Validaci√≥n cualitativa: feedback de core√≥grafos/profesores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059dd822",
   "metadata": {},
   "source": [
    "**Introducci√≥n**\n",
    "\n",
    "La creaci√≥n coreogr√°fica es un proceso complejo en el que confluyen m√∫ltiples dimensiones: t√©cnica, expresiva, est√©tica, espacial y musical. Tradicionalmente, los core√≥grafos se apoyan en la observaci√≥n subjetiva y en la interacci√≥n directa con los int√©rpretes para tomar decisiones durante la composici√≥n. Sin embargo, en la actualidad, el desarrollo de tecnolog√≠as de visi√≥n por computador y aprendizaje autom√°tico abre la posibilidad de incorporar herramientas inteligentes que analicen objetivamente el movimiento y ofrezcan sugerencias en tiempo real o a partir de grabaciones.\n",
    "El presente proyecto propone el desarrollo de un asistente coreogr√°fico inteligente que, a partir de la captura en v√≠deo (subido o en streaming), procese las secuencias de movimiento de los bailarines y proporcione retroalimentaci√≥n automatizada para mejorar la calidad t√©cnica, la expresividad y la organizaci√≥n espacial de la coreograf√≠a. Este enfoque busca situarse en la intersecci√≥n entre arte y tecnolog√≠a, ofreciendo al core√≥grafo un apoyo complementario que no sustituye la creatividad humana, sino que la amplifica mediante an√°lisis basados en datos.\n",
    "\n",
    "Objetivos\n",
    "\n",
    "Objetivo General\n",
    "\n",
    "Dise√±ar e implementar un sistema de asistencia coreogr√°fica basado en visi√≥n por computador y machine learning, capaz de analizar v√≠deos de danza y generar sugerencias constructivas que apoyen el proceso creativo de core√≥grafos y bailarines.\n",
    "\n",
    "Objetivos Espec√≠ficos\n",
    "\n",
    "Revisi√≥n cr√≠tica del problema: identificar los principales retos en la creaci√≥n coreogr√°fica que pueden beneficiarse de un an√°lisis automatizado (t√©cnicos, espaciales, r√≠tmicos, est√©ticos).\n",
    "\n",
    "Obtenci√≥n y procesamiento de datos: recopilar datasets de danza y procesar secuencias de movimiento mediante t√©cnicas de pose estimation (MediaPipe, OpenPose).\n",
    "\n",
    "Definici√≥n de features coreogr√°ficas: dise√±ar m√©tricas objetivas a partir de los keypoints del cuerpo humano (amplitud, simetr√≠a, ocupaci√≥n espacial, fluidez).\n",
    "\n",
    "Entrenamiento de modelos de machine learning: explorar algoritmos de clasificaci√≥n y an√°lisis secuencial (SVM, Random Forest, LSTM/GRU) para evaluar la calidad del movimiento y generar sugerencias.\n",
    "\n",
    "Validaci√≥n del sistema: comparar m√©tricas t√©cnicas con evaluaciones de expertos en danza, asegurando la pertinencia de las recomendaciones.\n",
    "Desarrollo de una interfaz de uso: implementar un prototipo funcional en un notebook (y eventualmente en una app sencilla) donde se puedan subir v√≠deos o conectar una c√°mara en directo.\n",
    "\n",
    " Revisi√≥n del Problema\n",
    "\n",
    "El proceso de creaci√≥n coreogr√°fica enfrenta varios desaf√≠os:\n",
    "Subjetividad en la evaluaci√≥n: la calidad de un movimiento o de una secuencia depende en gran medida de la mirada del core√≥grafo, lo que puede limitar la retroalimentaci√≥n objetiva.\n",
    "\n",
    "Dificultad de an√°lisis en tiempo real: en ensayos, es complicado analizar simult√°neamente la t√©cnica individual, la coordinaci√≥n grupal y el uso del espacio.\n",
    "\n",
    "Falta de herramientas digitales espec√≠ficas para danza: existen aplicaciones de an√°lisis de movimiento en deportes o rehabilitaci√≥n, pero pocas enfocadas en las necesidades de la composici√≥n coreogr√°fica.\n",
    "\n",
    "Limitada retroalimentaci√≥n cuantitativa: la mayor√≠a de las observaciones son cualitativas; faltan m√©tricas visualizables que permitan al core√≥grafo detectar patrones o desequilibrios.\n",
    "\n",
    "El asistente coreogr√°fico propuesto busca dar respuesta a estas limitaciones mediante:\n",
    "- la captura y an√°lisis autom√°tico de movimiento;\n",
    "- la transformaci√≥n de datos en sugerencias √∫tiles;\n",
    "- la complementariedad entre la intuici√≥n art√≠stica y el an√°lisis objetivo.\n",
    "\n",
    "Este proyecto se alinea con la tendencia emergente de integrar la inteligencia artificial en las artes esc√©nicas, fomentando nuevas formas de creaci√≥n y colaboraci√≥n entre el arte y la tecnolog√≠a.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a519fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistema (ffmpeg para v√≠deo; parallel √∫til en batch)\n",
    "!apt-get -yq update\n",
    "!apt-get -yq install ffmpeg parallel\n",
    "\n",
    "# Paquetes Python esenciales para esta notebook\n",
    "%pip -q install --upgrade pandas scipy scikit-learn tqdm matplotlib \\\n",
    "                         opencv-python-headless ultralytics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b15bef",
   "metadata": {},
   "source": [
    "# **B√∫squeda y Recopilaci√≥n de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb2e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports globales ===\n",
    "import os, sys, glob, json, math, shutil, zipfile, itertools, pathlib\n",
    "from typing import Optional, Tuple, List, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "# === Constantes ===\n",
    "# COCO-17: √≠ndices est√°ndar usados por YOLOv8/MMPose (pose de 17 puntos)\n",
    "COCO_EDGES = [\n",
    "    (5,7),(7,9),   # brazo izquierdo: hombro->codo->mu√±eca\n",
    "    (6,8),(8,10),  # brazo derecho\n",
    "    (11,13),(13,15), # pierna izq: cadera->rodilla->tobillo\n",
    "    (12,14),(14,16), # pierna dcha\n",
    "    (5,6), (11,12),  # hombros, caderas\n",
    "    (5,11), (6,12)   # hombro- cadera (lado)\n",
    "]\n",
    "\n",
    "# Rutas del proyecto\n",
    "BASE = ROOT\n",
    "RAW = f\"{BASE}/data/raw/aistpp\"\n",
    "PROCESSED = f\"{BASE}/data/processed/aistpp\"\n",
    "ANN = f\"{BASE}/data/annotations/aistpp\"\n",
    "LOGS = f\"{BASE}/logs\"\n",
    "\n",
    "print(\"Constantes inicializadas. COCO_EDGES:\", len(COCO_EDGES), \"aristas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b46f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Utilidades para keypoints 2D/3D ===\n",
    "\n",
    "def find_first_glob(root: str, pattern: str) -> Optional[str]:\n",
    "    rootp = pathlib.Path(root)\n",
    "    m = sorted(rootp.rglob(pattern))\n",
    "    return str(m[0]) if m else None\n",
    "\n",
    "def load_any(path: str):\n",
    "    suf = pathlib.Path(path).suffix.lower()\n",
    "    if suf in (\".pkl\", \".pickle\"):\n",
    "        import pickle\n",
    "        with open(path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    if suf == \".npz\":\n",
    "        data = np.load(path, allow_pickle=True)\n",
    "        return {k: data[k] for k in data.files}\n",
    "    if suf == \".npy\":\n",
    "        return np.load(path, allow_pickle=True)\n",
    "    raise ValueError(f\"Formato no soportado: {suf} ({path})\")\n",
    "\n",
    "def to_TJD(obj) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Convierte estructuras comunes a un ndarray (T, J, D) float32, D in {2,3}.\n",
    "    Devuelve None si no puede inferirse.\n",
    "    \"\"\"\n",
    "    if obj is None:\n",
    "        return None\n",
    "    # Casos tipo dict con clave 'keypoints' o similar\n",
    "    if isinstance(obj, dict):\n",
    "        for k in (\"keypoints\", \"poses\", \"kpts\", \"arr\", \"data\"):\n",
    "            if k in obj:\n",
    "                arr = np.asarray(obj[k])\n",
    "                break\n",
    "        else:\n",
    "            # si no hay claves t√≠picas, prueba cualquier valor ndarray\n",
    "            for v in obj.values():\n",
    "                if isinstance(v, np.ndarray) and v.ndim >= 2:\n",
    "                    arr = np.asarray(v); break\n",
    "            else:\n",
    "                return None\n",
    "    else:\n",
    "        arr = np.asarray(obj)\n",
    "\n",
    "    arr = np.asarray(arr)\n",
    "    # Si viene (N, J*D) ‚Üí reshape\n",
    "    if arr.ndim == 2 and arr.shape[1] in (17*2, 17*3):\n",
    "        D = 2 if arr.shape[1] == 34 else 3\n",
    "        J = 17\n",
    "        T = arr.shape[0]\n",
    "        arr = arr.reshape(T, J, D)\n",
    "    # Si viene (T, J, D)\n",
    "    if arr.ndim == 3 and arr.shape[-1] in (2,3):\n",
    "        return arr.astype(np.float32)\n",
    "    return None\n",
    "\n",
    "def interpolate_nan(K: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Interplola NaNs por columna en cada joint-dim independiente.\"\"\"\n",
    "    K = K.copy()\n",
    "    T, J, D = K.shape\n",
    "    for j in range(J):\n",
    "        for d in range(D):\n",
    "            v = K[:, j, d]\n",
    "            nans = ~np.isfinite(v)\n",
    "            if nans.any():\n",
    "                t = np.arange(T)\n",
    "                if (~nans).sum() >= 2:\n",
    "                    K[:, j, d] = np.interp(t, t[~nans], v[~nans])\n",
    "                else:\n",
    "                    # si casi todo es NaN, rellena con 0\n",
    "                    K[:, j, d] = 0.0\n",
    "    return K\n",
    "\n",
    "def normalize_2d(K: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normaliza 2D por traslaci√≥n (centro de masa aproximado) y escala (distancia hombros).\n",
    "    Devuelve (T,J,2).\n",
    "    \"\"\"\n",
    "    K = K.copy().astype(np.float32)\n",
    "    # centro de masa aprox = media de caderas (11,12) si existen; si no, media global\n",
    "    if K.shape[1] >= 13:\n",
    "        com = np.nanmean(K[:, [11,12], :], axis=1)\n",
    "    else:\n",
    "        com = np.nanmean(K, axis=1)\n",
    "    K = K - com[:, None, :]\n",
    "\n",
    "    # escala: distancia entre hombros (5 y 6) si existen; si no, mediana de distancias\n",
    "    if K.shape[1] >= 7:\n",
    "        shoulder_dist = np.linalg.norm(K[:,5,:] - K[:,6,:], axis=1)\n",
    "        s = np.nanmedian(shoulder_dist)\n",
    "    else:\n",
    "        # mediana de distancias a COM\n",
    "        s = np.nanmedian(np.linalg.norm(K, axis=2))\n",
    "    if not np.isfinite(s) or s <= 1e-6:\n",
    "        s = 1.0\n",
    "    K /= s\n",
    "    return K\n",
    "\n",
    "def plot_skeleton_2d(frame: np.ndarray, title=\"\"):\n",
    "    xs, ys = frame[:,0], frame[:,1]\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.scatter(xs, ys, s=12)\n",
    "    for a,b in COCO_EDGES:\n",
    "        if a < len(frame) and b < len(frame):\n",
    "            plt.plot([xs[a], xs[b]], [ys[a], ys[b]])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis(\"equal\");\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "import os, time, pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Si no existiera COCO_EDGES en tu entorno, lo definimos para la visualizaci√≥n\n",
    "try:\n",
    "    COCO_EDGES\n",
    "except NameError:\n",
    "    COCO_EDGES = [\n",
    "        (5,7),(7,9),(6,8),(8,10),(11,13),(13,15),\n",
    "        (12,14),(14,16),(5,6),(11,12),(5,11),(6,12)\n",
    "    ]\n",
    "\n",
    "# ---------- Helpers de demo (usan TUS funciones) ----------\n",
    "def pick_best_frame(K2: np.ndarray) -> int:\n",
    "    \"\"\"Elige el frame con m√°s puntos finitos para visualizar.\"\"\"\n",
    "    if K2.ndim != 2 or K2.shape[1] < 2:\n",
    "        return 0\n",
    "    # K2 es (J,2) en un frame; cuando venga la secuencia usamos fuera\n",
    "    return 0\n",
    "\n",
    "def pick_best_frame_seq(K2_seq: np.ndarray) -> int:\n",
    "    \"\"\"Para una secuencia (T,J,2), elige el frame con m√°s joints v√°lidos.\"\"\"\n",
    "    T = K2_seq.shape[0]\n",
    "    fin = np.isfinite(K2_seq[:,:,0]) & np.isfinite(K2_seq[:,:,1])\n",
    "    cnt = fin.sum(axis=1)\n",
    "    return int(np.argmax(cnt)) if T else 0\n",
    "\n",
    "def demo_keypoints_debug(ROOT: str):\n",
    "    print(f\" Buscando archivos en: {ROOT}\")\n",
    "    patterns = [\"**/*.npz\", \"**/*.npy\", \"**/*.pkl\", \"**/*.pickle\"]\n",
    "    path = None\n",
    "    for pat in patterns:\n",
    "        path = find_first_glob(ROOT, pat)\n",
    "        if path:\n",
    "            print(f\" Encontrado: {path}  (patr√≥n: {pat})\")\n",
    "            break\n",
    "    if not path:\n",
    "        print(\" No se encontr√≥ ning√∫n archivo de keypoints en la ruta dada.\")\n",
    "        return\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    obj = load_any(path)\n",
    "    print(f\" load_any: {time.perf_counter()-t0:.3f}s | tipo: {type(obj)}\")\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    K = to_TJD(obj)\n",
    "    print(f\" to_TJD: {time.perf_counter()-t0:.3f}s | shape: {None if K is None else K.shape}\")\n",
    "\n",
    "    if K is None:\n",
    "        print(\" No se pudo convertir a (T,J,D). Revisa el contenido del archivo.\")\n",
    "        if isinstance(obj, dict):\n",
    "            keys = list(obj.keys())\n",
    "            print(\" Claves disponibles:\", keys[:10], \"...\" if len(keys)>10 else \"\")\n",
    "        return\n",
    "\n",
    "    # Estad√≠sticas b√°sicas\n",
    "    T,J,D = K.shape\n",
    "    n_nan = int(np.isnan(K).sum())\n",
    "    print(f\"Frames: {T} | Joints: {J} | Dims: {D} | NaNs totales: {n_nan}\")\n",
    "\n",
    "    # Interpolaci√≥n de NaNs (tu funci√≥n)\n",
    "    Kc = interpolate_nan(K)\n",
    "    print(\" Interpolaci√≥n de NaNs aplicada.\")\n",
    "\n",
    "    # Normalizaci√≥n y visualizaci√≥n 2D si hay al menos 2D\n",
    "    if D >= 2:\n",
    "        K2_seq = normalize_2d(Kc[...,:2])  # (T,J,2) normalizado\n",
    "        f = pick_best_frame_seq(K2_seq)\n",
    "        print(f\" Visualizando frame #{f} (mayor n¬∫ de puntos v√°lidos).\")\n",
    "        plot_skeleton_2d(K2_seq[f], title=f\"Frame {f}\")\n",
    "    else:\n",
    "        print(\"‚Ñπ Datos con D<2; se omite visualizaci√≥n de esqueleto.\")\n",
    "\n",
    "# ==== EJECUTAR DEMO ====\n",
    "ROOT = \"/content/drive/MyDrive/asistente_coreografico/data/annotations/aistpp/aist_plusplus_final/keypoints2d\"\n",
    "demo_keypoints_debug(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959d55ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, pickle, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BASE = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "ANN  = f\"{BASE}/data/annotations/aistpp\"\n",
    "\n",
    "def load_any(path):\n",
    "    suf = pathlib.Path(path).suffix.lower()\n",
    "    if suf == \".pkl\" or suf == \".pickle\":\n",
    "        with open(path, \"rb\") as f: obj = pickle.load(f)\n",
    "        return obj\n",
    "    if suf == \".npz\":\n",
    "        data = np.load(path, allow_pickle=True)\n",
    "        return {k: data[k] for k in data.files}\n",
    "    if suf == \".npy\":\n",
    "        return np.load(path, allow_pickle=True)\n",
    "    if suf == \".json\":\n",
    "        with open(path, \"r\") as f: return json.load(f)\n",
    "    raise ValueError(f\"Extensi√≥n no soportada: {suf}\")\n",
    "\n",
    "def to_TJD_from_any(obj):\n",
    "    # Si el PKL/NPZ es dict, busca arrays grandes dentro\n",
    "    def iter_arrays(o, depth=3):\n",
    "        if depth < 0: return\n",
    "        if isinstance(o, np.ndarray):\n",
    "            yield o\n",
    "        elif isinstance(o, dict):\n",
    "            for v in o.values(): yield from iter_arrays(v, depth-1)\n",
    "        elif isinstance(o, (list,tuple)):\n",
    "            for v in o: yield from iter_arrays(v, depth-1)\n",
    "\n",
    "    for arr in iter_arrays(obj, 4):\n",
    "        if not isinstance(arr, np.ndarray): continue\n",
    "        if arr.ndim != 3: continue\n",
    "        # probar permutaciones a (T,J,D) con D=2/3\n",
    "        for axes in [(0,1,2),(0,2,1),(1,0,2),(1,2,0),(2,0,1),(2,1,0)]:\n",
    "            T,J,D = arr.shape[axes[0]], arr.shape[axes[1]], arr.shape[axes[2]]\n",
    "            if D in (2,3) and 5 <= J <= 80 and T >= 8:\n",
    "                return np.transpose(arr, axes).astype(np.float32)\n",
    "    # si ya era np.ndarray (T,J,D)\n",
    "    if isinstance(obj, np.ndarray) and obj.ndim == 3 and obj.shape[-1] in (2,3):\n",
    "        return obj.astype(np.float32)\n",
    "    return None\n",
    "\n",
    "def find_first_existing(patterns, root):\n",
    "    rootp = pathlib.Path(root)\n",
    "    for pat in patterns:\n",
    "        f = sorted(rootp.rglob(pat))\n",
    "        if f: return str(f[0])\n",
    "    return None\n",
    "\n",
    "# Buscar 2D y 3D t√≠picos dentro de aist_plusplus_final\n",
    "p2 = find_first_existing([\n",
    "    \"aist_plusplus_final/keypoints2d/*.pkl\",\n",
    "    \"aist_plusplus_final/**/keypoints2d*.pkl\",\n",
    "    \"*keypoints2d*.pkl\",\"*pose2d*.pkl\",\"*2d*keypoints*.pkl\",\n",
    "    \"*keypoints2d*.npz\",\"*pose2d*.npz\",\"*2d*keypoints*.npz\",\n",
    "], ANN)\n",
    "\n",
    "p3 = find_first_existing([\n",
    "    \"aist_plusplus_final/keypoints3d/*.pkl\",\n",
    "    \"aist_plusplus_final/**/keypoints3d*.pkl\",\n",
    "    \"*keypoints3d*.pkl\",\"*pose3d*.pkl\",\"*3d*keypoints*.pkl\",\n",
    "    \"*keypoints3d*.npz\",\"*pose3d*.npz\",\"*3d*keypoints*.npz\",\n",
    "], ANN)\n",
    "\n",
    "print(\"Detectado 2D:\", p2)\n",
    "print(\"Detectado 3D:\", p3)\n",
    "\n",
    "K2 = None\n",
    "if p2:\n",
    "    obj2 = load_any(p2)\n",
    "    K2 = to_TJD_from_any(obj2)\n",
    "    print(\"K2 shape:\", None if K2 is None else K2.shape)\n",
    "\n",
    "K3 = None\n",
    "if p3:\n",
    "    obj3 = load_any(p3)\n",
    "    K3 = to_TJD_from_any(obj3)\n",
    "    print(\"K3 shape:\", None if K3 is None else K3.shape)\n",
    "\n",
    "# ---------- Limpieza NaN (interpolaci√≥n temporal por joint,dim) ----------\n",
    "def interpolate_nan_1d(y):\n",
    "    \"\"\"\n",
    "    y: (T,) con NaN -> forward/backward fill + interp lineal\n",
    "    \"\"\"\n",
    "    y = y.astype(np.float32)\n",
    "    T = len(y)\n",
    "    idx = np.arange(T)\n",
    "    mask = ~np.isnan(y)\n",
    "    if mask.sum() == 0:\n",
    "        return y  # todo NaN -> se tratar√° arriba\n",
    "    # forward/backward\n",
    "    # forward fill\n",
    "    last = np.nan\n",
    "    for t in range(T):\n",
    "        if np.isnan(y[t]) and not np.isnan(last):\n",
    "            y[t] = last\n",
    "        else:\n",
    "            last = y[t]\n",
    "    # backward fill\n",
    "    last = np.nan\n",
    "    for t in range(T-1, -1, -1):\n",
    "        if np.isnan(y[t]) and not np.isnan(last):\n",
    "            y[t] = last\n",
    "        else:\n",
    "            last = y[t]\n",
    "    # si a√∫n quedan NaN extremos, interp lineal con puntos v√°lidos\n",
    "    mask = ~np.isnan(y)\n",
    "    if mask.sum() >= 2 and mask.sum() < T:\n",
    "        y[~mask] = np.interp(idx[~mask], idx[mask], y[mask])\n",
    "    return y\n",
    "\n",
    "def clean_nan_interpolate(K, min_valid_ratio=0.15):\n",
    "    \"\"\"\n",
    "    Interpola NaN en cada joint y dimensi√≥n. Descarta joints con pocos datos v√°lidos.\n",
    "    Devuelve K_clean (T,J',D) y un mapa de joints usados.\n",
    "    \"\"\"\n",
    "    if K is None: return None, []\n",
    "    Kc = K.copy()\n",
    "    T,J,D = Kc.shape\n",
    "    use_joints = []\n",
    "    for j in range(J):\n",
    "        valid = ~np.isnan(Kc[:,j,:]).any(axis=1)\n",
    "        ratio = valid.mean()\n",
    "        if ratio < min_valid_ratio:\n",
    "            # demasiados NaN -> descartar este joint completo\n",
    "            Kc[:,j,:] = np.nan\n",
    "            continue\n",
    "        for d in range(D):\n",
    "            Kc[:,j,d] = interpolate_nan_1d(Kc[:,j,d])\n",
    "        use_joints.append(j)\n",
    "    # si todos descartados, devolvemos tal cual para evitar crash\n",
    "    if not use_joints:\n",
    "        return Kc, []\n",
    "    # filtrar a solo joints √∫tiles (al menos uno no NaN)\n",
    "    Kc = Kc[:, use_joints, :]\n",
    "    return Kc, use_joints\n",
    "\n",
    "def nanrobust_metrics(K):\n",
    "    \"\"\"\n",
    "    M√©tricas que ignoran NaNs: amplitud (nanmax-nanmin), velocidad media, simetr√≠a.\n",
    "    \"\"\"\n",
    "    T,J,D = K.shape\n",
    "    amp = (np.nanmax(K, axis=0) - np.nanmin(K, axis=0))  # (J,D)\n",
    "    amp_mean = np.nanmean(amp, axis=0)                   # (D,)\n",
    "    vel = np.diff(K, axis=0)                             # (T-1,J,D)\n",
    "    vel_norm = np.linalg.norm(vel, axis=2)               # (T-1,J)\n",
    "    vel_mean = np.nanmean(vel_norm)\n",
    "    # simetr√≠a: pares COCO, usando solo joints presentes\n",
    "    COCO_PAIRS = [(5,6),(7,8),(9,10),(11,12),(13,14),(15,16)]\n",
    "    pair_vals = []\n",
    "    for a,b in COCO_PAIRS:\n",
    "        if a < J and b < J:\n",
    "            diff = K[:,a,:] - K[:,b,:]\n",
    "            # Check number of dimensions before calculating norm\n",
    "            if diff.ndim > 1:\n",
    "                d = np.linalg.norm(diff, axis=1).mean()  # Correct axis for (T, D) -> (T,)\n",
    "                pair_vals.append(np.nanmean(d))\n",
    "    sym_raw = np.nanmean(pair_vals) if pair_vals else np.nan\n",
    "    # avoid division by zero if all amplitude means are zero or NaN\n",
    "    sum_amp_mean = np.nansum(amp_mean)\n",
    "    sym_index = sym_raw / (sum_amp_mean + 1e-6) if sum_amp_mean > 0 else np.nan\n",
    "    return {\n",
    "        \"amp_media_por_eje\": [float(x) if np.isfinite(x) else float('nan') for x in amp_mean],\n",
    "        \"vel_media\": float(vel_mean) if np.isfinite(vel_mean) else float('nan'),\n",
    "        \"simetria_indice\": float(sym_index) if np.isfinite(sym_index) else float('nan')\n",
    "    }\n",
    "\n",
    "# Limpiar K3 y medir\n",
    "if K3 is not None:\n",
    "    K3c, used3 = clean_nan_interpolate(K3, min_valid_ratio=0.10)\n",
    "    print(f\"Joints 3D usados: {len(used3)} de {K3.shape[1]}\")\n",
    "    m3 = nanrobust_metrics(K3c)\n",
    "    print(\"M√©tricas 3D (limpias):\", m3)\n",
    "\n",
    "# Intentar localizar/cargar 2D si no se encontr√≥\n",
    "if K2 is None:\n",
    "    # En muchos paquetes 2D falta, trabajamos con proyecci√≥n (x,y) del 3D limpio\n",
    "    if K3 is not None:\n",
    "        K2 = K3c[:,:,:2]  # x,y\n",
    "        print(\"K2 generado por proyecci√≥n de K3 (x,y). Shape:\", K2.shape)\n",
    "\n",
    "# Visualizaci√≥n 2D\n",
    "def plot_skeleton_2d(frame, title=\"Skeleton 2D\"):\n",
    "    # Conectividad COCO aproximada\n",
    "    edges = [(5,7),(7,9),(6,8),(8,10),(11,13),(13,15),\n",
    "             (12,14),(14,16),(5,6),(11,12),(5,11),(6,12)]\n",
    "    xs, ys = frame[:,0], frame[:,1]\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.scatter(xs, ys, s=12)\n",
    "    for a,b in edges:\n",
    "        if a < len(frame) and b < len(frame):\n",
    "            plt.plot([xs[a], xs[b]], [ys[a], ys[b]])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis(\"equal\"); plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "if K2 is not None and np.isfinite(K2).any():\n",
    "    mid = len(K2)//2\n",
    "    plot_skeleton_2d(K2[mid], \"Frame medio (2D limpio)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ea3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Centro de masas aproximado = promedio de caderas (11 y 12 en COCO)\n",
    "def center_of_mass(K):\n",
    "    if K.shape[1] >= 13:\n",
    "        return (K[:,11,:] + K[:,12,:]) / 2\n",
    "    return K.mean(axis=1)\n",
    "\n",
    "def features_coreograficos(K):\n",
    "    T,J,D = K.shape\n",
    "    feats = {}\n",
    "\n",
    "    # --- amplitud global ---\n",
    "    amp = (K.max(axis=0) - K.min(axis=0)).mean(axis=0)\n",
    "    feats[\"amplitud_x\"], feats[\"amplitud_y\"] = amp[0], amp[1]\n",
    "    if D == 3: feats[\"amplitud_z\"] = amp[2]\n",
    "\n",
    "    # --- velocidad / fluidez ---\n",
    "    vel = np.linalg.norm(np.diff(K,axis=0),axis=2).mean()\n",
    "    feats[\"velocidad_media\"] = vel\n",
    "\n",
    "    # --- simetr√≠a ---\n",
    "    pairs = [(5,6),(7,8),(9,10),(11,12),(13,14),(15,16)]\n",
    "    pair_dists = []\n",
    "    for a,b in pairs:\n",
    "        if a<J and b<J:\n",
    "            d = np.linalg.norm(K[:,a,:]-K[:,b,:],axis=1).mean()\n",
    "            pair_dists.append(d)\n",
    "    feats[\"simetria\"] = np.mean(pair_dists)\n",
    "\n",
    "    # --- niveles espaciales ---\n",
    "    com = center_of_mass(K)\n",
    "    feats[\"nivel_alto\"] = np.percentile(com[:,1],90)\n",
    "    feats[\"nivel_bajo\"] = np.percentile(com[:,1],10)\n",
    "    feats[\"nivel_rango\"] = feats[\"nivel_bajo\"] - feats[\"nivel_alto\"]\n",
    "\n",
    "    # --- variedad direccional ---\n",
    "    disp = np.diff(com,axis=0)\n",
    "    dirs = np.arctan2(disp[:,1], disp[:,0])\n",
    "    cambios = np.abs(np.diff(dirs))\n",
    "    feats[\"variedad_direcciones\"] = np.mean(cambios)\n",
    "\n",
    "    return feats\n",
    "\n",
    "def sugerencias(feats: dict):\n",
    "    \"\"\"\n",
    "    Genera sugerencias coreogr√°ficas a partir de m√©tricas de an√°lisis.\n",
    "    Soporta nombres alternativos y m√©tricas opcionales.\n",
    "    Devuelve lista de strings (sugerencias deduplicadas y priorizadas).\n",
    "    \"\"\"\n",
    "\n",
    "    S = []  # sugerencias\n",
    "\n",
    "    # ===== Helpers =====\n",
    "    def val(*keys, default=None):\n",
    "        for k in keys:\n",
    "            if k in feats and feats[k] is not None:\n",
    "                return feats[k]\n",
    "        return default\n",
    "\n",
    "    def add(msg, prio=5):\n",
    "        # prio: 1 (cr√≠tico) .. 9 (cosm√©tico)\n",
    "        if msg:\n",
    "            S.append((prio, msg.strip()))\n",
    "\n",
    "    # ===== Normalizaci√≥n de nombres frecuentes =====\n",
    "    ax   = val(\"amplitud_x\", \"amp_x\")\n",
    "    ay   = val(\"amplitud_y\", \"amp_y\")\n",
    "    az   = val(\"amplitud_z\", \"amp_z\")\n",
    "    vel  = val(\"velocidad_media\", \"vel_media\")\n",
    "    vel_sd = val(\"velocidad_std\", \"vel_std\")\n",
    "    sim  = val(\"simetria\", \"simetria_raw\")\n",
    "    varD = val(\"variedad_direcciones\", \"variedad_dir\")          # (rad prom |ŒîŒ∏|)\n",
    "    nivel = val(\"nivel_rango\", \"nivel_rango\")                   # (p10 - p90 Y COM)\n",
    "    disp = val(\"disp_total\", \"trayectoria_longitud\")            # longitud de COM\n",
    "    frames = val(\"frames\")\n",
    "    dims   = val(\"dims\")\n",
    "\n",
    "    # ===== T√©cnicos (alineaci√≥n, equilibrio, extensiones, torso, cabeza) =====\n",
    "    # Alineaci√≥n postural (0..100, mayor=mejor)\n",
    "    alineacion = val(\"alineacion_postural\", \"posture_alignment_score\")\n",
    "    if alineacion is not None:\n",
    "        if alineacion < 40:\n",
    "            add(\"Alinear ejes corporales: revisar colocaci√≥n de pelvis, caja tor√°cica y eje cabeza‚Äëcadera.\", prio=2)\n",
    "        elif alineacion < 70:\n",
    "            add(\"Ajustar alineaci√≥n: activar centro (core) para estabilizar hombros y caderas.\", prio=4)\n",
    "\n",
    "    # Equilibrio/estabilidad (0..100, mayor=mejor) y sway/temblor (grande=peor)\n",
    "    equilibrio = val(\"equilibrio\", \"balance_score\")\n",
    "    sway = val(\"oscilacion_centro\", \"sway_mag\")  # pix o normalizado\n",
    "    if equilibrio is not None:\n",
    "        if equilibrio < 40:\n",
    "            add(\"Equilibrio bajo: ensayar apoyos con foco visual y transferencias de peso m√°s claras.\", prio=2)\n",
    "        elif equilibrio < 70:\n",
    "            add(\"Mejorar estabilidad: trabajar relev√©s controlados y anclajes de pie de apoyo.\", prio=4)\n",
    "    if sway is not None and sway > 15:\n",
    "        add(\"Reducir oscilaci√≥n de tronco: reforzar control de core y respiraci√≥n dirigida.\", prio=4)\n",
    "\n",
    "    # Extensiones (0..180¬∫ aproximado)\n",
    "    ext_pierna = val(\"extension_pierna\", \"leg_extension_deg\")\n",
    "    if ext_pierna is not None:\n",
    "        if ext_pierna < 60:\n",
    "            add(\"Extensi√≥n de pierna limitada: trabajar flexibilidad de isquios y acci√≥n de psoas.\", prio=5)\n",
    "        elif ext_pierna > 150:\n",
    "            add(\"Gran extensi√≥n de pierna: cuidar cierre limpio y sost√©n para evitar colapso.\", prio=6)\n",
    "\n",
    "    ext_brazo = val(\"extension_brazo\", \"arm_extension_deg\")\n",
    "    if ext_brazo is not None and ext_brazo < 70:\n",
    "        add(\"Mayor proyecci√≥n de brazos: extender a trav√©s de dedos manteniendo hombros bajos.\", prio=5)\n",
    "\n",
    "    # Torso / cabeza (0..100, mayor=mejor)\n",
    "    torso_estab = val(\"estabilidad_torso\", \"torso_stability\")\n",
    "    if torso_estab is not None and torso_estab < 50:\n",
    "        add(\"Torso inestable: aislar disociaciones pelvis/torso para limpiar l√≠neas.\", prio=4)\n",
    "    control_cabeza = val(\"control_cabeza\", \"head_control\")\n",
    "    if control_cabeza is not None and control_cabeza < 50:\n",
    "        add(\"Control de cabeza bajo: definir focos (spotting) y direcciones claras de mirada.\", prio=5)\n",
    "\n",
    "    # ===== Espaciales =====\n",
    "    if ax is not None and ay is not None:\n",
    "        if ax < 50 or ay < 50:\n",
    "            add(\"Aumentar amplitud: proyectar m√°s en horizontal/vertical y ampliar desplazamientos.\", prio=3)\n",
    "        if abs(ax - ay) > 120:\n",
    "            add(\"Equilibrar uso de ejes: compensar horizontal/vertical para un espacio m√°s homog√©neo.\", prio=5)\n",
    "        if max(ax, ay) > 260:\n",
    "            add(\"Amplitud muy alta: alternar micro‚Äëgestos/pausas para no saturar el encuadre.\", prio=6)\n",
    "    if az is not None and az > 40:\n",
    "        add(\"Exceso de variaci√≥n en profundidad: estabilizar planos antes de cambiar de nivel Z.\", prio=7)\n",
    "\n",
    "    if nivel is not None:\n",
    "        if nivel < 30:\n",
    "            add(\"Explorar niveles: a√±adir suelo (low) y saltos (high) para mayor contraste vertical.\", prio=3)\n",
    "        elif nivel > 120:\n",
    "            add(\"Rango vertical muy amplio: introducir tr√°nsitos por nivel medio para cohesi√≥n.\", prio=6)\n",
    "\n",
    "    if disp is not None:\n",
    "        if disp < 150:\n",
    "            add(\"Ocupaci√≥n espacial reducida: abrir diagonales y profundidades para ventilar la escena.\", prio=4)\n",
    "        elif disp > 2000:\n",
    "            add(\"Demasiada traslaci√≥n: crear anclajes y puntos de fijaci√≥n para foco visual.\", prio=6)\n",
    "\n",
    "    # Curvatura/entrop√≠a de trayectoria (0 lineal .. alto curvo/err√°tico)\n",
    "    curv = val(\"curvatura_trayectoria\", \"path_curvature\", \"trayectoria_curv\")\n",
    "    if curv is not None:\n",
    "        if curv < 0.15:\n",
    "            add(\"Trayectorias lineales: incorporar arcos/espirales para enriquecer el dibujo espacial.\", prio=6)\n",
    "        elif curv > 0.8:\n",
    "            add(\"Trayectorias muy sinuosas: incluir l√≠neas rectas para contraste y legibilidad.\", prio=7)\n",
    "\n",
    "    # ===== Direcciones / Orientaci√≥n =====\n",
    "    if varD is not None:\n",
    "        if varD < 0.4:\n",
    "            add(\"Poca variedad direccional: sumar giros, cambios de orientaci√≥n y diagonales.\", prio=4)\n",
    "        elif varD > 1.8:\n",
    "            add(\"Exceso de quiebres: sostener orientaci√≥n m√°s tiempo para dar foco.\", prio=6)\n",
    "\n",
    "    # ===== Din√°mica (velocidad/fluidez/pausas/energ√≠a) =====\n",
    "    if vel is not None:\n",
    "        if vel < 2.0:\n",
    "            add(\"Incrementar fluidez: encadenar transiciones y elevar tonicidad en pasajes clave.\", prio=3)\n",
    "        elif vel > 8.0:\n",
    "            add(\"Regular velocidad: introducir suspensiones/pausas para respiraci√≥n esc√©nica.\", prio=5)\n",
    "\n",
    "    if vel_sd is not None:\n",
    "        if vel_sd < 0.5:\n",
    "            add(\"Din√°mica mon√≥tona: a√±adir acentos, contrastes de peso y calidad de esfuerzo.\", prio=4)\n",
    "        elif vel_sd > 3.0:\n",
    "            add(\"Din√°mica err√°tica: clarificar acentos primarios y limpiar transiciones.\", prio=5)\n",
    "\n",
    "    pausas = val(\"pausas_ratio\", \"pause_ratio\")  # 0..1\n",
    "    if pausas is not None:\n",
    "        if pausas < 0.05:\n",
    "            add(\"Casi sin pausas: insertar micro‚Äësilencios para realzar acentos.\", prio=6)\n",
    "        elif pausas > 0.35:\n",
    "            add(\"Muchas pausas: conectar frases para sostener la continuidad.\", prio=6)\n",
    "\n",
    "    energia = val(\"energia\", \"energy_level\")  # 0..100\n",
    "    if energia is not None:\n",
    "        if energia < 30:\n",
    "            add(\"Energ√≠a baja: elevar ataque y proyecci√≥n para sostener presencia esc√©nica.\", prio=4)\n",
    "        elif energia > 85:\n",
    "            add(\"Energ√≠a muy alta: modular con momentos de contenci√≥n para diversidad.\", prio=6)\n",
    "\n",
    "    # ===== Simetr√≠a / Disociaciones =====\n",
    "    if sim is not None:\n",
    "        if sim < 10:\n",
    "            add(\"Demasiada asimetr√≠a: introducir momentos de equilibrio bilateral.\", prio=5)\n",
    "        elif sim > 80:\n",
    "            add(\"Mucha simetr√≠a: explorar disociaciones entre lados para enriquecer textura.\", prio=5)\n",
    "\n",
    "    disoc = val(\"disociacion\", \"disociation_score\")  # 0..100\n",
    "    if disoc is not None:\n",
    "        if disoc < 30:\n",
    "            add(\"Poca disociaci√≥n: trabajar independencia de brazos/torso/piernas.\", prio=6)\n",
    "        elif disoc > 85:\n",
    "            add(\"Mucha disociaci√≥n: re‚Äësincronizar focos corporales para cohesi√≥n del fraseo.\", prio=7)\n",
    "\n",
    "    # ===== Suelo / Peso / Tiempo / Espacio / Fluidez (Laban) =====\n",
    "    tiempo_suelo = val(\"tiempo_en_suelo\", \"ground_time_ratio\")  # 0..1\n",
    "    if tiempo_suelo is not None:\n",
    "        if tiempo_suelo < 0.1:\n",
    "            add(\"Casi sin trabajo de suelo: integrar apoyos low para contraste de niveles.\", prio=5)\n",
    "        elif tiempo_suelo > 0.6:\n",
    "            add(\"Mucho suelo: alternar elevaciones a nivel medio/alto para balance.\", prio=6)\n",
    "\n",
    "    laban_peso   = val(\"laban_peso\", \"effort_weight\")     # 0 ligero .. 1 fuerte\n",
    "    laban_tiempo = val(\"laban_tiempo\", \"effort_time\")     # 0 sostenido .. 1 s√∫bito\n",
    "    laban_espacio= val(\"laban_espacio\", \"effort_space\")   # 0 indirecto .. 1 directo\n",
    "    laban_fluidez= val(\"laban_fluidez\", \"effort_flow\")    # 0 ligado .. 1 libre\n",
    "    if laban_peso is not None:\n",
    "        if laban_peso < 0.3: add(\"Calidad ligera: incorporar acentos de peso para densidad expresiva.\", prio=6)\n",
    "        elif laban_peso > 0.8: add(\"Peso muy marcado: intercalar pasajes ligeros para contraste.\", prio=6)\n",
    "    if laban_tiempo is not None:\n",
    "        if laban_tiempo < 0.3: add(\"Tiempo sostenido: sumar ataques s√∫bitos para sorpresa r√≠tmica.\", prio=6)\n",
    "        elif laban_tiempo > 0.8: add(\"Tiempo muy s√∫bito: incluir prolongaciones/sostenidos para respirar.\", prio=6)\n",
    "    if laban_espacio is not None:\n",
    "        if laban_espacio < 0.3: add(\"Espacio indirecto: introducir trayectorias directas y precisas.\", prio=7)\n",
    "        elif laban_espacio > 0.8: add(\"Espacio muy directo: sumar exploraci√≥n perif√©rica/curvil√≠nea.\", prio=7)\n",
    "    if laban_fluidez is not None:\n",
    "        if laban_fluidez < 0.3: add(\"Flujo muy ligado: liberar articulaciones para mayor libertad.\", prio=7)\n",
    "        elif laban_fluidez > 0.8: add(\"Flujo muy libre: consolidar cierres para claridad formal.\", prio=7)\n",
    "\n",
    "    # ===== M√∫sica / Ritmo =====\n",
    "    onbeat = val(\"onbeat_ratio\")\n",
    "    bpm    = val(\"bpm\")\n",
    "    if onbeat is not None:\n",
    "        if onbeat < 0.4:\n",
    "            add(\"Poca alineaci√≥n con el pulso: anclar acentos coreogr√°ficos a pulsos o contratiempos claros.\", prio=4)\n",
    "        elif onbeat > 0.9:\n",
    "            add(\"Adherencia total al pulso: jugar con s√≠ncopas/silencios para sorpresa.\", prio=6)\n",
    "    if bpm is not None and vel is not None:\n",
    "        if bpm >= 120 and vel < 3.0:\n",
    "            add(\"M√∫sica r√°pida con baja energ√≠a motriz: aumentar ataque y desplazamiento.\", prio=4)\n",
    "        if bpm <= 80 and vel > 6.0:\n",
    "            add(\"M√∫sica lenta con alta energ√≠a: introducir suspensi√≥n y foco en calidad del gesto.\", prio=5)\n",
    "\n",
    "    # ===== Grupales (sync/unison/spread/√°rea/proximidad/centros) =====\n",
    "    gm_sync  = val(\"gm_sync\", \"sync\")\n",
    "    gm_unis  = val(\"gm_unison\", \"unison\")\n",
    "    gm_sp    = val(\"gm_spread\", \"spread\")\n",
    "    gm_area  = val(\"formation_area\", \"gm_formation_area\")\n",
    "    prox_col = val(\"colisiones_proximidad\", \"near_collisions\")  # conteo/frame\n",
    "    centros  = val(\"centros_atencion\", \"attention_centers\")     # 1..N\n",
    "\n",
    "    if gm_sync is not None:\n",
    "        if gm_sync < 0.2:\n",
    "            add(\"Sincron√≠a grupal baja: ensayar cues comunes y respiraci√≥n compartida.\", prio=2)\n",
    "        elif gm_sync > 0.6:\n",
    "            add(\"Buena sincron√≠a: insertar contrapuntos/c√°nones controlados para riqueza.\", prio=6)\n",
    "    if gm_unis is not None:\n",
    "        if gm_unis < 0.5:\n",
    "            add(\"Un√≠sono d√©bil: trabajar frases espejo y acentos comunes antes del contrapunto.\", prio=3)\n",
    "        elif gm_unis > 0.85:\n",
    "            add(\"Un√≠sono muy alto: introducir micro‚Äëvariaciones de timing/nivel.\", prio=6)\n",
    "    if gm_sp is not None:\n",
    "        if gm_sp < 60:\n",
    "            add(\"Formaci√≥n compacta: abrir aperturas y diagonales para respiraci√≥n esc√©nica.\", prio=3)\n",
    "        elif gm_sp > 300:\n",
    "            add(\"Formaci√≥n muy dispersa: crear subgrupos/centros de atenci√≥n para dirigir la mirada.\", prio=4)\n",
    "    if gm_area is not None:\n",
    "        if gm_area < 3000:\n",
    "            add(\"√Årea de formaci√≥n peque√±a: explorar geometr√≠as amplias (V, X, diagonales).\", prio=5)\n",
    "        elif gm_area > 20000:\n",
    "            add(\"√Årea de formaci√≥n grande: condensar en momentos clave para impacto visual.\", prio=6)\n",
    "    if prox_col is not None and prox_col > 0.2:\n",
    "        add(\"Riesgo de colisiones: definir rutas y prioridades de paso entre int√©rpretes.\", prio=3)\n",
    "    if centros is not None:\n",
    "        if centros < 1.5:\n",
    "            add(\"Un solo foco esc√©nico: sumar focos secundarios o desplazarlos en el tiempo.\", prio=7)\n",
    "        elif centros > 3.5:\n",
    "            add(\"Demasiados focos: simplificar para no dispersar la atenci√≥n del p√∫blico.\", prio=6)\n",
    "\n",
    "    # ===== Composici√≥n / Continuidad / Originalidad =====\n",
    "    continuidad = val(\"continuidad\", \"continuity_score\")  # 0..100\n",
    "    if continuidad is not None and continuidad < 50:\n",
    "        add(\"Continuidad d√©bil: mejorar enlaces entre frases y cadencias de cierre/apertura.\", prio=4)\n",
    "\n",
    "    trans_suaves = val(\"transiciones_suaves\", \"smooth_transitions\")  # 0..100\n",
    "    if trans_suaves is not None and trans_suaves < 50:\n",
    "        add(\"Transiciones bruscas: trabajar anticipaci√≥n y preparaci√≥n para cambios limpios.\", prio=5)\n",
    "\n",
    "    originalidad = val(\"originalidad_trayectoria\", \"trajectory_novelty\")  # 0..100\n",
    "    if originalidad is not None and originalidad < 40:\n",
    "        add(\"Baja originalidad espacial: introducir permutaciones (retrogradaci√≥n, inversi√≥n, desplazamientos).\", prio=7)\n",
    "\n",
    "    densidad = val(\"densidad_mov\", \"movement_density\")  # acciones/s\n",
    "    if densidad is not None:\n",
    "        if densidad < 0.5:\n",
    "            add(\"Densidad escasa: a√±adir ornamentaci√≥n o capas secundarias en transiciones.\", prio=7)\n",
    "        elif densidad > 3.0:\n",
    "            add(\"Densidad alta: limpiar material y dejar respirar los acentos.\", prio=7)\n",
    "\n",
    "    # ===== Comunicaci√≥n/Escena =====\n",
    "    contacto_visual = val(\"contacto_visual\", \"gaze_contact_ratio\")  # 0..1\n",
    "    if contacto_visual is not None:\n",
    "        if contacto_visual < 0.15:\n",
    "            add(\"Poco contacto visual: definir miradas/focos para aumentar conexi√≥n con p√∫blico y partener.\", prio=6)\n",
    "        elif contacto_visual > 0.8:\n",
    "            add(\"Contacto visual constante: alternar miradas perif√©ricas para matizar la relaci√≥n esc√©nica.\", prio=7)\n",
    "\n",
    "    respiracion = val(\"respiracion_sync\", \"breath_sync\")  # 0..100\n",
    "    if respiracion is not None and respiracion < 50:\n",
    "        add(\"Baja sincron√≠a respiratoria: utilizar respiraci√≥n como cue de inicio/cierre de frases.\", prio=6)\n",
    "\n",
    "    # ===== Heur√≠sticas de duraci√≥n =====\n",
    "    if frames is not None and frames < 150:  # ~5s a 30 FPS\n",
    "        add(\"Frase corta: repetir con variaciones (canon, retrogradaci√≥n, inversi√≥n) para consolidar material.\", prio=8)\n",
    "\n",
    "    # ===== Capa est√©tica global =====\n",
    "    add(\"Capa est√©tica: alinear intenci√≥n (peso/flujo) con cualidad del movimiento para coherencia expresiva.\", prio=9)\n",
    "\n",
    "    # ===== Post-proceso: de-dup + orden por prioridad =====\n",
    "    # Eliminamos duplicados manteniendo la mayor prioridad (menor n√∫mero)\n",
    "    agg = {}\n",
    "    for p, m in S:\n",
    "        if m not in agg or p < agg[m]:\n",
    "            agg[m] = p\n",
    "    ordered = sorted([(p, m) for m, p in agg.items()], key=lambda x: x[0])\n",
    "\n",
    "    # Devuelve solo los textos\n",
    "    out = [m for _, m in ordered]\n",
    "    return out or [\"El movimiento presenta buena diversidad y balance.\"]\n",
    "\n",
    "# ---- aplicar sobre K2 (si est√° cargado) ----\n",
    "if K2 is not None:\n",
    "    feats = features_coreograficos(K2)\n",
    "    print(\"Features extra√≠dos:\\n\", feats)\n",
    "    print(\"\\nSugerencias coreogr√°ficas:\")\n",
    "    for sug in sugerencias(feats):\n",
    "        print(\" -\", sug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef10348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "\n",
    "BASE = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "ANN  = f\"{BASE}/data/annotations/aistpp\"\n",
    "PROCESSED = f\"{BASE}/data/processed/aistpp\"\n",
    "\n",
    "\n",
    "CSV  = f\"{PROCESSED}/features_coreograficos.csv\"\n",
    "ANNOTATION_DIR = f\"{ANN}/aist_plusplus_final/keypoints3d\" # Se Asumen los 3D keypoints que se estan utilizando\n",
    "\n",
    "all_features = []\n",
    "\n",
    "# Encontramos todos los pkl files en el directorio de anotaciones\n",
    "pkl_files = list(pathlib.Path(ANNOTATION_DIR).rglob(\"*.pkl\"))\n",
    "\n",
    "print(f\"Found {len(pkl_files)} annotation files.\")\n",
    "\n",
    "for pkl_file in pkl_files:\n",
    "    try:\n",
    "        obj = load_any(str(pkl_file))\n",
    "        K = to_TJD_from_any(obj)\n",
    "\n",
    "        if K is not None and np.isfinite(K).any():\n",
    "            # Liempieza de valores NaN e interpolaci√≥n\n",
    "            Kc, used_joints = clean_nan_interpolate(K, min_valid_ratio=0.10)\n",
    "\n",
    "            if Kc is not None and np.isfinite(Kc).any():\n",
    "                 # Extraemos los features\n",
    "                feats = features_coreograficos(Kc)\n",
    "\n",
    "                # A√±adimos metadata\n",
    "                feats['filename'] = pkl_file.name\n",
    "                feats['filepath'] = str(pkl_file)\n",
    "                feats['frames'] = Kc.shape[0]\n",
    "                feats['joints'] = Kc.shape[1]\n",
    "                feats['dims'] = Kc.shape[2]\n",
    "\n",
    "                all_features.append(feats)\n",
    "            else:\n",
    "                print(f\"Skipping {pkl_file.name}: No valid data after cleaning.\")\n",
    "        else:\n",
    "             print(f\"Skipping {pkl_file.name}: Could not load or find valid keypoint data.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pkl_file.name}: {e}\")\n",
    "\n",
    "\n",
    "if all_features:\n",
    "    df = pd.DataFrame(all_features)\n",
    "    df.to_csv(CSV, index=False)\n",
    "    print(f\"\\nSuccessfully extracted features and saved to {CSV}\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"\\nNo features were extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca37b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRENAMIENTO (umbral por etiqueta)\n",
    "import numpy as np, pandas as pd, os, json, joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# --- Rutas ---\n",
    "BASE = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "PROC = f\"{BASE}/data/processed/aistpp\"\n",
    "ART  = f\"{BASE}/artifacts\"\n",
    "CSV  = f\"{PROC}/features_coreograficos.csv\"\n",
    "os.makedirs(ART, exist_ok=True)\n",
    "\n",
    "# --- Cargar datos base ---\n",
    "df = pd.read_csv(CSV)\n",
    "\n",
    "# Si ya tienes y_complete de celdas previas, lo usamos. Si no, lo reconstruimos peque√±o.\n",
    "if 'y_complete' not in globals():\n",
    "    # Etiquetas m√≠nimas por si no existe y_complete (usa tus reglas si ya las definiste)\n",
    "    def _mk_y(d):\n",
    "        dnum = d.select_dtypes(include=np.number).copy()\n",
    "        q20, q80 = dnum.quantile(0.20), dnum.quantile(0.80)\n",
    "        lab = {}\n",
    "        if {\"amplitud_x\",\"amplitud_y\"} <= set(dnum.columns):\n",
    "            lab['amplitud_baja']     = ((dnum['amplitud_x']<=q20['amplitud_x'])|(dnum['amplitud_y']<=q20['amplitud_y'])).astype(int)\n",
    "            lab['amplitud_excesiva'] = ((dnum['amplitud_x']>=q80['amplitud_x'])|(dnum['amplitud_y']>=q80['amplitud_y'])).astype(int)\n",
    "            ratio = dnum['amplitud_x']/(dnum['amplitud_y']+1e-6)\n",
    "            r10,r90 = ratio.quantile(0.10), ratio.quantile(0.90)\n",
    "            lab['amplitud_desbalance'] = ((ratio<=r10)|(ratio>=r90)).astype(int)\n",
    "        for k in [\"velocidad_media\",\"simetria\",\"nivel_rango\",\"variedad_direcciones\",\"frames\"]:\n",
    "            if k in dnum:\n",
    "                lab[f\"{k}_low\"]  = (dnum[k]<=q20.get(k,np.nan)).fillna(False).astype(int)\n",
    "                lab[f\"{k}_high\"] = (dnum[k]>=q80.get(k,np.nan)).fillna(False).astype(int)\n",
    "        return pd.DataFrame(lab)\n",
    "    y_complete = _mk_y(df)\n",
    "\n",
    "label_names = y_complete.columns.tolist()\n",
    "\n",
    "# --- FEATURE ENGINEERING  ---\n",
    "def build_features(d: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = pd.DataFrame(index=d.index)\n",
    "    # b√°sicos (usa los que existan)\n",
    "    base_cols = ['amplitud_x','amplitud_y','amplitud_z',\n",
    "                 'velocidad_media','simetria','nivel_rango',\n",
    "                 'variedad_direcciones','frames']\n",
    "    for c in base_cols:\n",
    "        if c in d.columns: out[c] = pd.to_numeric(d[c], errors='coerce')\n",
    "\n",
    "    # derivados (solo si hay datos fuente)\n",
    "    if {'amplitud_x','amplitud_y'} <= set(out.columns):\n",
    "        out['amp_diff']  = (out['amplitud_x'] - out['amplitud_y']).abs()\n",
    "        out['amp_ratio'] = out['amplitud_x'] / (out['amplitud_y'].abs() + 1e-6)\n",
    "    if 'velocidad_media' in out:\n",
    "        out['vel_log1p'] = np.log1p(out['velocidad_media'].clip(lower=0))\n",
    "    if 'nivel_rango' in out:\n",
    "        out['nivel_abs'] = out['nivel_rango'].abs()\n",
    "    if {'velocidad_media','variedad_direcciones'} <= set(out.columns):\n",
    "        out['vel_x_varDir'] = out['velocidad_media'] * out['variedad_direcciones']\n",
    "    if {'simetria','amplitud_x'} <= set(out.columns):\n",
    "        out['sim_x_ampx'] = out['simetria'] * out['amplitud_x']\n",
    "\n",
    "    return out\n",
    "\n",
    "X_df = build_features(df)\n",
    "feature_cols = X_df.columns.tolist()\n",
    "X_all = X_df.values\n",
    "Y_all = y_complete.values\n",
    "\n",
    "# --- Split train/val/test (70/15/15) ---\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X_all, Y_all, test_size=0.15, random_state=42\n",
    ")\n",
    "# val = 15% del total => relativo a trainval:\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.1765, random_state=42\n",
    ")\n",
    "\n",
    "# --- Pipeline con LogisticRegressionCV dentro de OneVsRest ---\n",
    "pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\",  RobustScaler()),\n",
    "    (\"clf\", OneVsRestClassifier(\n",
    "        LogisticRegressionCV(\n",
    "            Cs=np.logspace(-2, 1, 6),   # 0.01..10\n",
    "            solver=\"liblinear\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=4000,\n",
    "            cv=3,\n",
    "            scoring=\"f1\",\n",
    "            n_jobs=-1,\n",
    "            refit=True\n",
    "        ),\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# --- Buscar UMBRALES por etiqueta en validaci√≥n para maximizar F1 ---\n",
    "def find_optimal_thresholds(y_true, y_score, grid=None):\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.2, 0.8, 61)  # 0.2..0.8 paso 0.01\n",
    "    C = y_true.shape[1]\n",
    "    thr = np.full(C, 0.5, dtype=float)\n",
    "    for i in range(C):\n",
    "        yt = y_true[:, i]\n",
    "        # si en val hay solo una clase, dejamos 0.5\n",
    "        if np.unique(yt).size < 2:\n",
    "            thr[i] = 0.5\n",
    "            continue\n",
    "        best_f1, best_t = -1.0, 0.5\n",
    "        scores_i = y_score[:, i]\n",
    "        for t in grid:\n",
    "            yp = (scores_i >= t).astype(int)\n",
    "            f1 = f1_score(yt, yp, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_t = f1, t\n",
    "        thr[i] = best_t\n",
    "    return thr\n",
    "\n",
    "# Probabilidades en validaci√≥n\n",
    "try:\n",
    "    y_val_score = pipe.predict_proba(X_val)\n",
    "except Exception:\n",
    "    # fallback: usar decision_function y pasarlo por sigmoid\n",
    "    logits = pipe.decision_function(X_val)\n",
    "    y_val_score = 1.0 / (1.0 + np.exp(-logits))\n",
    "\n",
    "thresholds = find_optimal_thresholds(y_val, y_val_score)\n",
    "\n",
    "# --- Wrapper compatible con tu celda de evaluaci√≥n ---\n",
    "class ThresholdedOVR:\n",
    "    \"\"\"Envuelve un pipeline y aplica umbral por etiqueta en predict.\"\"\"\n",
    "    def __init__(self, pipeline, thresholds, label_names=None, feature_cols=None):\n",
    "        self.pipeline = pipeline\n",
    "        self.thresholds_ = np.asarray(thresholds, dtype=float)\n",
    "        self.label_names = list(label_names) if label_names is not None else None\n",
    "        self.feature_cols = list(feature_cols) if feature_cols is not None else None\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.pipeline.predict_proba(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        P = self.predict_proba(X)\n",
    "        thr = self.thresholds_\n",
    "        # broadcast seguro\n",
    "        return (P >= thr.reshape(1, -1)).astype(int)\n",
    "\n",
    "# construir objeto final esperado por evaluaci√≥n\n",
    "complete_model = ThresholdedOVR(\n",
    "    pipeline=pipe,\n",
    "    thresholds=thresholds,\n",
    "    label_names=label_names,\n",
    "    feature_cols=feature_cols\n",
    ")\n",
    "\n",
    "# --- Evaluaci√≥n r√°pida en test para ver mejora (opcional) ---\n",
    "P_test = complete_model.predict_proba(X_test)\n",
    "Yp_test = (P_test >= thresholds.reshape(1, -1)).astype(int)\n",
    "print(\"F1 macro (test, con umbrales √≥ptimos):\", f1_score(y_test, Yp_test, average=\"macro\", zero_division=0))\n",
    "print(\"F1 micro (test, con umbrales √≥ptimos):\", f1_score(y_test, Yp_test, average=\"micro\", zero_division=0))\n",
    "\n",
    "# --- Guardado de artefactos ---\n",
    "bundle = {\n",
    "    \"pipeline\": pipe,\n",
    "    \"thresholds\": thresholds,\n",
    "    \"label_names\": label_names,\n",
    "    \"feature_cols\": feature_cols\n",
    "}\n",
    "joblib.dump(bundle, f\"{ART}/complete_model_thresholded_bundle.joblib\")\n",
    "pd.Series(label_names).to_csv(f\"{ART}/complete_label_names.csv\", index=False, header=False)\n",
    "pd.Series(feature_cols).to_csv(f\"{ART}/complete_feature_cols.csv\", index=False, header=False)\n",
    "with open(f\"{ART}/complete_thresholds.json\", \"w\") as f:\n",
    "    json.dump({label_names[i]: float(thresholds[i]) for i in range(len(label_names))}, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úîÔ∏è Artefactos guardados en:\", ART)\n",
    "print(\" - complete_model_thresholded_bundle.joblib\")\n",
    "print(\" - complete_label_names.csv\")\n",
    "print(\" - complete_feature_cols.csv\")\n",
    "print(\" - complete_thresholds.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ba390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EVALUACI√ìN ===\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, hamming_loss, jaccard_score,\n",
    "    precision_recall_fscore_support, roc_auc_score, average_precision_score,\n",
    "    multilabel_confusion_matrix, f1_score # Import f1_score here\n",
    ")\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUACI√ìN MULTIETIQUETA ‚Äì RESUMEN GLOBAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get predictions from the complete_model\n",
    "y_pred = complete_model.predict(X_test)\n",
    "\n",
    "# Attempt to get probabilities for AUC/AP if the estimator allows it\n",
    "y_score = None\n",
    "try:\n",
    "    # Check if the model is a OneVsRestClassifier and its estimators have predict_proba\n",
    "    if hasattr(complete_model, \"estimators_\") and all(hasattr(est, \"predict_proba\") for est in complete_model.estimators_):\n",
    "        y_score = np.column_stack([est.predict_proba(X_test)[:,1] for est in complete_model.estimators_])\n",
    "    elif hasattr(complete_model, \"predict_proba\"):\n",
    "         y_score = complete_model.predict_proba(X_test)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[AVISO] No se pudieron obtener probabilidades: {e}\")\n",
    "\n",
    "# M√©tricas globales\n",
    "subset_acc   = (y_pred == y_test).all(axis=1).mean()\n",
    "hamm_loss    = hamming_loss(y_test, y_pred)\n",
    "f1_micro     = f1_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "f1_macro2    = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)  # ya mostrado antes, lo repetimos aqu√≠\n",
    "f1_weighted  = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "prec_micro   = precision_recall_fscore_support(y_test, y_pred, average=\"micro\", zero_division=0)[0]\n",
    "rec_micro    = precision_recall_fscore_support(y_test, y_pred, average=\"micro\", zero_division=0)[1]\n",
    "jaccard_samples = jaccard_score(y_test, y_pred, average=\"samples\", zero_division=0) # Corrected variable name\n",
    "jaccard_macro   = jaccard_score(y_test, y_pred, average=\"macro\", zero_division=0)   # Corrected variable name\n",
    "\n",
    "\n",
    "print(f\"Subset accuracy (exact match): {subset_acc:0.4f}\")\n",
    "print(f\"Hamming loss:                 {hamm_loss:0.4f}\")\n",
    "print(f\"F1 micro:                     {f1_micro:0.4f}\")\n",
    "print(f\"F1 macro:                     {f1_macro2:0.4f}\")\n",
    "print(f\"F1 weighted:                  {f1_weighted:0.4f}\")\n",
    "print(f\"Precisi√≥n micro:              {prec_micro:0.4f}\")\n",
    "print(f\"Recall micro:                 {rec_micro:0.4f}\")\n",
    "print(f\"Jaccard (samples):            {jaccard_samples:0.4f}\")\n",
    "print(f\"Jaccard (macro):              {jaccard_macro:0.4f}\")\n",
    "\n",
    "# M√©tricas por etiqueta\n",
    "per_label_rows = []\n",
    "mcm = multilabel_confusion_matrix(y_test, y_pred)\n",
    "# Use y_complete.columns to get the correct label names\n",
    "label_names_eval = y_complete.columns.tolist()\n",
    "for i, label_name in enumerate(label_names_eval):\n",
    "    tn, fp, fn, tp = mcm[i].ravel()\n",
    "\n",
    "    # Precisi√≥n/Recall/F1 por etiqueta\n",
    "    p, r, f1, support = precision_recall_fscore_support(\n",
    "        y_test[:, i], y_pred[:, i], average=\"binary\", zero_division=0\n",
    "    )\n",
    "\n",
    "    # Handle support being None explicitly\n",
    "    support_int = int(support) if support is not None else 0\n",
    "\n",
    "    # ROC-AUC y AP si hay probabilidades y ambas clases est√°n presentes\n",
    "    roc_auc = None\n",
    "    ap = None\n",
    "    if y_score is not None:\n",
    "        # Comprobamos que en test hay positivos y negativos\n",
    "        if len(np.unique(y_test[:, i])) == 2:\n",
    "            try:\n",
    "                roc_auc = roc_auc_score(y_test[:, i], y_score[:, i])\n",
    "            except Exception:\n",
    "                roc_auc = None\n",
    "            try:\n",
    "                ap = average_precision_score(y_test[:, i], y_score[:, i])\n",
    "            except Exception:\n",
    "                ap = None\n",
    "\n",
    "    per_label_rows.append({\n",
    "        \"label\": label_name,\n",
    "        \"support\": support_int, # Use the handled support value\n",
    "        \"tp\": int(tp), \"fp\": int(fp), \"fn\": int(fn), \"tn\": int(tn),\n",
    "        \"precision\": float(p), \"recall\": float(r), \"f1\": float(f1),\n",
    "        \"roc_auc\": (None if roc_auc is None else float(roc_auc)),\n",
    "        \"avg_precision\": (None if ap is None else float(ap)),\n",
    "    })\n",
    "\n",
    "per_label_df = pd.DataFrame(per_label_rows).sort_values(\"label\")\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"M√©tricas por etiqueta (top 10 por menor F1 para priorizar mejoras):\")\n",
    "# Ensure that there are at least 10 rows before trying to print the head of 10\n",
    "if len(per_label_df) >= 10:\n",
    "  print(per_label_df.sort_values(\"f1\").head(10).to_string(index=False))\n",
    "else:\n",
    "  print(per_label_df.sort_values(\"f1\").to_string(index=False))\n",
    "\n",
    "\n",
    "# Guardado de resultados\n",
    "overall_metrics = {\n",
    "    \"subset_accuracy\": subset_acc,\n",
    "    \"hamming_loss\": hamm_loss,\n",
    "    \"f1_micro\": f1_micro,\n",
    "    \"f1_macro\": f1_macro2,\n",
    "    \"f1_weighted\": f1_weighted,\n",
    "    \"precision_micro\": prec_micro,\n",
    "    \"recall_micro\": rec_micro,\n",
    "    \"jaccard_samples\": jaccard_samples,\n",
    "    \"jaccard_macro\": jaccard_macro,\n",
    "    \"num_labels\": int(y_complete.shape[1]), # Use y_complete for total number of labels\n",
    "    \"num_samples_test\": int(y_test.shape[0])\n",
    "}\n",
    "with open(f\"{ART}/eval_overall.json\", \"w\") as f:\n",
    "    json.dump(overall_metrics, f, indent=2)\n",
    "\n",
    "per_label_df.to_csv(f\"{ART}/eval_per_label.csv\", index=False)\n",
    "\n",
    "print(\"\\nArchivos de evaluaci√≥n guardados en:\", ART)\n",
    "print(\" - eval_overall.json (m√©tricas globales)\")\n",
    "print(\" - eval_per_label.csv (m√©tricas por etiqueta)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe61540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === INFERENCIA: umbrales por etiqueta + exclusiones + diagn√≥stico ===\n",
    "import os, json, numpy as np, pandas as pd, joblib\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "BASE = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "ART  = f\"{BASE}/artifacts\"\n",
    "PROC = f\"{BASE}/data/processed/aistpp\"\n",
    "CSV  = f\"{PROC}/features_coreograficos.csv\"\n",
    "\n",
    "# === Cargar artefactos del preprocesado y modelo ===\n",
    "imp          = joblib.load(f\"{ART}/imputer.joblib\")\n",
    "scaler       = joblib.load(f\"{ART}/scaler.joblib\")\n",
    "model        = joblib.load(f\"{ART}/model_ovr_logreg.joblib\")\n",
    "feature_cols = pd.read_csv(f\"{ART}/feature_cols.csv\", header=None)[0].tolist()\n",
    "label_names  = pd.read_csv(f\"{ART}/label_names.csv\", header=None)[0].tolist()\n",
    "\n",
    "# --- Mapeo de sugerencias (puedes ampliar este diccionario) ---\n",
    "label_to_text = {\n",
    "    \"amplitud_baja\":      \"Aumentar amplitud (extensiones y desplazamientos m√°s amplios).\",\n",
    "    \"variedad_baja\":      \"Introducir cambios de direcci√≥n y diagonales.\",\n",
    "    \"mucha_simetria\":     \"Explorar asimetr√≠as entre izquierda y derecha.\",\n",
    "    \"poca_simetria\":      \"Equilibrar con momentos de simetr√≠a.\",\n",
    "    \"fluidez_baja\":       \"Trabajar transiciones para mayor continuidad/fluidez.\",\n",
    "    \"poco_rango_niveles\": \"Usar niveles alto y bajo adem√°s del medio.\",\n",
    "}\n",
    "\n",
    "# --- Grupos mutuamente excluyentes (mantener solo la m√°s probable) ---\n",
    "mutex_groups = [\n",
    "    [\"amplitud_baja\", \"amplitud_excesiva\"],\n",
    "    [\"poco_rango_niveles\", \"exceso_rango_niveles\"],\n",
    "    [\"mucha_simetria\", \"poca_simetria\"],\n",
    "    [\"variedad_baja\", \"variedad_excesiva\"],\n",
    "    [\"sincronia_baja\", \"sincronia_alta\"],\n",
    "    [\"unisono_bajo\", \"unisono_alto\"],\n",
    "    [\"formacion_compacta\", \"formacion_dispers\"],\n",
    "    [\"area_formacion_peq\", \"area_formacion_gran\"],\n",
    "    [\"poco_tiempo_suelo\", \"mucho_tiempo_suelo\"],\n",
    "]\n",
    "\n",
    "# === Utilidades ===\n",
    "def _as_dataframe_one(feats_dict, cols):\n",
    "    row = {c: feats_dict.get(c, np.nan) for c in cols}\n",
    "    return pd.DataFrame([row], columns=cols)\n",
    "\n",
    "def _predict_proba_matrix(Xm):\n",
    "    \"\"\"Devuelve matriz de probabilidades shape (n_samples, n_labels).\"\"\"\n",
    "    # OneVsRest(LogisticRegression) -> estimators_ con predict_proba\n",
    "    if hasattr(model, \"estimators_\"):\n",
    "        cols = []\n",
    "        for est in model.estimators_:\n",
    "            if hasattr(est, \"predict_proba\"):\n",
    "                cols.append(est.predict_proba(Xm)[:, 1])\n",
    "            else:\n",
    "                # Fallback con decision_function -> sigmoide\n",
    "                from scipy.special import expit\n",
    "                cols.append(expit(est.decision_function(Xm)))\n",
    "        return np.column_stack(cols)\n",
    "    # Fallback gen√©rico\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        yps = model.predict_proba(Xm)\n",
    "        # Algunos devuelven lista de arrays por etiqueta\n",
    "        if isinstance(yps, list):\n",
    "            return np.column_stack([p[:,1] for p in yps])\n",
    "        return yps\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        from scipy.special import expit\n",
    "        return expit(model.decision_function(Xm))\n",
    "    # √öltimo recurso: binario a float\n",
    "    return model.predict(Xm).astype(float)\n",
    "\n",
    "def _enforce_mutex(selected_labels, prob_series):\n",
    "    \"\"\"Elimina conflictos en grupos mutuamente excluyentes, dejando la etiqueta con mayor prob.\"\"\"\n",
    "    selected = set(selected_labels)\n",
    "    for group in mutex_groups:\n",
    "        # Intersecci√≥n con seleccionadas\n",
    "        present = [g for g in group if g in selected]\n",
    "        if len(present) > 1:\n",
    "            # Mantener la de mayor probabilidad\n",
    "            best = max(present, key=lambda k: prob_series.get(k, 0.0))\n",
    "            for g in present:\n",
    "                if g != best:\n",
    "                    selected.discard(g)\n",
    "    return list(selected)\n",
    "\n",
    "# === Cargar o aprender umbrales por etiqueta (maximizando F1) ===\n",
    "TH_FILE = f\"{ART}/thresholds_f1.json\"\n",
    "\n",
    "def _recreate_labels_proxy(df):\n",
    "    \"\"\"Reconstruye etiquetas proxy como en entrenamiento (cuantiles 20/80, low/high).\"\"\"\n",
    "    # Columnas candidatas conocidas\n",
    "    candidates = [\"amplitud_x\",\"amplitud_y\",\"velocidad_media\",\"simetria\",\n",
    "                  \"nivel_rango\",\"variedad_direcciones\",\"frames\",\"joints\",\"dims\",\n",
    "                  \"velocidad_std\",\"vel_std\",\"disp_total\",\"trayectoria_longitud\",\n",
    "                  \"gm_sync\",\"sync\",\"gm_unison\",\"unison\",\"gm_spread\",\"spread\",\n",
    "                  \"formation_area\",\"gm_formation_area\",\"onbeat_ratio\",\"bpm\",\n",
    "                  \"alineacion_postural\",\"equilibrio\",\"curvatura_trayectoria\",\n",
    "                  \"tiempo_en_suelo\",\"amp_x\",\"amp_y\",\"simetria_raw\",\"variedad_dir\"]\n",
    "    exist = [c for c in candidates if c in df.columns]\n",
    "    q20 = df[exist].quantile(0.20)\n",
    "    q80 = df[exist].quantile(0.80)\n",
    "\n",
    "    def low(col):  return (df[col] <= q20[col]).astype(int)\n",
    "    def high(col): return (df[col] >= q80[col]).astype(int)\n",
    "\n",
    "    labels_spec = {\n",
    "        \"amplitud_baja\":       ([\"amplitud_x\",\"amplitud_y\",\"amp_x\",\"amp_y\"], \"low_any\"),\n",
    "        \"amplitud_excesiva\":   ([\"amplitud_x\",\"amplitud_y\",\"amp_x\",\"amp_y\"], \"high_any\"),\n",
    "        \"poco_rango_niveles\":  ([\"nivel_rango\"], \"low\"),\n",
    "        \"exceso_rango_niveles\":([\"nivel_rango\"], \"high\"),\n",
    "        \"fluidez_baja\":        ([\"velocidad_media\",\"vel_media\"], \"low\"),\n",
    "        \"velocidad_excesiva\":  ([\"velocidad_media\",\"vel_media\"], \"high\"),\n",
    "        \"dinamica_monotona\":   ([\"velocidad_std\",\"vel_std\"], \"low\"),\n",
    "        \"dinamica_erratica\":   ([\"velocidad_std\",\"vel_std\"], \"high\"),\n",
    "        \"poca_simetria\":       ([\"simetria\",\"simetria_raw\"], \"low\"),\n",
    "        \"mucha_simetria\":      ([\"simetria\",\"simetria_raw\"], \"high\"),\n",
    "        \"variedad_baja\":       ([\"variedad_direcciones\",\"variedad_dir\"], \"low\"),\n",
    "        \"variedad_excesiva\":   ([\"variedad_direcciones\",\"variedad_dir\"], \"high\"),\n",
    "        \"ocupacion_reducida\":  ([\"disp_total\",\"trayectoria_longitud\"], \"low\"),\n",
    "        \"traslacion_excesiva\": ([\"disp_total\",\"trayectoria_longitud\"], \"high\"),\n",
    "        \"frase_corta\":         ([\"frames\"], \"low\"),\n",
    "        \"sincronia_baja\":      ([\"gm_sync\",\"sync\"], \"low\"),\n",
    "        \"sincronia_alta\":      ([\"gm_sync\",\"sync\"], \"high\"),\n",
    "        \"unisono_bajo\":        ([\"gm_unison\",\"unison\"], \"low\"),\n",
    "        \"unisono_alto\":        ([\"gm_unison\",\"unison\"], \"high\"),\n",
    "        \"formacion_compacta\":  ([\"gm_spread\",\"spread\"], \"low\"),\n",
    "        \"formacion_dispers\":   ([\"gm_spread\",\"spread\"], \"high\"),\n",
    "        \"area_formacion_peq\":  ([\"formation_area\",\"gm_formation_area\"], \"low\"),\n",
    "        \"area_formacion_gran\": ([\"formation_area\",\"gm_formation_area\"], \"high\"),\n",
    "        \"alineacion_musical_baja\": ([\"onbeat_ratio\"], \"low\"),\n",
    "        \"alineacion_musical_alta\": ([\"onbeat_ratio\"], \"high\"),\n",
    "        \"desfase_tempo_rapido\":    ([\"bpm\",\"velocidad_media\",\"vel_media\"], \"bpm_high_vel_low\"),\n",
    "        \"desfase_tempo_lento\":     ([\"bpm\",\"velocidad_media\",\"vel_media\"], \"bpm_low_vel_high\"),\n",
    "        \"alineacion_postural_baja\": ([\"alineacion_postural\"], \"low\"),\n",
    "        \"alineacion_postural_alta\": ([\"alineacion_postural\"], \"high\"),\n",
    "        \"equilibrio_bajo\":          ([\"equilibrio\"], \"low\"),\n",
    "        \"equilibrio_alto\":          ([\"equilibrio\"], \"high\"),\n",
    "        \"curvatura_baja\":           ([\"curvatura_trayectoria\"], \"low\"),\n",
    "        \"curvatura_alta\":           ([\"curvatura_trayectoria\"], \"high\"),\n",
    "        \"poco_tiempo_suelo\":        ([\"tiempo_en_suelo\"], \"low\"),\n",
    "        \"mucho_tiempo_suelo\":       ([\"tiempo_en_suelo\"], \"high\"),\n",
    "    }\n",
    "\n",
    "    ys = {}\n",
    "    for name, (cols, mode) in labels_spec.items():\n",
    "        missing = [c for c in cols if c not in df.columns]\n",
    "        if missing:\n",
    "            continue\n",
    "        if mode == \"low\":\n",
    "            ys[name] = low(cols[0])\n",
    "        elif mode == \"high\":\n",
    "            ys[name] = high(cols[0])\n",
    "        elif mode == \"low_any\":\n",
    "            v = np.zeros(len(df), dtype=int)\n",
    "            for c in cols:\n",
    "                v = np.maximum(v, low(c).values)\n",
    "            ys[name] = v\n",
    "        elif mode == \"high_any\":\n",
    "            v = np.zeros(len(df), dtype=int)\n",
    "            for c in cols:\n",
    "                v = np.maximum(v, high(c).values)\n",
    "            ys[name] = v\n",
    "        elif mode == \"bpm_high_vel_low\":\n",
    "            if \"bpm\" in df.columns and ((\"velocidad_media\" in df.columns) or (\"vel_media\" in df.columns)):\n",
    "                vlow = df[\"velocidad_media\"] if \"velocidad_media\" in df.columns else df[\"vel_media\"]\n",
    "                ys[name] = ((df[\"bpm\"] >= df[\"bpm\"].quantile(0.80)) & (vlow <= vlow.quantile(0.20))).astype(int)\n",
    "        elif mode == \"bpm_low_vel_high\":\n",
    "            if \"bpm\" in df.columns and ((\"velocidad_media\" in df.columns) or (\"vel_media\" in df.columns)):\n",
    "                vlow = df[\"velocidad_media\"] if \"velocidad_media\" in df.columns else df[\"vel_media\"]\n",
    "                ys[name] = ((df[\"bpm\"] <= df[\"bpm\"].quantile(0.20)) & (vlow >= vlow.quantile(0.80))).astype(int)\n",
    "    if not ys:\n",
    "        raise RuntimeError(\"No se pudieron recrear etiquetas proxy para aprender umbrales.\")\n",
    "    Y = pd.DataFrame(ys)\n",
    "    # Asegurar mismo orden que label_names (filtrando a las que existan)\n",
    "    kept = [l for l in label_names if l in Y.columns]\n",
    "    return Y[kept]\n",
    "\n",
    "def _learn_thresholds_f1(df, save_path=TH_FILE):\n",
    "    \"\"\"Aprende umbral por etiqueta maximizando F1 usando el CSV y el modelo actual.\"\"\"\n",
    "    # Preparar X\n",
    "    Xraw = df[feature_cols].copy()\n",
    "    Ximp = imp.transform(Xraw)\n",
    "    X    = scaler.transform(Ximp)\n",
    "    # Probabilidades\n",
    "    probs = _predict_proba_matrix(X)  # shape (N, L)\n",
    "    # Etiquetas proxy\n",
    "    Y = _recreate_labels_proxy(df)    # shape (N, L') con subset de labels\n",
    "    # Alinear dimensiones si falta alguna etiqueta\n",
    "    kept_labels = list(Y.columns)\n",
    "    kept_idx = [label_names.index(l) for l in kept_labels]\n",
    "    probs = probs[:, kept_idx]\n",
    "\n",
    "    thresholds = {}\n",
    "    for j, lbl in enumerate(kept_labels):\n",
    "        y_true = Y.values[:, j].astype(int)\n",
    "        p = probs[:, j]\n",
    "        # Si todas son 0/1 constantes, usar 0.5 por defecto\n",
    "        if len(np.unique(y_true)) < 2:\n",
    "            thresholds[lbl] = 0.5\n",
    "            continue\n",
    "        # Buscar umbral que maximiza F1\n",
    "        # Probamos umbrales √∫nicos de p + bordes\n",
    "        cand = np.unique(np.r_[0.0, p, 1.0])\n",
    "        best_f1, best_t = -1.0, 0.5\n",
    "        for t in cand:\n",
    "            yhat = (p >= t).astype(int)\n",
    "            f1 = f1_score(y_true, yhat, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_t = f1, t\n",
    "        thresholds[lbl] = float(best_t)\n",
    "    # A√±adir las etiquetas sin proxy (usar 0.5)\n",
    "    for lbl in label_names:\n",
    "        if lbl not in thresholds:\n",
    "            thresholds[lbl] = 0.5\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(thresholds, f, indent=2)\n",
    "    print(f\"[INFO] Umbrales por etiqueta guardados en {save_path}\")\n",
    "    return thresholds\n",
    "\n",
    "def _load_or_learn_thresholds():\n",
    "    if os.path.exists(TH_FILE):\n",
    "        with open(TH_FILE, \"r\") as f:\n",
    "            th = json.load(f)\n",
    "        # Asegurar que est√°n todas las labels\n",
    "        for lbl in label_names:\n",
    "            th.setdefault(lbl, 0.5)\n",
    "        return th\n",
    "    # Aprender al vuelo desde el CSV\n",
    "    df_all = pd.read_csv(CSV)\n",
    "    return _learn_thresholds_f1(df_all, save_path=TH_FILE)\n",
    "\n",
    "label_thresholds = _load_or_learn_thresholds()\n",
    "\n",
    "def inferir_desde_features_dict(\n",
    "    feats: dict,\n",
    "    global_fallback_k=3,\n",
    "    global_fallback_min=0.25\n",
    "):\n",
    "    \"\"\"\n",
    "    - Aplica umbral ESPEC√çFICO por etiqueta (aprendido o 0.5).\n",
    "    - Si ninguna supera su umbral -> fallback: top-k ‚â• global_fallback_min (o top-1).\n",
    "    - Resuelve exclusiones mutuamente excluyentes conservando la etiqueta con mayor probabilidad.\n",
    "    Devuelve: (pred_labels, sugerencias, df_diag_ordenado)\n",
    "    \"\"\"\n",
    "    df1   = _as_dataframe_one(feats, feature_cols)\n",
    "    X_imp = imp.transform(df1)\n",
    "    X     = scaler.transform(X_imp)\n",
    "    probs = _predict_proba_matrix(X)[0]  # vector (L,)\n",
    "    prob_series = pd.Series(probs, index=label_names)\n",
    "\n",
    "    # Decisi√≥n por umbral espec√≠fico\n",
    "    decided = []\n",
    "    for lbl, p in prob_series.items():\n",
    "        t = label_thresholds.get(lbl, 0.5)\n",
    "        if p >= t:\n",
    "            decided.append(lbl)\n",
    "\n",
    "    # Fallback si nada supera su umbral\n",
    "    strategy = \"per-label thresholds\"\n",
    "    if len(decided) == 0:\n",
    "        strategy = f\"fallback(top-{global_fallback_k}, min={global_fallback_min})\"\n",
    "        topk = prob_series.sort_values(ascending=False)\n",
    "        decided = topk[topk >= global_fallback_min].head(global_fallback_k).index.tolist()\n",
    "        if len(decided) == 0 and len(topk) > 0:\n",
    "            decided = [topk.index[0]]\n",
    "\n",
    "    # Resolver exclusiones\n",
    "    selected = _enforce_mutex(decided, prob_series.to_dict())\n",
    "\n",
    "    # Construir diagn√≥stico ordenado\n",
    "    rows = []\n",
    "    for lbl in label_names:\n",
    "        rows.append({\n",
    "            \"label\": lbl,\n",
    "            \"prob\": float(prob_series[lbl]),\n",
    "            \"thr\": float(label_thresholds.get(lbl, 0.5)),\n",
    "            \"passes_thr\": lbl in decided,\n",
    "            \"selected_final\": lbl in selected,\n",
    "            \"group\": next((str(g) for g in mutex_groups if lbl in g), \"\")\n",
    "        })\n",
    "    diag = pd.DataFrame(rows).sort_values(\"prob\", ascending=False)\n",
    "\n",
    "    # Sugerencias ordenadas por prob\n",
    "    sugerencias = [label_to_text.get(lbl, lbl) for lbl in sorted(selected, key=lambda k: prob_series[k], reverse=True)]\n",
    "\n",
    "    # Imprimir resumen legible\n",
    "    print(\"\\n=== PROBABILIDADES (top 12) con umbral por etiqueta ===\")\n",
    "    print(diag.head(12)[[\"label\",\"prob\",\"thr\",\"passes_thr\",\"selected_final\",\"group\"]].to_string(index=False,\n",
    "          formatters={\"prob\": lambda v: f\"{v:0.3f}\", \"thr\": lambda v: f\"{v:0.3f}\"}))\n",
    "    print(f\"\\nEstrategia: {strategy}\")\n",
    "    print(\"Etiquetas finales:\", selected)\n",
    "    print(\"Sugerencias:\")\n",
    "    for s in sugerencias:\n",
    "        print(\" -\", s)\n",
    "\n",
    "    return selected, sugerencias, diag\n",
    "\n",
    "# === Ejemplo con un registro del CSV (fila 0) ===\n",
    "df_all = pd.read_csv(CSV)\n",
    "row0 = df_all.iloc[0].to_dict()\n",
    "feats0 = {c: row0[c] for c in feature_cols if c in row0}\n",
    "\n",
    "preds, suggs, diag = inferir_desde_features_dict(\n",
    "    feats0,\n",
    "    global_fallback_k=3,\n",
    "    global_fallback_min=0.25\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf1b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GUARDAR MODELO EN /models ===\n",
    "\n",
    "import os, json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline as SkPipeline\n",
    "\n",
    "# Rutas base\n",
    "BASE        = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "ART         = f\"{BASE}/artifacts\"\n",
    "MODELS_DIR  = f\"{BASE}/models\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# Cargar objetos desde memoria o desde /artifacts\n",
    "try:\n",
    "    imp\n",
    "    scaler\n",
    "    clf\n",
    "except NameError:\n",
    "    # Si no est√°n en el workspace actual, cargamos desde disco\n",
    "    imp_path    = f\"{ART}/imputer.joblib\"\n",
    "    scaler_path = f\"{ART}/scaler.joblib\"\n",
    "    clf_path    = f\"{ART}/model_ovr_logreg.joblib\"\n",
    "    assert os.path.exists(imp_path),    f\"Falta: {imp_path}\"\n",
    "    assert os.path.exists(scaler_path), f\"Falta: {scaler_path}\"\n",
    "    assert os.path.exists(clf_path),    f\"Falta: {clf_path}\"\n",
    "    imp    = joblib.load(imp_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    clf    = joblib.load(clf_path)\n",
    "\n",
    "#  Cargar columnas de features y nombres de etiquetas\n",
    "try:\n",
    "    feature_cols\n",
    "except NameError:\n",
    "    feat_path = f\"{ART}/feature_cols.csv\"\n",
    "    assert os.path.exists(feat_path), f\"Falta: {feat_path}\"\n",
    "    feature_cols = pd.read_csv(feat_path, header=None)[0].tolist()\n",
    "\n",
    "try:\n",
    "    label_names\n",
    "except NameError:\n",
    "    labels_path = f\"{ART}/label_names.csv\"\n",
    "    assert os.path.exists(labels_path), f\"Falta: {labels_path}\"\n",
    "    label_names = pd.read_csv(labels_path, header=None)[0].tolist()\n",
    "\n",
    "# Construir Pipeline y guardar\n",
    "pipe = SkPipeline([\n",
    "    (\"imputer\", imp),     # SimpleImputer ya ajustado\n",
    "    (\"scaler\",  scaler),  # RobustScaler ya ajustado\n",
    "    (\"clf\",     clf)      # OneVsRest(LogisticRegression) ya ajustado\n",
    "])\n",
    "\n",
    "pipe_path = f\"{MODELS_DIR}/pipeline_ovr_logreg.joblib\"\n",
    "joblib.dump(pipe, pipe_path)\n",
    "print(f\"‚úîÔ∏è Pipeline guardado en: {pipe_path}\")\n",
    "\n",
    "# Metadatos del pipeline\n",
    "meta = {\n",
    "    \"sklearn_version\": sklearn.__version__,\n",
    "    \"feature_cols\": list(feature_cols),\n",
    "    \"label_names\": list(label_names),\n",
    "    \"notes\": \"Pipeline con SimpleImputer + RobustScaler + OneVsRest(LogReg) entrenado.\"\n",
    "}\n",
    "meta_path = f\"{MODELS_DIR}/pipeline_metadata.json\"\n",
    "with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2, ensure_ascii=False)\n",
    "print(f\"‚úîÔ∏è Metadatos guardados en: {meta_path}\")\n",
    "\n",
    "# Ejemplo de carga r√°pida (opcional)\n",
    "try:\n",
    "    _ = X_raw  # si existe en el entorno actual\n",
    "except NameError:\n",
    "    # Si no tienes X_raw en memoria, puedes construirlo as√≠ (descomenta y ajusta):\n",
    "    # CSV = f\"{BASE}/data/processed/aistpp/features_coreograficos.csv\"\n",
    "    # assert os.path.exists(CSV), f\"No existe el CSV de features: {CSV}\"\n",
    "    # df = pd.read_csv(CSV)\n",
    "    # feature_cols_to_use = ['amplitud_x', 'amplitud_y', 'amplitud_z', 'velocidad_media',\n",
    "    #                       'simetria', 'nivel_rango', 'variedad_direcciones', 'frames']\n",
    "    # feature_cols_to_use = [col for col in feature_cols_to_use if col in df.columns]\n",
    "    # X_raw = df[feature_cols_to_use].copy()\n",
    "    X_raw = None\n",
    "\n",
    "\n",
    "pipe = joblib.load(pipe_path)\n",
    "\n",
    "def _align_features_df(df_in: pd.DataFrame, required_cols: list) -> pd.DataFrame:\n",
    "    \"\"\"Devuelve un DF con exactamente las columnas usadas en entrenamiento, en el mismo orden.\n",
    "       Columnas faltantes se rellenan con NaN (las tratar√° el Imputer).\"\"\"\n",
    "    df = pd.DataFrame(index=df_in.index)\n",
    "    for c in required_cols:\n",
    "        if c in df_in.columns:\n",
    "            df[c] = pd.to_numeric(df_in[c], errors=\"coerce\")\n",
    "        else:\n",
    "            df[c] = np.nan\n",
    "    return df[required_cols]\n",
    "\n",
    "# Si no tienes X_raw en memoria, carga el CSV y alin√©alo a feature_cols\n",
    "if 'X_raw' not in globals() or X_raw is None:\n",
    "    CSV = f\"{BASE}/data/processed/aistpp/features_coreograficos.csv\"\n",
    "    assert os.path.exists(CSV), f\"No existe el CSV de features: {CSV}\"\n",
    "    df_features = pd.read_csv(CSV)\n",
    "    X_raw = _align_features_df(df_features, feature_cols)\n",
    "else:\n",
    "    # Si ya existe X_raw, aseg√∫rate de que es DataFrame y alin√©alo\n",
    "    if isinstance(X_raw, np.ndarray):\n",
    "        # Si te pasaron un array, lo convertimos a DF sin nombres => no es v√°lido para verificaci√≥n de columnas\n",
    "        # Carga el CSV para obtener columnas y reemplaza X_raw por el dataset alineado\n",
    "        CSV = f\"{BASE}/data/processed/aistpp/features_coreograficos.csv\"\n",
    "        df_features = pd.read_csv(CSV)\n",
    "        X_raw = _align_features_df(df_features, feature_cols)\n",
    "    else:\n",
    "        X_raw = _align_features_df(X_raw, feature_cols)\n",
    "\n",
    "# Predicci√≥n ya con columnas correctas\n",
    "y_pred  = pipe.predict(X_raw)\n",
    "# predict_proba disponible con OneVsRest(LogReg)\n",
    "try:\n",
    "    y_proba = pipe.predict_proba(X_raw)\n",
    "except Exception:\n",
    "    # Fallback si no existiera predict_proba\n",
    "    if hasattr(pipe, \"decision_function\"):\n",
    "        logits = pipe.decision_function(X_raw)\n",
    "        y_proba = 1.0 / (1.0 + np.exp(-logits))\n",
    "    else:\n",
    "        y_proba = None\n",
    "\n",
    "print(\"Pred shape:\", y_pred.shape, \"| Proba shape:\", None if y_proba is None else y_proba.shape)\n",
    "print(\"‚úîÔ∏è Inferencia realizada con columnas alineadas:\", feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceafea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "BASE = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "ART  = f\"{BASE}/artifacts\"\n",
    "os.makedirs(ART, exist_ok=True)\n",
    "\n",
    "# Cargar artefactos de entrenamiento\n",
    "imp          = joblib.load(f\"{ART}/imputer.joblib\")\n",
    "scaler       = joblib.load(f\"{ART}/scaler.joblib\")\n",
    "model        = joblib.load(f\"{ART}/model_ovr_logreg.joblib\")\n",
    "feature_cols = pd.read_csv(f\"{ART}/feature_cols.csv\", header=None)[0].tolist()\n",
    "label_names  = pd.read_csv(f\"{ART}/label_names.csv\", header=None)[0].tolist()\n",
    "\n",
    "label_to_text = {\n",
    "    \"amplitud_baja\":      \"Aumentar amplitud (extensiones y desplazamientos m√°s amplios).\",\n",
    "    \"variedad_baja\":      \"Introducir cambios de direcci√≥n y diagonales.\",\n",
    "    \"mucha_simetria\":     \"Explorar asimetr√≠as entre izquierda y derecha.\",\n",
    "    \"poca_simetria\":      \"Equilibrar con momentos de simetr√≠a.\",\n",
    "    \"fluidez_baja\":       \"Trabajar transiciones para mayor continuidad/fluidez.\",\n",
    "    \"poco_rango_niveles\": \"Usar niveles alto y bajo adem√°s del medio.\",\n",
    "}\n",
    "\n",
    "def get_pairs(J):\n",
    "    # COCO-17 (YOLO-Pose): hombros/codos/mu√±ecas/caderas/rodillas/tobillos\n",
    "    return [(5,6),(7,8),(9,10),(11,12),(13,14),(15,16)]\n",
    "\n",
    "def center_of_mass(K):\n",
    "    # COCO: caderas 11 y 12\n",
    "    T,J,D = K.shape\n",
    "    if J >= 13:\n",
    "        return (K[:,11,:] + K[:,12,:]) / 2\n",
    "    return K.mean(axis=1)\n",
    "\n",
    "def features_coreograficos(K):\n",
    "    T,J,D = K.shape\n",
    "    amp_mean = (np.nanmax(K,axis=0) - np.nanmin(K,axis=0)).mean(axis=0)\n",
    "    amp_x = float(amp_mean[0]); amp_y = float(amp_mean[1])\n",
    "    amp_z = float(amp_mean[2]) if D==3 else np.nan\n",
    "    vel = np.linalg.norm(np.diff(K,axis=0),axis=2)\n",
    "    vel_media = float(np.nanmean(vel)) if vel.size else 0.0\n",
    "    pair_vals=[]\n",
    "    for a,b in get_pairs(J):\n",
    "        if a<J and b<J:\n",
    "            diff = K[:,a,:]-K[:,b,:]\n",
    "            if diff.ndim > 1:\n",
    "                d = np.linalg.norm(diff,axis=1).mean() # Correct axis for (T, D) -> (T,)\n",
    "                pair_vals.append(np.nanmean(d))\n",
    "            elif diff.ndim == 1: # Handle case where diff is 1D (T,)\n",
    "                 d = np.linalg.norm(diff).mean()\n",
    "                 pair_vals.append(np.nanmean(d))\n",
    "    sim_raw = float(np.nanmean(pair_vals)) if pair_vals else np.nan\n",
    "    com = center_of_mass(K)\n",
    "    nivel_p10 = float(np.nanpercentile(com[:,1],10))\n",
    "    nivel_p90 = float(np.nanpercentile(com[:,1],90))\n",
    "    nivel_rango = float(nivel_p10 - nivel_p90)\n",
    "    disp = np.diff(com,axis=0)\n",
    "    dirs = np.arctan2(disp[:,1], disp[:,0] + 1e-9)\n",
    "    cambios = np.abs(np.diff(dirs))\n",
    "    variedad_dir = float(np.nanmean(cambios)) if len(cambios)>0 else 0.0\n",
    "    return {\n",
    "        \"amp_x\": amp_x, \"amp_y\": amp_y, \"amp_z\": amp_z,\n",
    "        \"vel_media\": vel_media,\n",
    "        \"simetria_raw\": sim_raw,\n",
    "        \"nivel_rango\": nivel_rango,\n",
    "        \"variedad_dir\": variedad_dir,\n",
    "        \"frames\": int(T), \"joints\": int(J), \"dims\": int(D)\n",
    "    }\n",
    "\n",
    "def inferir_desde_features_dict(feats: dict):\n",
    "    x = np.array([[feats.get(c, np.nan) for c in feature_cols]], dtype=float)\n",
    "    x = scaler.transform(imp.transform(x))\n",
    "    yhat = model.predict(x)[0]\n",
    "    pred_labels = [label_names[i] for i,v in enumerate(yhat) if v==1]\n",
    "    sugerencias = [label_to_text.get(lbl, lbl) for lbl in pred_labels]\n",
    "    return pred_labels, sugerencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Carpeta donde quieres guardar los pesos .pt\n",
    "BASE = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "MODELS_DIR = f\"{BASE}/models\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "def _resolve_downloaded_weight_path(model_obj, model_name: str):\n",
    "    \"\"\"\n",
    "    Intenta localizar en disco el .pt que YOLO descarg√≥ al crear el modelo.\n",
    "    \"\"\"\n",
    "    # 1) Atributo t√≠pico en Ultralytics v8\n",
    "    p = getattr(model_obj, \"ckpt_path\", None)\n",
    "    if isinstance(p, str) and os.path.exists(p):\n",
    "        return p\n",
    "\n",
    "    # 2) B√∫squeda en caches comunes\n",
    "    candidates_roots = [\n",
    "        os.path.expanduser(\"~/.cache/ultralytics\"),\n",
    "        os.path.expanduser(\"~/.cache/torch/hub\"),\n",
    "        os.path.expanduser(\"~/.cache\"),\n",
    "        \"/root/.cache\",\n",
    "        \"/content\",\n",
    "    ]\n",
    "    for root in candidates_roots:\n",
    "        try:\n",
    "            for hit in glob.glob(os.path.join(root, \"**\", model_name), recursive=True):\n",
    "                if os.path.isfile(hit):\n",
    "                    return hit\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 3) No encontrado\n",
    "    return None\n",
    "\n",
    "def _load_or_download_yolo(model_name: str, save_dir: str):\n",
    "    \"\"\"\n",
    "    Si el peso existe en save_dir, lo carga desde ah√≠.\n",
    "    Si no existe, instancia YOLO(model_name) para forzar descarga,\n",
    "    luego copia el .pt descargado a save_dir y devuelve el modelo cargado desde ah√≠.\n",
    "    \"\"\"\n",
    "    target_path = os.path.join(save_dir, model_name)\n",
    "    if os.path.exists(target_path):\n",
    "        # Cargar directamente desde el archivo ya guardado en Drive\n",
    "        return YOLO(target_path), target_path\n",
    "\n",
    "    # Forzar descarga (YOLO gestiona la descarga al instanciar con el nombre)\n",
    "    tmp_model = YOLO(model_name)\n",
    "    resolved = _resolve_downloaded_weight_path(tmp_model, model_name)\n",
    "\n",
    "    if resolved and os.path.exists(resolved):\n",
    "        # Copiar a tu carpeta de modelos en Drive\n",
    "        shutil.copy2(resolved, target_path)\n",
    "        print(f\"‚úîÔ∏è Peso descargado y copiado a: {target_path}\")\n",
    "        # Cargar desde la ruta destino (para que desde ahora siempre use ese .pt)\n",
    "        return YOLO(target_path), target_path\n",
    "    else:\n",
    "        # Si no logramos resolver el archivo, seguimos usando el objeto ya cargado\n",
    "        print(\" No se pudo resolver la ruta f√≠sica del .pt descargado; \"\n",
    "              \"se usar√° el modelo en memoria. (Se intent√≥ buscar en caches comunes).\")\n",
    "        return tmp_model, None\n",
    "\n",
    "def video_to_keypoints_yolo(\n",
    "    video_path,\n",
    "    model_name=\"yolov8n-pose.pt\",\n",
    "    conf=0.25,\n",
    "    iou=0.5,\n",
    "    stride=1,\n",
    "    max_people=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Extrae keypoints COCO-17 (x,y,score) por frame usando YOLOv8 Pose.\n",
    "    Devuelve:\n",
    "      - kpts_main: (N, 17, 3) de la persona principal\n",
    "      - fps: frames por segundo del v√≠deo\n",
    "    \"\"\"\n",
    "    assert os.path.exists(video_path), f\"No existe el video: {video_path}\"\n",
    "\n",
    "    # Cargar/descargar y guardar en MODELS_DIR\n",
    "    model, weight_path = _load_or_download_yolo(model_name, MODELS_DIR)\n",
    "    if weight_path:\n",
    "        print(f\"Usando pesos desde: {weight_path}\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"No se pudo abrir el video: {video_path}\")\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "\n",
    "    frames = []\n",
    "    idx = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        if (idx % max(1, stride)) != 0:\n",
    "            idx += 1\n",
    "            continue\n",
    "\n",
    "        # Inferencia por frame\n",
    "        res = model.predict(source=frame, conf=conf, iou=iou, verbose=False)\n",
    "        kpts_list = []\n",
    "        if len(res) and hasattr(res[0], \"keypoints\") and res[0].keypoints is not None:\n",
    "            xy = res[0].keypoints.xy\n",
    "            cf = res[0].keypoints.conf\n",
    "            xy = xy.cpu().numpy() if hasattr(xy, \"cpu\") else np.asarray(xy)\n",
    "            if cf is None:\n",
    "                cf = np.ones_like(xy[..., 0])\n",
    "            else:\n",
    "                cf = cf.cpu().numpy() if hasattr(cf, \"cpu\") else np.asarray(cf)\n",
    "\n",
    "            for i in range(xy.shape[0]):\n",
    "                # (17,2) + (17,1) -> (17,3)\n",
    "                k = np.concatenate([xy[i], cf[i][..., None]], axis=-1)\n",
    "                kpts_list.append(k)\n",
    "\n",
    "        if kpts_list:\n",
    "            # elige persona principal por mayor score medio\n",
    "            scores = []\n",
    "            for k in kpts_list:\n",
    "                # Calcular score medio, manejando posibles NaN\n",
    "                valid_scores = k[:, 2][~np.isnan(k[:, 2])]\n",
    "                if len(valid_scores) > 0:\n",
    "                    scores.append(np.mean(valid_scores))\n",
    "                else:\n",
    "                    scores.append(-np.inf)  # Si todos son NaN, usar -infinito\n",
    "\n",
    "            # Verificar que haya al menos un score v√°lido\n",
    "            if not all(score == -np.inf for score in scores):\n",
    "                main = kpts_list[np.argmax(scores)]\n",
    "                frames.append(main)\n",
    "            else:\n",
    "                # Si todos los scores son inv√°lidos, agregar array de NaN\n",
    "                frames.append(np.full((17, 3), np.nan))\n",
    "        else:\n",
    "            # Si no hay detecciones, agregar array de NaN\n",
    "            frames.append(np.full((17, 3), np.nan))\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    if not frames:\n",
    "        return None, fps\n",
    "    return np.stack(frames, axis=0), fps\n",
    "\n",
    "\n",
    "# --- EJEMPLO DE USO ---\n",
    "demo_path = f\"{BASE}/demo/solo.mp4\"\n",
    "kpts, fps = video_to_keypoints_yolo(demo_path, model_name=\"yolov8n-pose.pt\", conf=0.25, stride=1)\n",
    "print(\"FPS:\", fps)\n",
    "print(\"Keypoints shape:\", None if kpts is None else kpts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona una sola persona por frame (la de mayor √°rea de bounding box).\n",
    "# Devuelve K con forma (T, 17, 2) en p√≠xeles.\n",
    "# Si no detecta a nadie en un frame, deja NaN para ese frame (luego interpolamos).\n",
    "\n",
    "import cv2, numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def video_to_keypoints_yolo(video_path, model_name=\"yolov8n-pose.pt\", conf=0.25, stride=1):\n",
    "    \"\"\"\n",
    "    Devuelve K: (T, 17, 2) en p√≠xeles (x,y) con NaNs si no hay detecci√≥n.\n",
    "    Selecciona la persona con mayor caja por frame.\n",
    "    \"\"\"\n",
    "    model = YOLO(model_name)  # descarga autom√°tica del modelo\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), f\"No se pudo abrir el v√≠deo: {video_path}\"\n",
    "\n",
    "    T = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    FPS = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "\n",
    "    J = 17  # COCO-17 en YOLO-Pose\n",
    "    K = np.full((T, J, 2), np.nan, dtype=np.float32)\n",
    "\n",
    "    t = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        if t % stride != 0:\n",
    "            t += 1\n",
    "            continue\n",
    "\n",
    "        # Predicci√≥n\n",
    "        res = model.predict(frame, conf=conf, verbose=False)[0]\n",
    "        if res.boxes is not None and len(res.boxes) > 0 and res.keypoints is not None:\n",
    "            # Elegir persona con caja m√°s grande\n",
    "            boxes = res.boxes.xyxy.cpu().numpy()  # (N,4)\n",
    "            areas = (boxes[:,2]-boxes[:,0]) * (boxes[:,3]-boxes[:,1])\n",
    "            idx = int(np.argmax(areas))\n",
    "            kps = res.keypoints.xy[idx].cpu().numpy()  # (17,2) en p√≠xeles\n",
    "            # Algunos modelos devuelven flotantes fuera de imagen; clamp suave\n",
    "            kps[:,0] = np.clip(kps[:,0], 0, W-1)\n",
    "            kps[:,1] = np.clip(kps[:,1], 0, H-1)\n",
    "            K[t] = kps\n",
    "\n",
    "        t += 1\n",
    "\n",
    "    cap.release()\n",
    "    return K, FPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abce6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== limpieza NaNs + features + overlay + EJECUCI√ìN =====\n",
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import joblib\n",
    "\n",
    "# --- Rutas base ---\n",
    "BASE = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "ART  = f\"{BASE}/artifacts\"\n",
    "OUT  = f\"{BASE}/data/processed/aistpp\"\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "# --- Utilidades NaN ---\n",
    "def interpolate_nan_1d(y):\n",
    "    y = y.astype(np.float32)\n",
    "    T = len(y); idx = np.arange(T)\n",
    "    mask = np.isfinite(y)\n",
    "    if mask.sum() == 0: return y\n",
    "    last = np.nan\n",
    "    for i in range(T):\n",
    "        if not np.isfinite(y[i]) and np.isfinite(last): y[i] = last\n",
    "        else: last = y[i]\n",
    "    last = np.nan\n",
    "    for i in range(T-1, -1, -1):\n",
    "        if not np.isfinite(y[i]) and np.isfinite(last): y[i] = last\n",
    "        else: last = y[i]\n",
    "    mask = np.isfinite(y)\n",
    "    if 2 <= mask.sum() < T:\n",
    "        y[~mask] = np.interp(idx[~mask], idx[mask], y[mask])\n",
    "    return y\n",
    "\n",
    "def clean_nan_interpolate(K, min_valid_ratio=0.10):\n",
    "    if K is None or len(K) == 0:\n",
    "        return None, []\n",
    "    Kc = K.copy()\n",
    "    T,J,D = Kc.shape\n",
    "    used = []\n",
    "    for j in range(J):\n",
    "        valid = np.isfinite(Kc[:,j,:]).all(axis=1)\n",
    "        if valid.mean() < min_valid_ratio:\n",
    "            Kc[:,j,:] = np.nan\n",
    "            continue\n",
    "        for d in range(D):\n",
    "            Kc[:,j,d] = interpolate_nan_1d(Kc[:,j,d])\n",
    "        used.append(j)\n",
    "    if not used: return Kc, []\n",
    "    return Kc[:,used,:], used\n",
    "\n",
    "# --- Esqueleto COCO-17 (pares b√°sicos brazo/torso/pierna) ---\n",
    "COCO_EDGES = [(5,7),(7,9),(6,8),(8,10),(11,13),(13,15),\n",
    "              (12,14),(14,16),(5,6),(11,12),(5,11),(6,12)]\n",
    "\n",
    "# --- Dibujo de overlay (corrige desempaquetado x,y,score) ---\n",
    "def overlay_suggestions_on_video(video_path, K, timeline, out_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), f\"No se pudo abrir el v√≠deo: {video_path}\"\n",
    "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    FPS = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    vw = cv2.VideoWriter(out_path, fourcc, FPS, (W,H))\n",
    "\n",
    "    t = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok: break\n",
    "\n",
    "        if K is not None and t < len(K):\n",
    "            P = K[t]  # (J,3) -> x,y,score\n",
    "            # esqueleto\n",
    "            for a,b in COCO_EDGES:\n",
    "                if a < P.shape[0] and b < P.shape[0]:\n",
    "                    xa,ya = P[a,:2]; xb,yb = P[b,:2]\n",
    "                    if np.isfinite(xa) and np.isfinite(ya) and np.isfinite(xb) and np.isfinite(yb):\n",
    "                        cv2.line(frame, (int(xa),int(ya)), (int(xb),int(yb)), (255,255,255), 2)\n",
    "            for j in range(P.shape[0]):\n",
    "                x,y = P[j,:2]\n",
    "                if np.isfinite(x) and np.isfinite(y):\n",
    "                    cv2.circle(frame, (int(x),int(y)), 2, (255,255,255), -1)\n",
    "\n",
    "        # sugerencias activas en frame t\n",
    "        active = []\n",
    "        for seg in timeline:\n",
    "            if seg[\"start_f\"] <= t <= seg[\"end_f\"]:\n",
    "                active = seg.get(\"sugerencias\", [])\n",
    "        y0 = 30\n",
    "        for s in active[:4]:\n",
    "            cv2.putText(frame, f\"‚Ä¢ {s}\", (20, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 4, cv2.LINE_AA)\n",
    "            cv2.putText(frame, f\"‚Ä¢ {s}\", (20, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "            y0 += 28\n",
    "\n",
    "        vw.write(frame); t += 1\n",
    "\n",
    "    cap.release(); vw.release()\n",
    "    return out_path\n",
    "\n",
    "# --- Features simples desde COCO-2D (coherentes con tu set b√°sico) ---\n",
    "def features_coreograficos(Kw):\n",
    "    \"\"\"\n",
    "    Kw: (T,J,3) con NaNs posibles\n",
    "    Devuelve dict con claves usadas por tu pipeline cl√°sico.\n",
    "    \"\"\"\n",
    "    T,J,D = Kw.shape\n",
    "    xy = Kw[:,:,:2]\n",
    "    # amplitudes globales (rango global X/Y)\n",
    "    amp_x = float(np.nanmax(xy[:,:,0]) - np.nanmin(xy[:,:,0])) if np.isfinite(xy[:,:,0]).any() else 0.0\n",
    "    amp_y = float(np.nanmax(xy[:,:,1]) - np.nanmin(xy[:,:,1])) if np.isfinite(xy[:,:,1]).any() else 0.0\n",
    "    # velocidad media (norma frame-to-frame)\n",
    "    if T > 1:\n",
    "        vel = np.linalg.norm(np.diff(xy, axis=0), axis=2)  # (T-1,J)\n",
    "        vel_media = float(np.nanmean(vel))\n",
    "    else:\n",
    "        vel_media = 0.0\n",
    "    # simetr√≠a (distancias medias entre pares L-R)\n",
    "    pairs = [(5,6),(7,8),(9,10),(11,12),(13,14),(15,16)]\n",
    "    dists = []\n",
    "    for a,b in pairs:\n",
    "        if a < J and b < J:\n",
    "            d = np.linalg.norm(xy[:,a,:] - xy[:,b,:], axis=1)\n",
    "            dists.append(np.nanmean(d))\n",
    "    simetria = float(np.nanmean(dists)) if len(dists) else np.nan\n",
    "    # centro de masa (cadera aprox: 11,12) y rango de niveles\n",
    "    if J > 12:\n",
    "        com = (xy[:,11,:] + xy[:,12,:]) / 2.0\n",
    "    else:\n",
    "        com = np.nanmean(xy, axis=1)\n",
    "    if np.isfinite(com[:,1]).any():\n",
    "        p10 = float(np.nanpercentile(com[:,1], 10))\n",
    "        p90 = float(np.nanpercentile(com[:,1], 90))\n",
    "        nivel_rango = float(p10 - p90)\n",
    "    else:\n",
    "        nivel_rango = 0.0\n",
    "    # variedad direcciones (cambios de √°ngulo de la trayectoria del COM)\n",
    "    if T > 2:\n",
    "        disp = np.diff(com, axis=0)\n",
    "        dirs = np.arctan2(disp[:,1], disp[:,0] + 1e-9)\n",
    "        cambios = np.abs(np.diff(dirs))\n",
    "        variedad_dir = float(np.nanmean(cambios)) if len(cambios)>0 else 0.0\n",
    "    else:\n",
    "        variedad_dir = 0.0\n",
    "\n",
    "    return {\n",
    "        \"amplitud_x\": amp_x,\n",
    "        \"amplitud_y\": amp_y,\n",
    "        \"velocidad_media\": vel_media,\n",
    "        \"simetria\": simetria,\n",
    "        \"nivel_rango\": nivel_rango,\n",
    "        \"variedad_direcciones\": variedad_dir,\n",
    "        \"frames\": int(T),\n",
    "        \"joints\": int(J),\n",
    "        \"dims\": int(D)\n",
    "    }\n",
    "\n",
    "# --- Inferencia con artefactos guardados (pipeline o piezas sueltas) ---\n",
    "def inferir_desde_features_dict(feats: dict):\n",
    "    \"\"\"\n",
    "    Carga pipeline_ovr_logreg.joblib si existe; si no, usa imp+scaler+clf.\n",
    "    Devuelve (labels_activas, sugerencias_texto)\n",
    "    \"\"\"\n",
    "    # Cargar metadatos\n",
    "    feature_cols_path = os.path.join(ART, \"feature_cols.csv\")\n",
    "    label_names_path  = os.path.join(ART, \"label_names.csv\")\n",
    "    if os.path.exists(feature_cols_path):\n",
    "        feat_cols = pd.read_csv(feature_cols_path, header=None)[0].tolist()\n",
    "    else:\n",
    "        feat_cols = list(feats.keys())\n",
    "    if os.path.exists(label_names_path):\n",
    "        labels_all = pd.read_csv(label_names_path, header=None)[0].tolist()\n",
    "    else:\n",
    "        labels_all = []\n",
    "\n",
    "    # Preparar vector en orden correcto\n",
    "    x = np.array([[feats.get(c, np.nan) for c in feat_cols]], dtype=float)\n",
    "\n",
    "    # Intentar pipeline completo\n",
    "    pipe_path = os.path.join(BASE, \"models\", \"pipeline_ovr_logreg.joblib\")\n",
    "    if os.path.exists(pipe_path):\n",
    "        pipe = joblib.load(pipe_path)\n",
    "        yhat = pipe.predict(x)[0]\n",
    "    else:\n",
    "        # Piezas sueltas\n",
    "        imp_path  = os.path.join(ART, \"imputer.joblib\")\n",
    "        scl_path  = os.path.join(ART, \"scaler.joblib\")\n",
    "        clf_path  = os.path.join(ART, \"model_ovr_logreg.joblib\")\n",
    "        assert all(os.path.exists(p) for p in [imp_path, scl_path, clf_path]), \\\n",
    "            \"No se encontraron artefactos de modelo en artifacts/ ni pipeline en models/.\"\n",
    "        imp    = joblib.load(imp_path)\n",
    "        scaler = joblib.load(scl_path)\n",
    "        clf    = joblib.load(clf_path)\n",
    "        x = scaler.transform(imp.transform(x))\n",
    "        yhat = clf.predict(x)[0]\n",
    "\n",
    "    # Mapear a texto (fallback simple si no hay mapa)\n",
    "    label_to_text = {\n",
    "        \"amplitud_baja\":      \"Aumentar amplitud (extensiones y desplazamientos m√°s amplios).\",\n",
    "        \"variedad_baja\":      \"Introducir cambios de direcci√≥n y diagonales.\",\n",
    "        \"mucha_simetria\":     \"Explorar asimetr√≠as entre izquierda y derecha.\",\n",
    "        \"poca_simetria\":      \"Equilibrar con momentos de simetr√≠a.\",\n",
    "        \"fluidez_baja\":       \"Trabajar transiciones para mayor continuidad/fluidez.\",\n",
    "        \"poco_rango_niveles\": \"Usar niveles alto y bajo adem√°s del medio.\",\n",
    "        \"exceso_rango_niveles\": \"Reducir rango vertical para mayor cohesi√≥n.\",\n",
    "        \"frase_corta\":        \"Frase corta: considerar repetici√≥n o desarrollo del material.\"\n",
    "    }\n",
    "    active_labels = []\n",
    "    suggs = []\n",
    "    names = labels_all if labels_all else [f\"label_{i}\" for i in range(len(yhat))]\n",
    "    for i, v in enumerate(yhat):\n",
    "        if v == 1:\n",
    "            lbl = names[i]\n",
    "            active_labels.append(lbl)\n",
    "            suggs.append(label_to_text.get(lbl, f\"Mejorar {lbl}\"))\n",
    "\n",
    "    return active_labels, suggs\n",
    "\n",
    "# --- Pipeline de v√≠deo con YOLO (usa tu funci√≥n existente de keypoints) ---\n",
    "def run_inference_over_video_yolo(video_path, model_name=\"yolov8n-pose.pt\",\n",
    "                                  conf=0.25, stride=1, win_sec=5.0, hop_sec=2.5):\n",
    "    # Necesita que video_to_keypoints_yolo ya est√© definida en una celda anterior\n",
    "    assert 'video_to_keypoints_yolo' in globals(), \"Define primero video_to_keypoints_yolo(...)\"\n",
    "    K, FPS = video_to_keypoints_yolo(video_path, model_name=model_name, conf=conf, stride=stride)\n",
    "\n",
    "    if K is None or len(K) == 0:\n",
    "        print(\" Sin detecciones v√°lidas (K es None o vac√≠o). Revisa conf/iluminaci√≥n/escala.\")\n",
    "        return None\n",
    "\n",
    "    Kc, used = clean_nan_interpolate(K, min_valid_ratio=0.10)\n",
    "    if not used:\n",
    "        print(\" No hay articulaciones v√°lidas tras limpieza. Prueba bajar 'conf' o un modelo m√°s grande (yolov8s-pose).\")\n",
    "        return None\n",
    "\n",
    "    win = max(1, int(round(win_sec * FPS)))\n",
    "    hop = max(1, int(round(hop_sec * FPS)))\n",
    "    T = len(Kc)\n",
    "\n",
    "    rows = []; timeline=[]\n",
    "    for start in range(0, T-1, hop):\n",
    "        end = min(T-1, start + win)\n",
    "        if end - start < max(8, int(0.25*win)): break\n",
    "        Kw = Kc[start:end]\n",
    "        feats = features_coreograficos(Kw)\n",
    "        labels, suggs = inferir_desde_features_dict(feats)\n",
    "        timeline.append({\"start_f\":start, \"end_f\":end, \"sugerencias\":suggs, \"labels\":labels})\n",
    "        row = {\"start_f\":start, \"end_f\":end, \"start_s\":start/FPS, \"end_s\":end/FPS}\n",
    "        row.update(feats); row[\"labels\"]=\"|\".join(labels); row[\"sugerencias\"]=\"|\".join(suggs)\n",
    "        rows.append(row)\n",
    "\n",
    "    out_csv = os.path.join(OUT, \"timeline_sugerencias_yolo.csv\")\n",
    "    pd.DataFrame(rows).to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    out_mp4 = os.path.join(OUT, \"video_anotado_yolo.mp4\")\n",
    "    overlay_suggestions_on_video(video_path, Kc, timeline, out_mp4)\n",
    "\n",
    "    print(\"Listo\")\n",
    "    print(\"CSV:\", out_csv)\n",
    "    print(\"V√≠deo:\", out_mp4)\n",
    "    return {\"csv\": out_csv, \"video\": out_mp4, \"timeline\": timeline}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_primeras_anotaciones(res, n=10):\n",
    "    assert res is not None, \"res es None: ¬øse ejecut√≥ run_inference_over_video_yolo?\"\n",
    "    filas = []\n",
    "\n",
    "    # Intentar desde el timeline en memoria (si existe)\n",
    "    if \"timeline\" in res and isinstance(res[\"timeline\"], list) and len(res[\"timeline\"]) > 0:\n",
    "        tl = res[\"timeline\"][:n]\n",
    "        for i, seg in enumerate(tl):\n",
    "            start_f = seg.get(\"start_f\")\n",
    "            end_f   = seg.get(\"end_f\")\n",
    "            # Si adem√°s tienes start_s/end_s en CSV, lo mostraremos abajo.\n",
    "            suger = seg.get(\"sugerencias\") or seg.get(\"sugerencias_single\") or seg.get(\"sugerencias_global\") or []\n",
    "            labels = seg.get(\"labels\") or []\n",
    "            filas.append({\n",
    "                \"i\": i,\n",
    "                \"start_f\": start_f,\n",
    "                \"end_f\": end_f,\n",
    "                \"labels\": \" ¬∑ \".join(labels) if isinstance(labels, list) else str(labels),\n",
    "                \"sugerencias\": \" ¬∑ \".join(suger) if isinstance(suger, list) else str(suger)\n",
    "            })\n",
    "\n",
    "    # Completar con el CSV para tener tiempos en segundos y features\n",
    "    if \"csv\" in res and res[\"csv\"] and os.path.exists(res[\"csv\"]):\n",
    "        df = pd.read_csv(res[\"csv\"])\n",
    "        # Columnas interesantes si existen\n",
    "        cols_base = [c for c in [\"start_s\",\"end_s\",\"labels\",\"sugerencias\",\n",
    "                                 \"amp_x\",\"amp_y\",\"vel_media\",\"simetria_raw\",\"nivel_rango\",\"variedad_dir\"]\n",
    "                     if c in df.columns]\n",
    "        df_preview = df[cols_base].head(n).copy()\n",
    "\n",
    "        # Limpieza visual de listas en texto\n",
    "        for c in [\"labels\",\"sugerencias\"]:\n",
    "            if c in df_preview.columns:\n",
    "                df_preview[c] = df_preview[c].fillna(\"\").astype(str).apply(\n",
    "                    lambda s: \" ¬∑ \".join([x.strip() for x in s.split(\"|\") if x.strip()])[:300]\n",
    "                )\n",
    "\n",
    "        print(\"=== Primeras ventanas (desde CSV) ===\")\n",
    "        display(df_preview)\n",
    "\n",
    "        # Adem√°s, un resumen legible en texto:\n",
    "        print(\"\\nResumen (texto):\")\n",
    "        for i, row in df_preview.iterrows():\n",
    "            st = row.get(\"start_s\", 0.0); et = row.get(\"end_s\", 0.0)\n",
    "            print(f\"[{i}] {st:6.2f}s ‚Üí {et:6.2f}s\")\n",
    "            if \"sugerencias\" in df_preview.columns and str(row.get(\"sugerencias\",\"\")).strip():\n",
    "                for s in str(row[\"sugerencias\"]).split(\" ¬∑ \"):\n",
    "                    if s.strip():\n",
    "                        print(\"   -\", s.strip())\n",
    "            elif \"labels\" in df_preview.columns and str(row.get(\"labels\",\"\")).strip():\n",
    "                for lab in str(row[\"labels\"]).split(\" ¬∑ \"):\n",
    "                    if lab.strip():\n",
    "                        print(\"   -\", lab.strip())\n",
    "            print()\n",
    "\n",
    "    elif filas:\n",
    "        # Si no hay CSV, al menos muestra lo que haya en memoria\n",
    "        df_mem = pd.DataFrame(filas)\n",
    "        print(\"=== Primeras ventanas (desde res['timeline']) ===\")\n",
    "        display(df_mem)\n",
    "        print(\"\\nResumen (texto):\")\n",
    "        for _, r in df_mem.iterrows():\n",
    "            print(f\"[{int(r['i'])}] f{int(r['start_f'])} ‚Üí f{int(r['end_f'])}\")\n",
    "            if str(r.get(\"sugerencias\",\"\")).strip():\n",
    "                for s in str(r[\"sugerencias\"]).split(\" ¬∑ \"):\n",
    "                    if s.strip():\n",
    "                        print(\"   -\", s.strip())\n",
    "            elif str(r.get(\"labels\",\"\")).strip():\n",
    "                for lab in str(r[\"labels\"]).split(\" ¬∑ \"):\n",
    "                    if lab.strip():\n",
    "                        print(\"   -\", lab.strip())\n",
    "            print()\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No encontr√© timeline en memoria ni CSV en res['csv'].\")\n",
    "\n",
    "# --- Usa la funci√≥n con tu 'res' ---\n",
    "preview_primeras_anotaciones(res, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde7a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "ART  = f\"{BASE}/artifacts\"\n",
    "os.makedirs(ART, exist_ok=True)\n",
    "\n",
    "# Carga artefactos (entrenados previamente con tu CSV)\n",
    "imp          = joblib.load(f\"{ART}/imputer.joblib\")\n",
    "scaler       = joblib.load(f\"{ART}/scaler.joblib\")\n",
    "model        = joblib.load(f\"{ART}/model_ovr_logreg.joblib\")\n",
    "feature_cols = pd.read_csv(f\"{ART}/feature_cols.csv\", header=None)[0].tolist()\n",
    "label_names  = pd.read_csv(f\"{ART}/label_names.csv\", header=None)[0].tolist()\n",
    "\n",
    "label_to_text = {\n",
    "    \"amplitud_baja\":      \"Aumentar amplitud (extensiones y desplazamientos m√°s amplios).\",\n",
    "    \"variedad_baja\":      \"Introducir cambios de direcci√≥n y diagonales.\",\n",
    "    \"mucha_simetria\":     \"Explorar asimetr√≠as entre izquierda y derecha.\",\n",
    "    \"poca_simetria\":      \"Equilibrar con momentos de simetr√≠a.\",\n",
    "    \"fluidez_baja\":       \"Trabajar transiciones para mayor continuidad/fluidez.\",\n",
    "    \"poco_rango_niveles\": \"Usar niveles alto y bajo adem√°s del medio.\",\n",
    "}\n",
    "\n",
    "# --- pares izquierda/derecha COCO-17 ---\n",
    "COCO_EDGES = [(5,7),(7,9),(6,8),(8,10),(11,13),(13,15),(12,14),(14,16),(5,6),(11,12),(5,11),(6,12)]\n",
    "COCO_PAIRS = [(5,6),(7,8),(9,10),(11,12),(13,14),(15,16)]\n",
    "\n",
    "def center_of_mass(K):\n",
    "    # COCO: caderas 11 y 12 si existen\n",
    "    T,J,D = K.shape\n",
    "    if J >= 13:\n",
    "        return (K[:,11,:] + K[:,12,:]) / 2\n",
    "    return K.mean(axis=1)\n",
    "\n",
    "def features_coreograficos(K):\n",
    "    \"\"\"K: (T,J,D) con NaNs posibles, devuelve dict de features.\"\"\"\n",
    "    T,J,D = K.shape\n",
    "    amp_mean = (np.nanmax(K,axis=0) - np.nanmin(K,axis=0)).mean(axis=0)\n",
    "    amp_x = float(amp_mean[0]); amp_y = float(amp_mean[1])\n",
    "    amp_z = float(amp_mean[2]) if D==3 else np.nan\n",
    "    vel = np.linalg.norm(np.diff(K,axis=0),axis=2)\n",
    "    vel_media = float(np.nanmean(vel)) if vel.size else 0.0\n",
    "    pair_vals=[]\n",
    "    for a,b in COCO_PAIRS:\n",
    "        if a<J and b<J:\n",
    "            diff = K[:,a,:]-K[:,b,:]\n",
    "            # Check number of dimensions before calculating norm\n",
    "            if diff.ndim > 1:\n",
    "                d = np.linalg.norm(diff,axis=1).mean() # Correct axis for (T, D) -> (T,)\n",
    "                pair_vals.append(np.nanmean(d))\n",
    "            elif diff.ndim == 1: # Handle case where diff is 1D (T,)\n",
    "                 d = np.linalg.norm(diff).mean()\n",
    "                 pair_vals.append(np.nanmean(d))\n",
    "    sim_raw = float(np.nanmean(pair_vals)) if pair_vals else np.nan\n",
    "    com = center_of_mass(K)\n",
    "    nivel_p10 = float(np.nanpercentile(com[:,1],10))\n",
    "    nivel_p90 = float(np.nanpercentile(com[:,1],90))\n",
    "    nivel_rango = float(nivel_p10 - nivel_p90)\n",
    "    disp = np.diff(com,axis=0)\n",
    "    dirs = np.arctan2(disp[:,1], disp[:,0] + 1e-9)\n",
    "    cambios = np.abs(np.diff(dirs))\n",
    "    variedad_dir = float(np.nanmean(cambios)) if len(cambios)>0 else 0.0\n",
    "    return {\n",
    "        \"amp_x\": amp_x, \"amp_y\": amp_y, \"amp_z\": amp_z,\n",
    "        \"vel_media\": vel_media,\n",
    "        \"simetria_raw\": sim_raw,\n",
    "        \"nivel_rango\": nivel_rango,\n",
    "        \"variedad_dir\": variedad_dir,\n",
    "        \"frames\": int(T), \"joints\": int(J), \"dims\": int(D)\n",
    "    }\n",
    "\n",
    "def inferir_desde_features_dict(feats: dict):\n",
    "    x = np.array([[feats.get(c, np.nan) for c in feature_cols]], dtype=float)\n",
    "    x = scaler.transform(imp.transform(x))\n",
    "    yhat = model.predict(x)[0]\n",
    "    pred_labels = [label_names[i] for i,v in enumerate(yhat) if v==1]\n",
    "    sugerencias = [label_to_text.get(lbl, lbl) for lbl in pred_labels]\n",
    "    return pred_labels, sugerencias\n",
    "\n",
    "def interpolate_nan_1d(y):\n",
    "    y = y.astype(np.float32)\n",
    "    T = len(y); idx = np.arange(T)\n",
    "    mask = np.isfinite(y)\n",
    "    if mask.sum() == 0: return y\n",
    "    # forward/backward\n",
    "    last = np.nan\n",
    "    for i in range(T):\n",
    "        if not np.isfinite(y[i]) and np.isfinite(last): y[i] = last\n",
    "        else: last = y[i]\n",
    "    last = np.nan\n",
    "    for i in range(T-1,-1,-1):\n",
    "        if not np.isfinite(y[i]) and np.isfinite(last): y[i] = last\n",
    "        else: last = y[i]\n",
    "    mask = np.isfinite(y)\n",
    "    if 2 <= mask.sum() < T:\n",
    "        y[~mask] = np.interp(idx[~mask], idx[mask], y[mask])\n",
    "    return y\n",
    "\n",
    "def clean_nan_interpolate(K, min_valid_ratio=0.10):\n",
    "    Kc = K.copy()\n",
    "    T,J,D = Kc.shape\n",
    "    used = []\n",
    "    for j in range(J):\n",
    "        valid = np.isfinite(Kc[:,j,:]).all(axis=1)\n",
    "        if valid.mean() < min_valid_ratio:\n",
    "            Kc[:,j,:] = np.nan\n",
    "            continue\n",
    "        for d in range(D):\n",
    "            Kc[:,j,d] = interpolate_nan_1d(Kc[:,j,d])\n",
    "        used.append(j)\n",
    "    if not used: return Kc, []\n",
    "    return Kc[:,used,:], used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547aa98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deteccion multipersona\n",
    "\n",
    "import cv2, numpy as np\n",
    "from ultralytics import YOLO\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def _centroid_from_kps(kps):\n",
    "    # kps: (J,2) con NaNs; devuelve centro v√°lido\n",
    "    mask = np.isfinite(kps).all(axis=1)\n",
    "    if mask.any():\n",
    "        return np.nanmean(kps[mask], axis=0)\n",
    "    return np.array([np.nan, np.nan], dtype=np.float32)\n",
    "\n",
    "def assign_tracks(prev_centroids, det_centroids, max_dist=100.0):\n",
    "    \"\"\"\n",
    "    Asigna detecciones a tracks previos v√≠a Hungarian.\n",
    "    Devuelve pares (prev_idx -> det_idx), y listas de no asignados.\n",
    "    \"\"\"\n",
    "    if len(prev_centroids)==0 or len(det_centroids)==0:\n",
    "        return [], list(range(len(prev_centroids))), list(range(len(det_centroids)))\n",
    "    C = np.zeros((len(prev_centroids), len(det_centroids)), dtype=np.float32)\n",
    "    for i, pc in enumerate(prev_centroids):\n",
    "        for j, dc in enumerate(det_centroids):\n",
    "            if np.any(np.isnan(pc)) or np.any(np.isnan(dc)):\n",
    "                C[i,j] = 1e6\n",
    "            else:\n",
    "                C[i,j] = np.linalg.norm(pc - dc)\n",
    "    rows, cols = linear_sum_assignment(C)\n",
    "    matches, prev_un, det_un = [], [], []\n",
    "    used_prev, used_det = set(), set()\n",
    "    for r,c in zip(rows, cols):\n",
    "        if C[r,c] <= max_dist:\n",
    "            matches.append((r,c))\n",
    "            used_prev.add(r); used_det.add(c)\n",
    "    for i in range(len(prev_centroids)):\n",
    "        if i not in used_prev: prev_un.append(i)\n",
    "    for j in range(len(det_centroids)):\n",
    "        if j not in used_det: det_un.append(j)\n",
    "    return matches, prev_un, det_un\n",
    "\n",
    "def video_to_tracks_yolo(\n",
    "    video_path, model_name=\"yolov8n-pose.pt\", conf=0.25, stride=1,\n",
    "    max_missed=30, max_tracks=12, assign_max_dist=120.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Devuelve:\n",
    "      tracks_K: dict track_id -> (T,J,2) con NaNs\n",
    "      FPS, W, H\n",
    "    \"\"\"\n",
    "    model = YOLO(model_name)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), f\"No se pudo abrir el v√≠deo: {video_path}\"\n",
    "    T = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    FPS = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    J = 17\n",
    "\n",
    "    # Estructuras de tracking\n",
    "    tracks = {}           # track_id -> dict(last_centroid, last_frame, missed, kps_per_frame)\n",
    "    next_id = 0\n",
    "\n",
    "    t = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        if t % stride != 0:\n",
    "            t += 1\n",
    "            continue\n",
    "\n",
    "        res = model.predict(frame, conf=conf, verbose=False)[0]\n",
    "        det_kps_list, det_centroids = [], []\n",
    "        if res.keypoints is not None and len(res.keypoints) > 0:\n",
    "            for i in range(len(res.keypoints)):\n",
    "                kps = res.keypoints.xy[i].cpu().numpy()  # (17,2)\n",
    "                kps[:,0] = np.clip(kps[:,0], 0, W-1)\n",
    "                kps[:,1] = np.clip(kps[:,1], 0, H-1)\n",
    "                det_kps_list.append(kps.astype(np.float32))\n",
    "                det_centroids.append(_centroid_from_kps(kps))\n",
    "\n",
    "        # Preparar centroids previos (de tracks activos)\n",
    "        active_ids = [tid for tid, tr in tracks.items() if tr[\"missed\"] < max_missed]\n",
    "        prev_centroids = [tracks[tid][\"last_centroid\"] for tid in active_ids]\n",
    "\n",
    "        # Asignaci√≥n\n",
    "        matches, prev_un, det_un = assign_tracks(prev_centroids, det_centroids, max_dist=assign_max_dist)\n",
    "\n",
    "        # Actualizar tracks con matches\n",
    "        for (pi, di) in matches:\n",
    "            tid = active_ids[pi]\n",
    "            kps = det_kps_list[di]\n",
    "            c = det_centroids[di]\n",
    "            tracks[tid][\"kps\"].append((t, kps))\n",
    "            tracks[tid][\"last_centroid\"] = c\n",
    "            tracks[tid][\"last_frame\"] = t\n",
    "            tracks[tid][\"missed\"] = 0\n",
    "\n",
    "        # Los prev no asignados: incrementar missed\n",
    "        for pi in prev_un:\n",
    "            tid = active_ids[pi]\n",
    "            tracks[tid][\"missed\"] += 1\n",
    "\n",
    "        # Nuevas detecciones -> nuevos tracks\n",
    "        for di in det_un:\n",
    "            if len(tracks) >= max_tracks:\n",
    "                continue\n",
    "            kps = det_kps_list[di]\n",
    "            c = det_centroids[di]\n",
    "            tracks[next_id] = {\n",
    "                \"kps\": [(t, kps)],\n",
    "                \"last_centroid\": c,\n",
    "                \"last_frame\": t,\n",
    "                \"missed\": 0\n",
    "            }\n",
    "            next_id += 1\n",
    "\n",
    "        t += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Convertir a tensores (T,J,2) por track\n",
    "    tracks_K = {}\n",
    "    for tid, tr in tracks.items():\n",
    "        K = np.full((T, J, 2), np.nan, dtype=np.float32)\n",
    "        for (f, kps) in tr[\"kps\"]:\n",
    "            if 0 <= f < T:\n",
    "                K[f] = kps\n",
    "        tracks_K[tid] = K\n",
    "\n",
    "    return tracks_K, FPS, W, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cba594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#M√©tricas grupales y decisi√≥n autom√°tica\n",
    "\n",
    "def nancorr(a, b):\n",
    "    \"\"\"Correlaci√≥n de Pearson nan-robusta.\"\"\"\n",
    "    mask = np.isfinite(a) & np.isfinite(b)\n",
    "    if mask.sum() < 3: return np.nan\n",
    "    aa = a[mask] - np.nanmean(a[mask])\n",
    "    bb = b[mask] - np.nanmean(b[mask])\n",
    "    denom = (np.sqrt(np.nanmean(aa**2))*np.sqrt(np.nanmean(bb**2))) + 1e-9\n",
    "    return float(np.nanmean(aa*bb)/denom)\n",
    "\n",
    "def group_metrics(COMs):\n",
    "    \"\"\"\n",
    "    COMs: lista de arrays (T,2) por persona en la ventana (NaNs posibles)\n",
    "    Devuelve: sincron√≠a, dispersi√≥n, un√≠sono, √°rea de formaci√≥n\n",
    "    \"\"\"\n",
    "    n = len(COMs)\n",
    "    if n < 2:\n",
    "        return {\"sync\": np.nan, \"spread\": np.nan, \"unison\": np.nan, \"formation_area\": np.nan}\n",
    "\n",
    "    # Velocidades\n",
    "    vels = [np.linalg.norm(np.diff(c,axis=0),axis=1) for c in COMs]\n",
    "    # Direcciones (unitarios)\n",
    "    dirs = []\n",
    "    for c in COMs:\n",
    "        d = np.diff(c,axis=0)\n",
    "        norm = np.linalg.norm(d,axis=1) + 1e-9\n",
    "        dirs.append(d / norm[:,None])\n",
    "\n",
    "    # Sincron√≠a = corr de velocidades promedio por pares\n",
    "    pair_sync = []\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            pair_sync.append(nancorr(vels[i], vels[j]))\n",
    "    sync = float(np.nanmean(pair_sync)) if pair_sync else np.nan\n",
    "\n",
    "    # Un√≠sono = media de coseno(dir_i, dir_j) > 0.8 (proporci√≥n)\n",
    "    pair_unison = []\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            doti = (dirs[i]*dirs[j]).sum(axis=1)  # cosenos\n",
    "            mask = np.isfinite(doti)\n",
    "            if mask.sum() == 0: continue\n",
    "            pair_unison.append(np.nanmean((doti[mask] > 0.8).astype(np.float32)))\n",
    "    unison = float(np.nanmean(pair_unison)) if pair_unison else np.nan\n",
    "\n",
    "    # Dispersi√≥n = distancia media por pares de COM (promedio en ventana)\n",
    "    pair_dist = []\n",
    "    for t in range(COMs[0].shape[0]):\n",
    "        pts = []\n",
    "        for c in COMs:\n",
    "            if np.all(np.isfinite(c[t])):\n",
    "                pts.append(c[t])\n",
    "        if len(pts) >= 2:\n",
    "            pts = np.stack(pts)\n",
    "            # media de distancias por pares\n",
    "            D = np.linalg.norm(pts[:,None,:]-pts[None,:,:], axis=2)\n",
    "            pair_dist.append(np.nanmean(D[np.triu_indices(len(pts),1)]))\n",
    "    spread = float(np.nanmean(pair_dist)) if pair_dist else np.nan\n",
    "\n",
    "    # √Årea de formaci√≥n = √°rea del convex hull promedio (aprox usando todos los puntos)\n",
    "    all_pts = []\n",
    "    for c in COMs:\n",
    "        mask = np.all(np.isfinite(c), axis=1)\n",
    "        all_pts += [c[m] for m in np.where(mask)[0]]\n",
    "    if len(all_pts) >= 3:\n",
    "        pts = np.vstack(all_pts)\n",
    "        try:\n",
    "            hull = ConvexHull(pts)\n",
    "            area = float(hull.area)  # per√≠metro 3D en 2D? En 2D mejor usar hull.volume\n",
    "            area = float(hull.volume)  # en 2D, 'volume' es el √°rea\n",
    "        except Exception:\n",
    "            # fallback: bbox\n",
    "            xmin, ymin = np.nanmin(pts, axis=0)\n",
    "            xmax, ymax = np.nanmax(pts, axis=0)\n",
    "            area = float((xmax-xmin)*(ymax-ymin))\n",
    "    else:\n",
    "        area = np.nan\n",
    "\n",
    "    return {\"sync\": sync, \"spread\": spread, \"unison\": unison, \"formation_area\": area}\n",
    "\n",
    "def auto_decide_mode(tracks_K, min_frames_active=0.5, prop_single_threshold=0.8, multi_threshold=2):\n",
    "    \"\"\"\n",
    "    Decide 'single' vs 'multi':\n",
    "      - Cuenta personas activas por frame (‚â• Joints v√°lidos/ NaNs bajos).\n",
    "      - Si >80% de frames tienen exactamente 1 ‚Üí 'single', si no ‚Üí 'multi'.\n",
    "    \"\"\"\n",
    "    if not tracks_K:\n",
    "        return \"single\", None\n",
    "    T = next(iter(tracks_K.values())).shape[0]\n",
    "    active_counts = np.zeros(T, dtype=int)\n",
    "    for K in tracks_K.values():\n",
    "        valid = np.isfinite(K).all(axis=2)  # (T,J)\n",
    "        frames_valid = valid.mean(axis=1) >= min_frames_active   # proporci√≥n de joints v√°lidos\n",
    "        active_counts += frames_valid.astype(int)\n",
    "\n",
    "    prop_single = (active_counts == 1).mean()\n",
    "    if prop_single >= prop_single_threshold:\n",
    "        # single: elige el track con m√°s frames v√°lidos\n",
    "        best_id, best_frames = None, -1\n",
    "        for tid, K in tracks_K.items():\n",
    "            frames_valid = np.isfinite(K).all(axis=2).mean(axis=1) >= min_frames_active\n",
    "            cnt = int(frames_valid.sum())\n",
    "            if cnt > best_frames:\n",
    "                best_frames = cnt; best_id = tid\n",
    "        return \"single\", best_id\n",
    "    else:\n",
    "        # multi si en una proporci√≥n relevante hay >=2 personas\n",
    "        if (active_counts >= multi_threshold).mean() >= 0.2:\n",
    "            return \"multi\", None\n",
    "        # default\n",
    "        return \"single\", max(tracks_K, key=lambda tid: np.isfinite(tracks_K[tid]).all(axis=2).mean(axis=1).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4e13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeline por ventanas + overlay simple o multiple\n",
    "\n",
    "def overlay_video_multi(video_path, tracks_K, timeline, out_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), f\"No se pudo abrir el v√≠deo: {video_path}\"\n",
    "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    FPS = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    vw = cv2.VideoWriter(out_path, fourcc, FPS, (W,H))\n",
    "\n",
    "    # colores fijos por track\n",
    "    palette = [(255,255,255),(0,255,255),(255,0,255),(255,255,0),(0,200,255),(255,200,0),(200,255,0),(200,200,255)]\n",
    "    track_ids = sorted(tracks_K.keys())\n",
    "    color_of = {tid: palette[i%len(palette)] for i,tid in enumerate(track_ids)}\n",
    "\n",
    "    t = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok: break\n",
    "\n",
    "        # dibujar cada track si hay puntos\n",
    "        for tid, K in tracks_K.items():\n",
    "            if t < len(K):\n",
    "                P = K[t]\n",
    "                col = color_of[tid]\n",
    "                for a,b in COCO_EDGES:\n",
    "                    if a < P.shape[0] and b < P.shape[0]:\n",
    "                        xa,ya = P[a]; xb,yb = P[b]\n",
    "                        if np.isfinite(xa) and np.isfinite(ya) and np.isfinite(xb) and np.isfinite(yb):\n",
    "                            cv2.line(frame, (int(xa),int(ya)), (int(xb),int(yb)), col, 2)\n",
    "                for (x,y) in P:\n",
    "                    if np.isfinite(x) and np.isfinite(y):\n",
    "                        cv2.circle(frame, (int(x),int(y)), 2, col, -1)\n",
    "\n",
    "        # texto: sugerencias activas (globales)\n",
    "        active = []\n",
    "        for seg in timeline:\n",
    "            if seg[\"start_f\"] <= t <= seg[\"end_f\"]:\n",
    "                active = seg.get(\"sugerencias_global\", []) or seg.get(\"sugerencias_single\", [])\n",
    "        y0 = 30\n",
    "        for s in active[:4]:\n",
    "            cv2.putText(frame, f\"‚Ä¢ {s}\", (20, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 4, cv2.LINE_AA)\n",
    "            cv2.putText(frame, f\"‚Ä¢ {s}\", (20, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "            y0 += 28\n",
    "\n",
    "        vw.write(frame); t += 1\n",
    "\n",
    "    cap.release(); vw.release()\n",
    "\n",
    "def run_inference_auto(video_path, model_name=\"yolov8n-pose.pt\",\n",
    "                       conf=0.25, stride=1, win_sec=5.0, hop_sec=2.5):\n",
    "    # 1) detecci√≥n + tracking\n",
    "    tracks_K, FPS, W, H = video_to_tracks_yolo(video_path, model_name=model_name, conf=conf, stride=stride)\n",
    "\n",
    "    # 2) decisi√≥n auto\n",
    "    mode, best_id = auto_decide_mode(tracks_K)\n",
    "    print(f\"Modo decidido: {mode}  | best_id: {best_id}\")\n",
    "\n",
    "    # 3) limpiar/interpolar cada track\n",
    "    tracks_clean = {}\n",
    "    for tid, K in tracks_K.items():\n",
    "        Kc, used = clean_nan_interpolate(K, min_valid_ratio=0.10)\n",
    "        tracks_clean[tid] = Kc\n",
    "\n",
    "    win = max(1, int(round(win_sec * FPS)))\n",
    "    hop = max(1, int(round(hop_sec * FPS)))\n",
    "    T = next(iter(tracks_clean.values())).shape[0]\n",
    "\n",
    "    rows = []\n",
    "    timeline = []\n",
    "\n",
    "    if mode == \"single\":\n",
    "        # elegir K del best_id\n",
    "        K_sel = tracks_clean[best_id]\n",
    "        for start in range(0, T-1, hop):\n",
    "            end = min(T-1, start + win)\n",
    "            if end - start < max(8, int(0.25*win)): break\n",
    "            Kw = K_sel[start:end]\n",
    "            feats = features_coreograficos(Kw)\n",
    "            feats_ml = {c: feats.get(c, np.nan) for c in feature_cols}\n",
    "            labels, suggs = inferir_desde_features_dict(feats_ml)\n",
    "            timeline.append({\"start_f\":start, \"end_f\":end, \"sugerencias_single\":suggs})\n",
    "            row = {\"start_f\":start, \"end_f\":end, \"start_s\":start/FPS, \"end_s\":end/FPS, \"mode\":\"single\", \"track_id\":best_id}\n",
    "            row.update(feats); row[\"labels\"]=\"|\".join(labels); row[\"sugerencias\"]=\"|\".join(suggs)\n",
    "            rows.append(row)\n",
    "\n",
    "        out_dir = os.path.join(BASE, \"data/processed/aistpp\")\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        out_csv = os.path.join(out_dir, \"timeline_auto_single.csv\")\n",
    "        pd.DataFrame(rows).to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "        out_mp4 = os.path.join(out_dir, \"video_auto_single.mp4\")\n",
    "        overlay_video_multi(video_path, {best_id: tracks_clean[best_id]}, timeline, out_mp4)\n",
    "        print(\"CSV:\", out_csv); print(\"Video:\", out_mp4)\n",
    "        return {\"mode\": mode, \"csv\": out_csv, \"video\": out_mp4, \"timeline\": timeline}\n",
    "\n",
    "    else:\n",
    "        # MULTI: por ventana, computar features individuales + m√©tricas grupales\n",
    "        track_ids = sorted(tracks_clean.keys())\n",
    "        for start in range(0, T-1, hop):\n",
    "            end = min(T-1, start + win)\n",
    "            if end - start < max(8, int(0.25*win)): break\n",
    "\n",
    "            feats_per_track = {}\n",
    "            suggs_per_track = {}\n",
    "            COMs = []\n",
    "\n",
    "            for tid in track_ids:\n",
    "                Kw = tracks_clean[tid][start:end]\n",
    "                # si la ventana de ese track est√° totalmente NaN, saltar\n",
    "                if not np.isfinite(Kw).any():\n",
    "                    continue\n",
    "                feats = features_coreograficos(Kw)\n",
    "                feats_per_track[tid] = feats\n",
    "                feats_ml = {c: feats.get(c, np.nan) for c in feature_cols}\n",
    "                labels, suggs = inferir_desde_features_dict(feats_ml)\n",
    "                suggs_per_track[tid] = suggs\n",
    "                COMs.append(center_of_mass(Kw))\n",
    "\n",
    "            # m√©tricas grupales\n",
    "            gm = group_metrics(COMs) if len(COMs) >= 2 else {\"sync\":np.nan,\"spread\":np.nan,\"unison\":np.nan,\"formation_area\":np.nan}\n",
    "\n",
    "            # sugerencias globales (reglas simples sobre m√©tricas grupales)\n",
    "            sglob = []\n",
    "            if np.isfinite(gm[\"sync\"]) and gm[\"sync\"] < 0.2:\n",
    "                sglob.append(\"Sincron√≠a grupal baja: ensayar cues de entrada/salida y respiraci√≥n com√∫n.\")\n",
    "            if np.isfinite(gm[\"unison\"]) and gm[\"unison\"] < 0.5:\n",
    "                sglob.append(\"Poco un√≠sono: trabajar frases en espejo y acentos compartidos.\")\n",
    "            if np.isfinite(gm[\"spread\"]) and gm[\"spread\"] < 60:\n",
    "                sglob.append(\"Formaci√≥n muy compacta: explorar aperturas y diagonales.\")\n",
    "            if np.isfinite(gm[\"spread\"]) and gm[\"spread\"] > 300:\n",
    "                sglob.append(\"Demasiada dispersi√≥n: introducir agrupamientos o centros de atenci√≥n.\")\n",
    "            # (opcional) √°rea de formaci√≥n poco variable entre ventanas ‚Üí sugerir cambios de formaci√≥n\n",
    "\n",
    "            # fila CSV (agregada)\n",
    "            row = {\"start_f\":start, \"end_f\":end, \"start_s\":start/FPS, \"end_s\":end/FPS, \"mode\":\"multi\"}\n",
    "            row.update({f\"gm_{k}\":v for k,v in gm.items()})\n",
    "            row[\"sugerencias_global\"] = \"|\".join(sglob)\n",
    "            # puedes agregar resumidas por track si quieres\n",
    "            rows.append(row)\n",
    "\n",
    "            timeline.append({\n",
    "                \"start_f\":start, \"end_f\":end,\n",
    "                \"sugerencias_global\": sglob,\n",
    "                \"sugerencias_por_track\": {int(t): suggs_per_track[t] for t in suggs_per_track}\n",
    "            })\n",
    "\n",
    "        out_dir = os.path.join(BASE, \"data/processed/aistpp\")\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        out_csv = os.path.join(out_dir, \"timeline_auto_multi.csv\")\n",
    "        pd.DataFrame(rows).to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "        out_mp4 = os.path.join(out_dir, \"video_auto_multi.mp4\")\n",
    "        overlay_video_multi(video_path, tracks_clean, timeline, out_mp4)\n",
    "        print(\"CSV:\", out_csv); print(\"Video:\", out_mp4)\n",
    "        return {\"mode\": \"multi\", \"csv\": out_csv, \"video\": out_mp4, \"timeline\": timeline}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== SUBIR V√çDEO + EXTRAER KEYPOINTS (MediaPipe Pose) =====\n",
    "import os, tempfile\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from google.colab import files, drive\n",
    "\n",
    "# Montar Drive si no est√° montado\n",
    "if not os.path.isdir(\"/content/drive/MyDrive\"):\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "BASE = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "OUT_DIR = os.path.join(BASE, \"data/processed/custom_videos\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def upload_video():\n",
    "    up = files.upload()\n",
    "    if not up:\n",
    "        raise RuntimeError(\"No se subi√≥ ning√∫n archivo.\")\n",
    "    name = list(up.keys())[0]\n",
    "    return name, up[name]\n",
    "\n",
    "def process_video_with_mediapipe(video_path, output_dir):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"No se pudo abrir el v√≠deo: {video_path}\")\n",
    "\n",
    "    all_keypoints, frame_count = [], 0\n",
    "    # Pose con FP32; segmentaci√≥n desactivada para ir m√°s ligero\n",
    "    with mp.solutions.pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=2,\n",
    "        enable_segmentation=False,\n",
    "        min_detection_confidence=0.5\n",
    "    ) as pose:\n",
    "        while True:\n",
    "            ok, frame = cap.read()\n",
    "            if not ok:\n",
    "                break\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            res = pose.process(rgb)\n",
    "\n",
    "            if res.pose_landmarks:\n",
    "                # 33 landmarks √ó [x, y, z, visibility]\n",
    "                flat = []\n",
    "                for lm in res.pose_landmarks.landmark:\n",
    "                    flat.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
    "                all_keypoints.append(flat)\n",
    "            else:\n",
    "                all_keypoints.append([np.nan] * (33 * 4))\n",
    "\n",
    "            frame_count += 1\n",
    "            if frame_count % 30 == 0:\n",
    "                print(f\"Procesados {frame_count} frames...\")\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    arr = np.asarray(all_keypoints, dtype=np.float32)  # (T, 132)\n",
    "    out_name = os.path.splitext(os.path.basename(video_path))[0] + \"_keypoints.npy\"\n",
    "    out_path = os.path.join(output_dir, out_name)\n",
    "    np.save(out_path, arr)\n",
    "    return arr, out_path\n",
    "\n",
    "# Flujo: subir ‚Üí temporal ‚Üí procesar ‚Üí guardar\n",
    "video_tmp = None\n",
    "try:\n",
    "    name, data = upload_video()\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(name)[1]) as tmp:\n",
    "        tmp.write(data)\n",
    "        video_tmp = tmp.name\n",
    "    print(f\"‚ñ∂ V√≠deo '{name}' guardado temporalmente en: {video_tmp}\")\n",
    "\n",
    "    arr, saved = process_video_with_mediapipe(video_tmp, OUT_DIR)\n",
    "    print(f\"\\n‚úÖ Keypoints extra√≠dos: shape={arr.shape}  (frames x 132)\")\n",
    "    print(f\"üìÅ Guardado en: {saved}\")\n",
    "\n",
    "finally:\n",
    "    try:\n",
    "        if video_tmp and os.path.exists(video_tmp):\n",
    "            os.remove(video_tmp)\n",
    "            print(f\"üßπ Temporal eliminado: {video_tmp}\")\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5222608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import tempfile\n",
    "import mediapipe as mp  # Mantener el import: se usa en process_video_with_mediapipe si hace falta\n",
    "\n",
    "# Cargar artefactos (entrenados previamente con tu CSV)\n",
    "BASE = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "ART  = f\"{BASE}/artifacts\"\n",
    "imp          = joblib.load(f\"{ART}/imputer.joblib\")\n",
    "scaler       = joblib.load(f\"{ART}/scaler.joblib\")\n",
    "model        = joblib.load(f\"{ART}/model_ovr_logreg.joblib\")\n",
    "feature_cols = pd.read_csv(f\"{ART}/feature_cols.csv\", header=None)[0].tolist()\n",
    "label_names  = pd.read_csv(f\"{ART}/label_names.csv\", header=None)[0].tolist()\n",
    "\n",
    "label_to_text = {\n",
    "    \"amplitud_baja\":      \"Aumentar amplitud (extensiones y desplazamientos m√°s amplios).\",\n",
    "    \"variedad_baja\":      \"Introducir cambios de direcci√≥n y diagonales.\",\n",
    "    \"mucha_simetria\":     \"Explorar asimetr√≠as entre izquierda y derecha.\",\n",
    "    \"poca_simetria\":      \"Equilibrar con momentos de simetr√≠a.\",\n",
    "    \"fluidez_baja\":       \"Trabajar transiciones para mayor continuidad/fluidez.\",\n",
    "    \"poco_rango_niveles\": \"Usar niveles alto y bajo adem√°s del medio.\",\n",
    "    \"exceso_rango_niveles\": \"Reducir rango vertical para mayor cohesi√≥n.\",\n",
    "    \"frase_corta\": \"Frase corta: considerar repetici√≥n o desarrollo del material.\"\n",
    "    # A√±ade aqu√≠ el resto de etiquetas de label_names y su sugerencia correspondiente\n",
    "}\n",
    "\n",
    "# --- pares izquierda/derecha COCO-17 ---\n",
    "# Nota: MediaPipe proporciona 33 puntos, pero el modelo fue entrenado con COCO-17.\n",
    "# Se necesita mapear los puntos de MediaPipe a COCO-17 o reentrenar el modelo.\n",
    "# Para simplificar en este ejemplo, asumimos un mapeo o un subconjunto\n",
    "# de puntos MediaPipe que se alinea con COCO-17 para el c√°lculo de features.\n",
    "# Este mapeo es simplificado a efectos demostrativos.\n",
    "# Un mapeo correcto requerir√≠a revisar los √≠ndices de MediaPipe y COCO.\n",
    "# Suponemos que los primeros 17 puntos de MediaPipe se alinean con COCO-17 para estas features.\n",
    "MEDIAPIPE_TO_COCO_MAP = {\n",
    "    0: 0,  # Nariz\n",
    "    1: 1,  # Ojo izquierdo (interno)\n",
    "    2: 2,  # Ojo izquierdo\n",
    "    3: 3,  # Ojo izquierdo (externo)\n",
    "    4: 4,  # Ojo derecho (interno)\n",
    "    5: 5,  # Ojo derecho\n",
    "    6: 6,  # Ojo derecho (externo)\n",
    "    7: 7,  # Oreja izquierda\n",
    "    8: 8,  # Oreja derecha\n",
    "    9: 9,  # Boca izquierda\n",
    "    10: 10,  # Boca derecha\n",
    "    11: 11,  # Hombro izquierdo\n",
    "    12: 12,  # Hombro derecho\n",
    "    13: 13,  # Codo izquierdo\n",
    "    14: 14,  # Codo derecho\n",
    "    15: 15,  # Mu√±eca izquierda\n",
    "    16: 16,  # Mu√±eca derecha\n",
    "    17: None,  # Me√±ique izquierdo\n",
    "    18: None,  # Me√±ique derecho\n",
    "    19: None,  # √çndice izquierdo\n",
    "    20: None,  # √çndice derecho\n",
    "    21: None,  # Pulgar izquierdo\n",
    "    22: None,  # Pulgar derecho\n",
    "    23: None,  # Cadera izquierda\n",
    "    24: None,  # Cadera derecha\n",
    "    25: None,  # Rodilla izquierda\n",
    "    26: None,  # Rodilla derecha\n",
    "    27: None,  # Tobillo izquierdo\n",
    "    28: None,  # Tobillo derecho\n",
    "    29: None,  # Tal√≥n izquierdo\n",
    "    30: None,  # Tal√≥n derecho\n",
    "    31: None,  # Punta pie izquierdo\n",
    "    32: None,  # Punta pie derecho\n",
    "}\n",
    "\n",
    "# Pares COCO simplificados basados en los primeros 17 puntos de MediaPipe\n",
    "MEDIAPIPE_COCO_PAIRS = [(11,12), (13,14), (15,16)]  # Hombros, codos, mu√±ecas\n",
    "\n",
    "def center_of_mass_mediapipe(K):\n",
    "    # En MediaPipe las caderas son 23 y 24\n",
    "    T,J,D = K.shape\n",
    "    if J >= 25:  # Asumiendo que se usan puntos de MediaPipe\n",
    "        return (K[:,23,:2] + K[:,24,:2]) / 2  # Solo x, y para el centro de masas\n",
    "    return K[:,:,:2].mean(axis=1)  # Solo x, y promediando todos los puntos\n",
    "\n",
    "def features_coreograficos_mediapipe(K):\n",
    "    \"\"\"K: (T,J,D) con posibles NaNs; devuelve un dict de features.\"\"\"\n",
    "    T,J,D = K.shape\n",
    "    # Usar √∫nicamente x, y para features 2D\n",
    "    K_2d = K[:,:,:2]\n",
    "\n",
    "    amp_mean = (np.nanmax(K_2d, axis=0) - np.nanmin(K_2d, axis=0)).mean(axis=0)\n",
    "    amp_x = float(amp_mean[0]); amp_y = float(amp_mean[1])\n",
    "\n",
    "    vel = np.linalg.norm(np.diff(K_2d, axis=0), axis=2)\n",
    "    vel_media = float(np.nanmean(vel)) if vel.size else 0.0\n",
    "\n",
    "    pair_vals=[]\n",
    "    for a,b in MEDIAPIPE_COCO_PAIRS:\n",
    "        if a < J and b < J:\n",
    "            diff = K_2d[:,a,:] - K_2d[:,b,:]\n",
    "            if diff.ndim > 1:\n",
    "                d = np.linalg.norm(diff, axis=1).mean()  # Eje correcto para (T, D) -> (T,)\n",
    "                pair_vals.append(np.nanmean(d))\n",
    "            elif diff.ndim == 1:  # Caso en el que diff es 1D (T,)\n",
    "                d = np.linalg.norm(diff).mean()\n",
    "                pair_vals.append(np.nanmean(d))\n",
    "    sim_raw = float(np.nanmean(pair_vals)) if pair_vals else np.nan\n",
    "\n",
    "    com = center_of_mass_mediapipe(K)\n",
    "    nivel_p10 = float(np.nanpercentile(com[:,1], 10))\n",
    "    nivel_p90 = float(np.nanpercentile(com[:,1], 90))\n",
    "    nivel_rango = float(nivel_p10 - nivel_p90)\n",
    "\n",
    "    disp = np.diff(com, axis=0)\n",
    "    # Evitar divisi√≥n por cero en arctan2 a√±adiendo un peque√±o epsilon\n",
    "    dirs = np.arctan2(disp[:,1], disp[:,0] + 1e-9)\n",
    "    cambios = np.abs(np.diff(dirs))\n",
    "    variedad_dir = float(np.nanmean(cambios)) if len(cambios) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"amplitud_x\": amp_x,                  # Mantener nombres originales para consistencia con el modelo\n",
    "        \"amplitud_y\": amp_y,\n",
    "        \"velocidad_media\": vel_media,\n",
    "        \"simetria\": sim_raw,                  # Mantener nombres originales para consistencia con el modelo\n",
    "        \"nivel_rango\": nivel_rango,\n",
    "        \"variedad_direcciones\": variedad_dir, # Mantener nombres originales para consistencia con el modelo\n",
    "        \"frames\": int(T),\n",
    "        \"joints\": int(J),\n",
    "        \"dims\": int(D)\n",
    "    }\n",
    "\n",
    "def inferir_desde_features_dict(feats: dict):\n",
    "    # Asegurar que el orden de las features coincide con el de entrenamiento\n",
    "    x = np.array([[feats.get(c, np.nan) for c in feature_cols]], dtype=float)\n",
    "    x = scaler.transform(imp.transform(x))\n",
    "    yhat = model.predict(x)[0]\n",
    "    # Obtener etiquetas predichas (1 = predicha, 0 = no)\n",
    "    predicted_labels = [label_names[i] for i, v in enumerate(yhat) if v == 1]\n",
    "    sugerencias = [label_to_text.get(lbl, lbl) for lbl in predicted_labels]\n",
    "    return predicted_labels, sugerencias\n",
    "\n",
    "def interpolate_nan_1d(y):\n",
    "    y = y.astype(np.float32)\n",
    "    T = len(y); idx = np.arange(T)\n",
    "    mask = np.isfinite(y)\n",
    "    if mask.sum() == 0: return y\n",
    "    # Relleno hacia delante/atr√°s\n",
    "    last = np.nan\n",
    "    for i in range(T):\n",
    "        if not np.isfinite(y[i]) and np.isfinite(last): y[i] = last\n",
    "        else: last = y[i]\n",
    "    last = np.nan\n",
    "    for i in range(T-1, -1, -1):\n",
    "        if not np.isfinite(y[i]) and np.isfinite(last): y[i] = last\n",
    "        else: last = y[i]\n",
    "    mask = np.isfinite(y)\n",
    "    if 2 <= mask.sum() < T:\n",
    "        y[~mask] = np.interp(idx[~mask], idx[mask], y[mask])\n",
    "    return y\n",
    "\n",
    "def clean_nan_interpolate(K, min_valid_ratio=0.10):\n",
    "    # Limpia NaNs por articulaci√≥n y dimension, e interpola si hay datos suficientes\n",
    "    Kc = K.copy()\n",
    "    T,J,D = Kc.shape\n",
    "    used = []\n",
    "    for j in range(J):\n",
    "        # Validez: frames donde todas las dimensiones del punto son finitas\n",
    "        valid = np.isfinite(Kc[:,j,:]).all(axis=1)\n",
    "        if valid.mean() < min_valid_ratio:\n",
    "            Kc[:,j,:] = np.nan\n",
    "            continue\n",
    "        for d in range(D):\n",
    "            # Interpolar cada dimensi√≥n por separado\n",
    "            Kc[:,j,d] = interpolate_nan_1d(Kc[:,j,d])\n",
    "        # Comprobar si sigue habiendo alg√∫n valor v√°lido tras la interpolaci√≥n\n",
    "        if np.isfinite(Kc[:,j,:]).any():\n",
    "            used.append(j)\n",
    "\n",
    "    if not used:\n",
    "        print(\"No hay articulaciones v√°lidas tras limpieza e interpolaci√≥n.\")\n",
    "        return Kc, []  # Devuelve con NaNs si no hay puntos utilizables\n",
    "\n",
    "    # Filtrar para incluir solo las articulaciones usadas\n",
    "    return Kc[:,used,:], used\n",
    "\n",
    "# Aristas COCO simplificadas para dibujado basadas en los primeros 17 puntos de MediaPipe\n",
    "# Es una simplificaci√≥n; para dibujo preciso se necesitar√≠a un mapeo riguroso.\n",
    "MEDIAPIPE_COCO_EDGES_SIMPLIFIED = [\n",
    "    (11,13), (13,15),      # Brazo izquierdo (hombro a mu√±eca)\n",
    "    (12,14), (14,16),      # Brazo derecho (hombro a mu√±eca)\n",
    "    (11,12),               # Hombros\n",
    "    (23,24),               # Caderas\n",
    "    (23,25), (25,27),      # Pierna izquierda (cadera a tobillo)\n",
    "    (24,26), (26,28),      # Pierna derecha (cadera a tobillo)\n",
    "    (11,23), (12,24)       # Tronco (hombro a cadera)\n",
    "]\n",
    "\n",
    "def overlay_suggestions_on_video(video_path, K, timeline, out_path):\n",
    "    # Pinta esqueleto y sugerencias activas en cada frame y exporta v√≠deo anotado\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), f\"No se pudo abrir el v√≠deo: {video_path}\"\n",
    "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    FPS = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    vw = cv2.VideoWriter(out_path, fourcc, FPS, (W,H))\n",
    "\n",
    "    t = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok: break\n",
    "\n",
    "        if t < len(K):\n",
    "            P = K[t][:,:2]  # Solo x, y para dibujar\n",
    "            # Dibujar esqueleto (simplificado)\n",
    "            for a,b in MEDIAPIPE_COCO_EDGES_SIMPLIFIED:\n",
    "                if a < P.shape[0] and b < P.shape[0]:\n",
    "                    xa,ya = P[a]; xb,yb = P[b]\n",
    "                    if np.isfinite(xa) and np.isfinite(ya) and np.isfinite(xb) and np.isfinite(yb):\n",
    "                        cv2.line(frame, (int(xa),int(ya)), (int(xb),int(yb)), (255,255,255), 2)\n",
    "            for (x,y) in P:\n",
    "                if np.isfinite(x) and np.isfinite(y):\n",
    "                    cv2.circle(frame, (int(x),int(y)), 2, (255,255,255), -1)\n",
    "\n",
    "        # Sugerencias activas para el frame t\n",
    "        active = []\n",
    "        for seg in timeline:\n",
    "            if seg[\"start_f\"] <= t <= seg[\"end_f\"]:\n",
    "                active = seg[\"sugerencias\"]\n",
    "        y0 = 30\n",
    "        for s in active[:4]:\n",
    "            cv2.putText(frame, f\"‚Ä¢ {s}\", (20, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 4, cv2.LINE_AA)\n",
    "            cv2.putText(frame, f\"‚Ä¢ {s}\", (20, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "            y0 += 28\n",
    "\n",
    "        vw.write(frame); t += 1\n",
    "\n",
    "    cap.release(); vw.release()\n",
    "\n",
    "def run_inference_on_custom_video(video_path, keypoints_array, output_dir, win_sec=5.0, hop_sec=2.5):\n",
    "    \"\"\"\n",
    "    Ejecuta la inferencia sobre un v√≠deo custom usando keypoints ya extra√≠dos.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Ruta del v√≠deo original.\n",
    "        keypoints_array (np.ndarray): Array de keypoints de MediaPipe (T, J*D).\n",
    "        output_dir (str): Carpeta para guardar las salidas.\n",
    "        win_sec (float): Tama√±o de ventana en segundos para calcular features.\n",
    "        hop_sec (float): Salto entre ventanas en segundos.\n",
    "\n",
    "    Returns:\n",
    "        dict: Rutas al CSV y al v√≠deo anotado, y la estructura 'timeline'.\n",
    "    \"\"\"\n",
    "    # FPS del v√≠deo original\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    FPS = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    cap.release()\n",
    "\n",
    "    # Reajustar array de keypoints a (T, J, D)\n",
    "    # MediaPipe devuelve 33 puntos con (x, y, z, visibility)\n",
    "    T = keypoints_array.shape[0]\n",
    "    J = 33  # MediaPipe Pose: 33 puntos\n",
    "    D = 4   # x, y, z, visibility\n",
    "    K_raw = keypoints_array.reshape(T, J, D)\n",
    "\n",
    "    # 2) Limpieza e interpolaci√≥n de keypoints\n",
    "    Kc, used = clean_nan_interpolate(K_raw, min_valid_ratio=0.10)\n",
    "    if not used:\n",
    "        print(\"No hay articulaciones v√°lidas tras limpieza e interpolaci√≥n. No se puede continuar.\")\n",
    "        return None\n",
    "\n",
    "    win = max(1, int(round(win_sec * FPS)))\n",
    "    hop = max(1, int(round(hop_sec * FPS)))\n",
    "    T_clean = len(Kc)\n",
    "\n",
    "    rows = []\n",
    "    timeline = []\n",
    "\n",
    "    # 3) Calcular features y generar sugerencias con ventana deslizante\n",
    "    for start in range(0, T_clean - 1, hop):\n",
    "        end = min(T_clean - 1, start + win)\n",
    "        if end - start < max(8, int(0.25 * win)):\n",
    "             break  # Garantizar ventana suficientemente grande\n",
    "\n",
    "        Kw = Kc[start:end]\n",
    "\n",
    "        # Calcular features adaptadas a puntos MediaPipe\n",
    "        feats = features_coreograficos_mediapipe(Kw)\n",
    "\n",
    "        # Preparar features para la inferencia ML\n",
    "        feats_ml = {c: feats.get(c, np.nan) for c in feature_cols}\n",
    "\n",
    "        # Generar sugerencias\n",
    "        labels, suggs = inferir_desde_features_dict(feats_ml)\n",
    "\n",
    "        timeline.append({\"start_f\": start, \"end_f\": end, \"sugerencias\": suggs})\n",
    "\n",
    "        row = {\"start_f\": start, \"end_f\": end, \"start_s\": start / FPS, \"end_s\": end / FPS}\n",
    "        row.update(feats)\n",
    "        row[\"labels\"] = \"|\".join(labels)\n",
    "        row[\"sugerencias\"] = \"|\".join(suggs)\n",
    "        rows.append(row)\n",
    "\n",
    "    # 4) Guardar timeline a CSV\n",
    "    out_csv = os.path.join(output_dir, \"custom_video_suggestions_timeline.csv\")\n",
    "    pd.DataFrame(rows).to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Sugerencias (timeline) guardadas en: {out_csv}\")\n",
    "\n",
    "    # 5) Crear v√≠deo anotado\n",
    "    out_mp4 = os.path.join(output_dir, \"custom_video_annotated.mp4\")\n",
    "    overlay_suggestions_on_video(video_path, Kc, timeline, out_mp4)\n",
    "    print(f\"V√≠deo anotado guardado en: {out_mp4}\")\n",
    "\n",
    "    return {\"csv\": out_csv, \"video\": out_mp4, \"timeline\": timeline}\n",
    "\n",
    "# --- Ejecutar el proceso sobre el v√≠deo custom ---\n",
    "# Se asume que video_path y keypoints_array existen desde la celda previa.\n",
    "\n",
    "# Para demostraci√≥n, asumimos que las variables est√°n definidas por la ejecuci√≥n anterior.\n",
    "# Comprobamos que el v√≠deo original a√∫n est√° accesible para la superposici√≥n.\n",
    "# Si el archivo temporal se elimin√≥, habr√° que volver a subir o usar una ruta persistente.\n",
    "# Asumimos que video_path apunta a una ubicaci√≥n persistente o re-subimos si es necesario.\n",
    "\n",
    "# Re-subir el v√≠deo si el archivo temporal ya no existe\n",
    "try:\n",
    "    # Verificar si el archivo temporal previo sigue existiendo\n",
    "    # Assuming 'video_path' variable exists and has the path from previous execution\n",
    "    if 'video_path' not in locals() or not os.path.exists(video_path):\n",
    "         print(\"No se encontr√≥ el v√≠deo anterior o la ruta no est√° definida. Vuelve a subir el v√≠deo, por favor.\")\n",
    "         video_name, video_content = upload_video()\n",
    "         with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(video_name)[1]) as temp_video_file:\n",
    "             temp_video_file.write(video_content)\n",
    "             video_path = temp_video_file.name\n",
    "         print(f\"V√≠deo '{video_name}' re-subido y guardado temporalmente en: {video_path}\")\n",
    "\n",
    "    # Asegurar que keypoints_array tambi√©n est√© disponible\n",
    "    if 'keypoints_array' not in locals() or keypoints_array is None:\n",
    "        print(\"No se encontr√≥ el array de keypoints. Ejecuta primero el paso de MediaPipe.\")\n",
    "        # cargar desde el .npy guardado\n",
    "        keypoints_path = os.path.join(output_dir, \"custom_video_keypoints.npy\")\n",
    "        if os.path.exists(keypoints_path):\n",
    "            keypoints_array = np.load(keypoints_path)\n",
    "        else:\n",
    "            raise FileNotFoundError(\"No se encontr√≥ el archivo de keypoints.\")\n",
    "        # Para este ejemplo, asumimos que keypoints_array estar√° disponible tras la subida.\n",
    "\n",
    "\n",
    "    if 'video_path' in locals() and video_path and os.path.exists(video_path) and 'keypoints_array' in locals() and keypoints_array is not None:\n",
    "        output_dir = os.path.join(BASE, \"data/processed/custom_videos\")\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"Procesando v√≠deo: {video_path}\")\n",
    "        print(f\"Usando array de keypoints con forma: {keypoints_array.shape}\")\n",
    "        res_custom = run_inference_on_custom_video(video_path, keypoints_array, output_dir)\n",
    "        print(\"\\nProcesamiento del v√≠deo custom finalizado.\")\n",
    "        print(res_custom)\n",
    "\n",
    "        # Limpieza: eliminar el archivo temporal del v√≠deo al terminar\n",
    "        if 'video_path' in locals() and video_path and os.path.exists(video_path) and video_path.startswith(tempfile.gettempdir()):\n",
    "             os.remove(video_path)\n",
    "             print(f\"Archivo temporal de v√≠deo eliminado: {video_path}\")\n",
    "\n",
    "    else:\n",
    "        print(\"No se encontr√≥ el v√≠deo, la ruta del v√≠deo o el array de keypoints. No se puede continuar.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurri√≥ un error durante el procesamiento del v√≠deo custom: {e}\")\n",
    "    # Asegurar que el archivo temporal se elimine tambi√©n en caso de error\n",
    "    if 'video_path' in locals() and video_path and os.path.exists(video_path) and video_path.startswith(tempfile.gettempdir()):\n",
    "         os.remove(video_path)\n",
    "         print(f\"Archivo temporal eliminado por error: {video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1653f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualizaci√≥n de frames de un v√≠deo\n",
    "\n",
    "\n",
    "import os, math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Opcional (para modo slider)\n",
    "try:\n",
    "    from ipywidgets import interact, IntSlider\n",
    "    HAS_WIDGETS = True\n",
    "except Exception:\n",
    "    HAS_WIDGETS = False\n",
    "\n",
    "# -----------------------------\n",
    "# Config: intenta usar el v√≠deo anotado por defecto\n",
    "# -----------------------------\n",
    "BASE = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "DEFAULT_DIR = os.path.join(BASE, \"data/processed/custom_videos\")\n",
    "DEFAULT_ANNOTATED = os.path.join(DEFAULT_DIR, \"custom_video_annotated.mp4\")\n",
    "\n",
    "# Cambia esta ruta si quieres otro v√≠deo\n",
    "video_path = DEFAULT_ANNOTATED if os.path.exists(DEFAULT_ANNOTATED) else None\n",
    "print(\"V√≠deo detectado:\", video_path)\n",
    "\n",
    "# -----------------------------\n",
    "# Utilidades de v√≠deo\n",
    "# -----------------------------\n",
    "def get_video_info(path):\n",
    "    \"\"\"Devuelve diccionario con info b√°sica del v√≠deo.\"\"\"\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    assert cap.isOpened(), f\"No se pudo abrir el v√≠deo: {path}\"\n",
    "    fps   = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    nfrm  = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if cap.get(cv2.CAP_PROP_FRAME_COUNT) else 0\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height= int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    cap.release()\n",
    "    duration = nfrm / fps if fps > 0 and nfrm > 0 else 0\n",
    "    return {\"fps\": fps, \"frames\": nfrm, \"width\": width, \"height\": height, \"duration\": duration}\n",
    "\n",
    "def read_frame_at(path, t_sec=None, frame_index=None):\n",
    "    \"\"\"\n",
    "    Lee un frame en 't_sec' (segundos) o en 'frame_index'.\n",
    "    Devuelve (frame_rgb, idx, t_real_sec).\n",
    "    \"\"\"\n",
    "    assert os.path.exists(path), f\"No existe el archivo: {path}\"\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    assert cap.isOpened(), f\"No se pudo abrir el v√≠deo: {path}\"\n",
    "\n",
    "    fps  = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    nfrm = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if cap.get(cv2.CAP_PROP_FRAME_COUNT) else 0\n",
    "\n",
    "    if frame_index is None:\n",
    "        if t_sec is None:\n",
    "            t_sec = 0.0\n",
    "        frame_index = int(round(t_sec * fps))\n",
    "\n",
    "    frame_index = int(np.clip(frame_index, 0, max(0, nfrm-1)))\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "    ok, bgr = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    if not ok or bgr is None:\n",
    "        return None, frame_index, (frame_index / fps if fps > 0 else 0.0)\n",
    "\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    t_real = frame_index / fps if fps > 0 else 0.0\n",
    "    return rgb, frame_index, t_real\n",
    "\n",
    "def show_frame_at_time(path, t_sec):\n",
    "    \"\"\"Muestra un frame en el segundo 't_sec'.\"\"\"\n",
    "    info = get_video_info(path)\n",
    "    img, idx, t_real = read_frame_at(path, t_sec=t_sec)\n",
    "    if img is None:\n",
    "        print(\"No se pudo leer el frame.\")\n",
    "        return\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.imshow(img); plt.axis('off')\n",
    "    plt.title(f\"Frame {idx} @ {t_real:.2f}s  |  {info['width']}x{info['height']}  |  fps={info['fps']:.2f}\")\n",
    "    plt.show()\n",
    "\n",
    "def show_frames_grid(path, num_frames=12, cols=4, margin=0.02):\n",
    "    \"\"\"\n",
    "    Muestra una rejilla de 'num_frames' frames muestreados uniformemente.\n",
    "    \"\"\"\n",
    "    info = get_video_info(path)\n",
    "    n = info[\"frames\"]\n",
    "    if n <= 0:\n",
    "        print(\"No se pudo determinar el n√∫mero de frames.\")\n",
    "        return\n",
    "\n",
    "    # √çNDICES muestreados uniformemente (evita extremos por si hay negro)\n",
    "    idxs = np.linspace(int(n*0.02), max(int(n*0.98)-1, 0), num_frames).astype(int)\n",
    "    rows = int(math.ceil(num_frames / cols))\n",
    "    plt.figure(figsize=(4*cols, 3*rows))\n",
    "    for i, idx in enumerate(idxs):\n",
    "        img, _, t_real = read_frame_at(path, frame_index=idx)\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        if img is None:\n",
    "            plt.text(0.5, 0.5, f\"Frame {idx}\\nNo le√≠do\", ha='center', va='center')\n",
    "            plt.axis('off')\n",
    "        else:\n",
    "            plt.imshow(img); plt.axis('off')\n",
    "            plt.title(f\"{idx} ({t_real:.2f}s)\", fontsize=10)\n",
    "        plt.subplots_adjust(wspace=margin, hspace=margin)\n",
    "    plt.suptitle(f\"Rejilla de frames | total={n} | fps={info['fps']:.2f}\", y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "def show_slider(path):\n",
    "    \"\"\"\n",
    "    Slider interactivo para navegar frames.\n",
    "    Requiere ipywidgets; si no est√° disponible, avisa.\n",
    "    \"\"\"\n",
    "    if not HAS_WIDGETS:\n",
    "        print(\"ipywidgets no disponible. Instala con: !pip install ipywidgets y reinicia.\")\n",
    "        return\n",
    "    info = get_video_info(path)\n",
    "    n = info[\"frames\"]\n",
    "    def _show(idx):\n",
    "        img, _, t_real = read_frame_at(path, frame_index=idx)\n",
    "        plt.figure(figsize=(6,4))\n",
    "        if img is None:\n",
    "            plt.text(0.5, 0.5, f\"Frame {idx}\\nNo le√≠do\", ha='center', va='center')\n",
    "            plt.axis('off')\n",
    "        else:\n",
    "            plt.imshow(img); plt.axis('off')\n",
    "            plt.title(f\"Frame {idx} @ {t_real:.2f}s\")\n",
    "        plt.show()\n",
    "    interact(_show, idx=IntSlider(min=0, max=max(0,n-1), step=1, value=min(0, n//2)))\n",
    "\n",
    "\n",
    "# Ejemplos de uso\n",
    "if video_path:\n",
    "    info = get_video_info(video_path)\n",
    "    print(f\"Info: {info}\")\n",
    "    show_frames_grid(video_path, num_frames=12, cols=4)\n",
    "else:\n",
    "    print(\"No se encontr√≥ el v√≠deo por defecto. Ajusta la variable 'video_path' manualmente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b013f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Bootstrap robusto (imports + checks + carga artefactos)\n",
    "# =========================\n",
    "import os, glob, warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Imports que faltaban\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "\n",
    "\n",
    "\n",
    "#  Rutas base\n",
    "BASE        = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "ART         = f\"{BASE}/artifacts\"\n",
    "MODELS_DIR  = f\"{BASE}/models\"\n",
    "REPORTS_DIR = f\"{BASE}/reports\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)\n",
    "\n",
    "# 3) Verificaci√≥n de artefactos requeridos\n",
    "required = [\n",
    "    f\"{ART}/imputer.joblib\",\n",
    "    f\"{ART}/scaler.joblib\",\n",
    "    f\"{ART}/model_ovr_logreg.joblib\",\n",
    "    f\"{ART}/feature_cols.csv\",\n",
    "    f\"{ART}/label_names.csv\",\n",
    "]\n",
    "missing = [p for p in required if not os.path.exists(p)]\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        \"Faltan artefactos necesarios en ART:\\n  - \" + \"\\n  - \".join(missing)\n",
    "    )\n",
    "\n",
    "# 4) Carga artefactos (ya con pandas importado)\n",
    "imp          = load(f\"{ART}/imputer.joblib\")\n",
    "scaler       = load(f\"{ART}/scaler.joblib\")\n",
    "model_basic  = load(f\"{ART}/model_ovr_logreg.joblib\")\n",
    "feature_cols = pd.read_csv(f\"{ART}/feature_cols.csv\", header=None)[0].tolist()\n",
    "label_names  = pd.read_csv(f\"{ART}/label_names.csv\", header=None)[0].tolist()\n",
    "\n",
    "# 5) Diccionario de textos (si no existe)\n",
    "try:\n",
    "    label_to_text\n",
    "except NameError:\n",
    "    label_to_text = {ln: f\"Sugerencia para {ln}\" for ln in label_names}\n",
    "\n",
    "# 6) Utilidades de datos (con glob y Path ya disponibles)\n",
    "SEARCH_ROOTS = [\n",
    "    f\"{BASE}/data/aistppp\",\n",
    "    f\"{BASE}/data/AIST_ppp\",\n",
    "    f\"{BASE}/data/aistppp_features\",\n",
    "    f\"{BASE}/data/processed\",\n",
    "    f\"{BASE}/data/custom_videos/processed\",\n",
    "    f\"{BASE}/data/demo\",\n",
    "]\n",
    "\n",
    "def _align_features_df_any(df_like, cols):\n",
    "    \"\"\"Asegura DataFrame con columnas EXACTAS (ordenadas); rellena faltantes con NaN.\"\"\"\n",
    "    if isinstance(df_like, pd.DataFrame):\n",
    "        for c in cols:\n",
    "            if c not in df_like.columns:\n",
    "                df_like[c] = np.nan\n",
    "        return df_like[cols]\n",
    "    elif isinstance(df_like, (dict, pd.Series)):\n",
    "        return pd.DataFrame([{c: df_like.get(c, np.nan) for c in cols}])[cols]\n",
    "    else:\n",
    "        raise ValueError(\"Se esperaba DataFrame o dict/Series con nombres de columnas.\")\n",
    "\n",
    "def find_feature_files(roots=SEARCH_ROOTS):\n",
    "    files = []\n",
    "    for r in roots:\n",
    "        if not os.path.isdir(r):\n",
    "            continue\n",
    "        files += glob.glob(os.path.join(r, \"**\", \"features.parquet\"), recursive=True)\n",
    "        files += glob.glob(os.path.join(r, \"**\", \"features.csv\"), recursive=True)\n",
    "    return sorted(set(files))\n",
    "\n",
    "def load_video_features(path):\n",
    "    if path.endswith(\".parquet\"):\n",
    "        # Si falla por motor de parquet, instala pyarrow (ver arriba)\n",
    "        df = pd.read_parquet(path)\n",
    "    else:\n",
    "        df = pd.read_csv(path)\n",
    "    # normalizar variantes de tiempo\n",
    "    ren = {}\n",
    "    if \"start_sec\" not in df.columns and \"start_s\" in df.columns: ren[\"start_s\"] = \"start_sec\"\n",
    "    if \"end_sec\"   not in df.columns and \"end_s\"   in df.columns: ren[\"end_s\"]   = \"end_sec\"\n",
    "    if ren: df = df.rename(columns=ren)\n",
    "    return df, Path(path).parent.name\n",
    "\n",
    "def basic_predict_proba_df(df_feat):\n",
    "    \"\"\"imp + scaler + modelo b√°sico ‚Üí probabilidades multilabel (N, C).\"\"\"\n",
    "    Xdf  = _align_features_df_any(df_feat, feature_cols)\n",
    "    Ximp = imp.transform(Xdf)\n",
    "    Xs   = scaler.transform(Ximp)\n",
    "    proba = model_basic.predict_proba(Xs)\n",
    "    proba = np.asarray(proba, dtype=np.float32)\n",
    "    if proba.ndim == 1:\n",
    "        proba = proba[:, None]\n",
    "    return proba\n",
    "\n",
    "def build_sequence_dataset_from_features(files, seq_len=12, hop=6):\n",
    "    X_list, y_list, vids = [], [], []\n",
    "    for f in files:\n",
    "        df, vid = load_video_features(f)\n",
    "        # asegurar columnas del modelo b√°sico\n",
    "        for c in feature_cols:\n",
    "            if c not in df.columns:\n",
    "                df[c] = np.nan\n",
    "        Xw = df[feature_cols].astype(np.float32)\n",
    "        Yw = basic_predict_proba_df(Xw)  # (Nw, C)\n",
    "\n",
    "        N = len(Xw)\n",
    "        if N < seq_len:\n",
    "            continue\n",
    "        for s in range(0, N - seq_len + 1, hop):\n",
    "            e = s + seq_len\n",
    "            X_list.append(Xw.iloc[s:e].to_numpy(np.float32))\n",
    "            y_list.append(Yw[s:e].mean(axis=0).astype(np.float32))\n",
    "            vids.append(vid)\n",
    "\n",
    "    if not X_list:\n",
    "        return None\n",
    "\n",
    "    X = np.stack(X_list, 0)  # (Nseq, T, F)\n",
    "    y = np.stack(y_list, 0)  # (Nseq, C)\n",
    "    vids = np.array(vids)\n",
    "\n",
    "    uniq = np.unique(vids)\n",
    "    if len(uniq) >= 2:\n",
    "        np.random.shuffle(uniq)\n",
    "        n_val = max(1, int(round(0.2 * len(uniq))))\n",
    "        val_set = set(uniq[:n_val])\n",
    "        tr = np.array([v not in val_set for v in vids]); va = ~tr\n",
    "    else:\n",
    "        n = len(X)\n",
    "        cut = max(1, int(0.8 * n))\n",
    "        tr = np.zeros(n, bool); tr[:cut] = True; va = ~tr\n",
    "\n",
    "    return {\n",
    "        \"X_train\": X[tr], \"y_train\": y[tr],\n",
    "        \"X_val\":   X[va], \"y_val\":   y[va],\n",
    "        \"vids\": vids\n",
    "    }\n",
    "\n",
    "print(\" Artefactos y utilidades cargados correctamente.\")\n",
    "print(\"   - #feature_cols:\", len(feature_cols), \"| #labels:\", len(label_names))\n",
    "print(\"   - MODELS_DIR:\", MODELS_DIR)\n",
    "print(\"   - REPORTS_DIR:\", REPORTS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b8168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Setup, imports, rutas, hiperpar√°metros y flags\n",
    "\n",
    "import os, re, json, pickle, math, random, warnings, time, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    _HAS_SNS = True\n",
    "except Exception:\n",
    "    _HAS_SNS = False\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---- Rutas ----\n",
    "BASE        = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "DATA_DIR    = f\"{BASE}/data/annotations/aistpp/aist_plusplus_final\"\n",
    "MODELS_DIR  = f\"{BASE}/models\"\n",
    "REPORTS_DIR = f\"{BASE}/reports\"\n",
    "ART         = f\"{BASE}/artifacts\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)\n",
    "os.makedirs(ART, exist_ok=True)\n",
    "\n",
    "# ---- Hiperpar√°metros ----\n",
    "SEQ_LEN    = 30\n",
    "HOP        = 15\n",
    "MODEL_TYPE = \"lstm\"    # 'lstm' | 'bilstm' | 'transformer'\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS     = 50\n",
    "PATIENCE   = 10\n",
    "SEED       = 42\n",
    "\n",
    "# ---- Flags de ejecuci√≥n ----\n",
    "USE_CACHE      = True     # usa/crea cache de X,y,label_names en ART\n",
    "CLEAR_CACHE    = False    # fuerza ignorar caches\n",
    "LIMIT_FILES    = None     # p.ej. 200 para desarrollo r√°pido; None = todos\n",
    "VERBOSE_DATA   = True\n",
    "\n",
    "# ---- Semillas y GPU ---\n",
    "np.random.seed(SEED); random.seed(SEED); tf.random.set_seed(SEED)\n",
    "try:\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    for g in gpus:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    if gpus: print(f\"[GPU] {len(gpus)} GPU(s) detectadas.\")\n",
    "except Exception as e:\n",
    "    print(\"[GPU] Mem growth no aplicado:\", e)\n",
    "\n",
    "print(\"[OK] Entorno inicializado\")\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15388059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversi√≥n y limpieza de keypoints\n",
    "\n",
    "def to_TJD_from_any(obj):\n",
    "    \"\"\"Devuelve (T,J,D) con D in {2,3} o None.\"\"\"\n",
    "    arr = None\n",
    "    if isinstance(obj, dict):\n",
    "        for k in [\"keypoints3d\", \"joints3d\", \"poses_3d\", \"kp3d\", \"keypoints\"]:\n",
    "            if k in obj:\n",
    "                arr = np.array(obj[k]); break\n",
    "        if arr is None:\n",
    "            for v in obj.values():\n",
    "                if isinstance(v, np.ndarray):\n",
    "                    arr = v; break\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        arr = obj\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim != 3:\n",
    "        return None\n",
    "\n",
    "    T, A, B = arr.shape\n",
    "    for c in [arr, np.transpose(arr, (1,0,2)), np.transpose(arr, (0,2,1))]:\n",
    "        if c.shape[-1] in (2,3):\n",
    "            if c.shape[0] >= c.shape[1]:\n",
    "                return c.astype(np.float32)\n",
    "            else:\n",
    "                return np.transpose(c, (1,0,2)).astype(np.float32)\n",
    "    if A in (17,24,25) and B in (2,3):\n",
    "        return np.transpose(arr, (1,0,2)).astype(np.float32)\n",
    "    if B in (17,24,25) and A in (2,3):\n",
    "        return np.transpose(arr, (0,2,1)).astype(np.float32)\n",
    "    return None\n",
    "\n",
    "def clean_nan_interpolate(kp_TJD, min_valid_ratio=0.10):\n",
    "    \"\"\"Interpola NaNs temporalmente; descarta si ratio finitos < umbral.\"\"\"\n",
    "    x = kp_TJD.copy().astype(np.float32)\n",
    "    valid_ratio = np.isfinite(x).mean()\n",
    "    if valid_ratio < min_valid_ratio:\n",
    "        return None, valid_ratio\n",
    "    T,J,D = x.shape\n",
    "    for j in range(J):\n",
    "        for d in range(D):\n",
    "            series = x[:,j,d]\n",
    "            idx = np.where(np.isfinite(series))[0]\n",
    "            if len(idx) == 0:\n",
    "                x[:,j,d] = 0.0; continue\n",
    "            first, last = idx[0], idx[-1]\n",
    "            series[:first] = series[first]\n",
    "            series[last+1:] = series[last]\n",
    "            miss = np.where(~np.isfinite(series))[0]\n",
    "            if len(miss) > 0:\n",
    "                good = np.where(np.isfinite(series))[0]\n",
    "                x[miss,j,d] = np.interp(miss, good, series[good])\n",
    "    return x, valid_ratio\n",
    "\n",
    "def extract_label_from_filename(fname):\n",
    "    base = os.path.splitext(fname)[0]\n",
    "    m = re.search(r\"(ch\\d+)\", base)\n",
    "    return m.group(1) if m else base\n",
    "\n",
    "print(\"[OK] Funciones KP listas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91de3d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(kp_list, y_list, seq_len=SEQ_LEN, hop=HOP):\n",
    "    \"\"\"Devuelve X:[N,seq_len,J*D], y:[N,C].\"\"\"\n",
    "    X, Y = [], []\n",
    "    for kp, y in zip(kp_list, y_list):\n",
    "        T,J,D = kp.shape\n",
    "        if T <= 0: continue\n",
    "        for s in range(0, max(1, T - seq_len + 1), hop):\n",
    "            e = s + seq_len\n",
    "            if e <= T:\n",
    "                win = kp[s:e]\n",
    "            else:\n",
    "                pad = np.zeros((e - T, J, D), dtype=kp.dtype)\n",
    "                win = np.concatenate([kp[s:], pad], axis=0)\n",
    "            X.append(win.reshape(seq_len, J*D))\n",
    "            Y.append(y)\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    Y = np.asarray(Y, dtype=np.float32)\n",
    "    print(f\"[SEQ] X={X.shape} y={Y.shape} (seq_len={seq_len}, hop={hop})\")\n",
    "    return X, Y\n",
    "\n",
    "def dataset_cache_paths():\n",
    "    tag = f\"seq{SEQ_LEN}_hop{HOP}\"\n",
    "    return (os.path.join(ART, f\"aist_{tag}_X.npz\"),\n",
    "            os.path.join(ART, f\"aist_{tag}_y.npz\"),\n",
    "            os.path.join(ART, f\"aist_{tag}_label_names.json\"))\n",
    "\n",
    "def load_or_build_dataset():\n",
    "    X_path, y_path, ln_path = dataset_cache_paths()\n",
    "    if CLEAR_CACHE:\n",
    "        for p in [X_path, y_path, ln_path]:\n",
    "            if os.path.exists(p): os.remove(p)\n",
    "        print(\"[CACHE] Limpiado.\")\n",
    "\n",
    "    if USE_CACHE and all(os.path.exists(p) for p in [X_path, y_path, ln_path]):\n",
    "        print(\"[CACHE] Cargando dataset desde cache...\")\n",
    "        X = np.load(X_path)[\"X\"]; y = np.load(y_path)[\"y\"]\n",
    "        label_names = list(json.load(open(ln_path)))\n",
    "        print(f\"[CACHE] X:{X.shape} y:{y.shape} | clases={len(label_names)}\")\n",
    "        return X, y, label_names\n",
    "\n",
    "    print(\"[BUILD] Generando dataset (esto puede tardar)...\")\n",
    "    kp_list, y_list, label_names = load_aist_data()\n",
    "    X, y = prepare_sequences(kp_list, y_list, SEQ_LEN, HOP)\n",
    "\n",
    "    if USE_CACHE:\n",
    "        np.savez_compressed(X_path, X=X)\n",
    "        np.savez_compressed(y_path, y=y)\n",
    "        with open(ln_path, \"w\") as f: json.dump(label_names, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"[CACHE] Guardado: {X_path} | {y_path} | {ln_path}\")\n",
    "\n",
    "    # libera memoria\n",
    "    del kp_list, y_list; gc.collect()\n",
    "    return X, y, label_names\n",
    "\n",
    "print(\"[OK] Ventanas + cache listo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf2fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_lstm_model(input_shape, num_labels):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Masking(mask_value=0., input_shape=input_shape),\n",
    "        tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.2),\n",
    "        tf.keras.layers.LSTM(64, dropout=0.3, recurrent_dropout=0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(num_labels, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_bilstm_model(input_shape, num_labels):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Masking(mask_value=0., input_shape=input_shape),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.2)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, dropout=0.3, recurrent_dropout=0.2)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(num_labels, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_transformer_model(input_shape, num_labels):\n",
    "    \"\"\"Transformer simple con proyecci√≥n para residual.\"\"\"\n",
    "    seq_len, d_model = input_shape\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    pos = tf.range(start=0, limit=seq_len, delta=1)\n",
    "    pos_emb = tf.keras.layers.Embedding(input_dim=seq_len, output_dim=d_model)(pos)  # [T,d_model]\n",
    "    x = inputs + pos_emb  # broadcast sobre batch\n",
    "\n",
    "    attn = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=max(1, d_model//8))(x, x)\n",
    "    attn = tf.keras.layers.Dense(d_model)(attn)  # asegura misma dim para residual\n",
    "    x = tf.keras.layers.Add()([x, attn])\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    ffn = tf.keras.Sequential([tf.keras.layers.Dense(128, activation='relu'),\n",
    "                               tf.keras.layers.Dense(d_model)])(x)\n",
    "    x = tf.keras.layers.Add()([x, ffn])\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    outputs = tf.keras.layers.Dense(num_labels, activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "print(\"[OK] Modelos listos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb02253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, model_type):\n",
    "    hist = history.history\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    ax1.plot(hist.get('loss', []), label='Train')\n",
    "    if 'val_loss' in hist: ax1.plot(hist['val_loss'], label='Val')\n",
    "    ax1.set_title(f'P√©rdida - {model_type.upper()}'); ax1.set_xlabel('√âpoca'); ax1.set_ylabel('Loss'); ax1.legend()\n",
    "\n",
    "    mkey = 'binary_accuracy' if 'binary_accuracy' in hist else ('accuracy' if 'accuracy' in hist else None)\n",
    "    if mkey:\n",
    "        ax2.plot(hist[mkey], label='Train')\n",
    "        if f\"val_{mkey}\" in hist: ax2.plot(hist[f\"val_{mkey}\"], label='Val')\n",
    "        ax2.set_title(f'{mkey} - {model_type.upper()}'); ax2.set_xlabel('√âpoca'); ax2.set_ylabel(mkey); ax2.legend()\n",
    "    else:\n",
    "        ax2.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_png = os.path.join(REPORTS_DIR, f\"{MODEL_TYPE}_training_curves.png\")\n",
    "    plt.savefig(out_png, dpi=150); plt.show()\n",
    "    print(f\"[OK] Curvas guardadas en: {out_png}\")\n",
    "\n",
    "def _safe_evaluate(model, X, y):\n",
    "    try:\n",
    "        out = model.evaluate(X, y, verbose=0, return_dict=True)\n",
    "        if isinstance(out, dict):\n",
    "            return out\n",
    "    except TypeError:\n",
    "        pass\n",
    "    vals = model.evaluate(X, y, verbose=0)\n",
    "    names = getattr(model, \"metrics_names\", None)\n",
    "    if names and isinstance(vals, (list, tuple)):\n",
    "        return {n: float(v) for n, v in zip(names, vals)}\n",
    "    return {\"loss\": float(vals) if np.isscalar(vals) else float(vals[0])}\n",
    "\n",
    "def generate_evaluation_report(model, X_test, y_test, model_type, label_names):\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    y_bin  = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    if len(label_names) != y_test.shape[1]:\n",
    "        print(\"[WARN] target_names ‚â† n¬∫ clases; usar√© nombres gen√©ricos.\")\n",
    "        label_names = [f\"cls_{i}\" for i in range(y_test.shape[1])]\n",
    "\n",
    "    report = classification_report(y_test, y_bin, target_names=label_names, output_dict=True, zero_division=0)\n",
    "    rp_path = os.path.join(REPORTS_DIR, f\"{model_type}_classification_report.csv\")\n",
    "    pd.DataFrame(report).transpose().to_csv(rp_path)\n",
    "    print(f\"[OK] Reporte de clasificaci√≥n en: {rp_path}\")\n",
    "\n",
    "    # Matriz de confusi√≥n para UNA etiqueta (binaria)\n",
    "    if _HAS_SNS and y_test.shape[1] > 0:\n",
    "        present = np.where(np.any(y_test, axis=0) | np.any(y_bin, axis=0))[0]\n",
    "        if len(present) > 0:\n",
    "            idx0 = int(present[0])\n",
    "            cm = confusion_matrix(y_test[:, idx0], y_bin[:, idx0])\n",
    "            plt.figure(figsize=(7,6))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                        xticklabels=[\"Pred 0\",\"Pred 1\"],\n",
    "                        yticklabels=[\"Real 0\",\"Real 1\"])\n",
    "            plt.title(f'Confusi√≥n - {model_type.upper()} - {label_names[idx0]}')\n",
    "            plt.ylabel('Real'); plt.xlabel('Predicha')\n",
    "            cm_path = os.path.join(REPORTS_DIR, f\"{model_type}_confusion_matrix.png\")\n",
    "            plt.savefig(cm_path, dpi=150); plt.show()\n",
    "            print(f\"[OK] Matriz de confusi√≥n en: {cm_path}\")\n",
    "        else:\n",
    "            print(\"[INFO] Sin clases presentes para matriz de confusi√≥n.\")\n",
    "    else:\n",
    "        print(\"[INFO] seaborn no disponible o sin clases -> sin matriz de confusi√≥n.\")\n",
    "\n",
    "    metrics = _safe_evaluate(model, X_test, y_test)\n",
    "    metrics.update({\n",
    "        \"model_type\": model_type,\n",
    "        \"input_shape\": tuple(int(x) for x in X_test.shape[1:]),\n",
    "        \"num_samples\": int(len(X_test))\n",
    "    })\n",
    "    with open(os.path.join(REPORTS_DIR, f\"{model_type}_metrics.json\"), \"w\") as f:\n",
    "        json.dump({k: float(v) if not isinstance(v, str) else v for k, v in metrics.items()}, f, indent=2)\n",
    "    print(f\"[OK] M√©tricas guardadas en: {os.path.join(REPORTS_DIR, f'{model_type}_metrics.json')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b4a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamiento + Evaluaci√≥n\n",
    "\n",
    "def train_and_evaluate():\n",
    "    X, y, label_names = load_or_build_dataset()\n",
    "    assert len(X) > 0 and len(y) > 0, \"No hay datos preparados.\"\n",
    "\n",
    "    unique_classes = np.unique(np.argmax(y, axis=1))\n",
    "    if len(unique_classes) > 1:\n",
    "        y_int = np.argmax(y, axis=1)\n",
    "        try:\n",
    "            X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y_int)\n",
    "        except ValueError as e:\n",
    "            print(\"[WARN] Stratify fall√≥:\", e)\n",
    "            X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "        try:\n",
    "            y_tr_int = np.argmax(y_tr, axis=1)\n",
    "            X_tr, X_va, y_tr, y_va = train_test_split(X_tr, y_tr, test_size=0.2, random_state=SEED, stratify=y_tr_int)\n",
    "        except ValueError as e:\n",
    "            print(\"[WARN] Stratify val fall√≥:\", e)\n",
    "            X_tr, X_va, y_tr, y_va = train_test_split(X_tr, y_tr, test_size=0.2, random_state=SEED)\n",
    "    else:\n",
    "        print(\"[WARN] Solo una clase. Split sin estratificar.\")\n",
    "        X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "        X_tr, X_va, y_tr, y_va = train_test_split(X_tr, y_tr, test_size=0.2, random_state=SEED)\n",
    "\n",
    "    print(f\"[SPLIT] Train={X_tr.shape} | Val={X_va.shape} | Test={X_te.shape}\")\n",
    "\n",
    "    input_shape = X_tr.shape[1:]\n",
    "    num_labels  = y_tr.shape[1]\n",
    "\n",
    "    if MODEL_TYPE == \"lstm\":\n",
    "        model = create_lstm_model(input_shape, num_labels)\n",
    "    elif MODEL_TYPE == \"bilstm\":\n",
    "        model = create_bilstm_model(input_shape, num_labels)\n",
    "    elif MODEL_TYPE == \"transformer\":\n",
    "        model = create_transformer_model(input_shape, num_labels)\n",
    "    else:\n",
    "        raise ValueError(\"MODEL_TYPE debe ser 'lstm' | 'bilstm' | 'transformer'.\")\n",
    "\n",
    "    ckpt_path = os.path.join(MODELS_DIR, f\"best_{MODEL_TYPE}_model.h5\")\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=max(1, PATIENCE//2), min_lr=1e-7, verbose=1),\n",
    "        ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True, save_weights_only=False, verbose=1)\n",
    "    ]\n",
    "\n",
    "    print(f\"[TRAIN] {MODEL_TYPE.upper()} ...\")\n",
    "    history = model.fit(\n",
    "        X_tr, y_tr,\n",
    "        validation_data=(X_va, y_va),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    metrics = _safe_evaluate(model, X_te, y_te)\n",
    "    loss = metrics.get(\"loss\", np.nan)\n",
    "    acc  = metrics.get(\"accuracy\", np.nan)\n",
    "    bacc = metrics.get(\"binary_accuracy\", np.nan)\n",
    "    print(f\"[TEST] loss={loss:.4f} | acc={acc:.4f} | bin_acc={bacc:.4f}\")\n",
    "\n",
    "    final_path = os.path.join(MODELS_DIR, f\"final_{MODEL_TYPE}_model.h5\")\n",
    "    model.save(final_path)\n",
    "    print(f\"[OK] Modelo final guardado en: {final_path}\")\n",
    "\n",
    "    hist_path = os.path.join(REPORTS_DIR, f\"{MODEL_TYPE}_training_history.csv\")\n",
    "    pd.DataFrame(history.history).to_csv(hist_path, index=False)\n",
    "    print(f\"[OK] Historial guardado en: {hist_path}\")\n",
    "\n",
    "    plot_training_history(history, MODEL_TYPE)\n",
    "    generate_evaluation_report(model, X_te, y_te, MODEL_TYPE, label_names)\n",
    "\n",
    "    return model, history, metrics, label_names\n",
    "\n",
    "print(\"[OK] train_and_evaluate listo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4e0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo con best model\n",
    "\n",
    "def run_demo_with_best_model(label_names):\n",
    "    best_path = os.path.join(MODELS_DIR, f\"best_{MODEL_TYPE}_model.h5\")\n",
    "    if not os.path.exists(best_path):\n",
    "        print(\"[INFO] No hay best model; salto demo.\")\n",
    "        return\n",
    "    print(f\"[DEMO] Cargando: {best_path}\")\n",
    "    model = tf.keras.models.load_model(best_path)\n",
    "\n",
    "    X, y, _ = load_or_build_dataset()\n",
    "    if len(X) == 0:\n",
    "        print(\"[DEMO] No hay datos.\"); return\n",
    "    demo_idx = 0\n",
    "    y_pred = model.predict(X[demo_idx:demo_idx+1], verbose=0)[0]\n",
    "    top = np.argsort(y_pred)[::-1][:min(5, len(label_names))]\n",
    "    print(\"\\n=== DEMO: Top predicciones ===\")\n",
    "    for i, j in enumerate(top, 1):\n",
    "        print(f\"{i}. {label_names[j]}: {y_pred[j]:.3f}\")\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.bar(range(len(y_pred)), y_pred)\n",
    "    plt.xlabel(\"Clases\"); plt.ylabel(\"Prob.\"); plt.title(f\"Predicciones ({MODEL_TYPE.upper()})\")\n",
    "    plt.xticks(range(len(label_names)), label_names, rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    demo_png = os.path.join(REPORTS_DIR, f\"{MODEL_TYPE}_demo_predictions.png\")\n",
    "    plt.savefig(demo_png, dpi=150); plt.show()\n",
    "    print(f\"[OK] Demo guardada en: {demo_png}\")\n",
    "\n",
    "print(\"[OK] Demo listo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb3f8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Sustituye SOLO esta funci√≥n por la versi√≥n de abajo ===\n",
    "import tempfile, shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "def export_best_model_to_onnx(model_type=None, models_dir=None, opset_candidates=(17, 15, 13)):\n",
    "    \"\"\"\n",
    "    Exporta a ONNX de forma robusta:\n",
    "      1) Carga el mejor .keras/.h5 (o lo reconstruye si s√≥lo hay pesos).\n",
    "      2) Intenta convertir con ConcreteFunction (from_function).\n",
    "      3) Si falla, exporta a SavedModel y convierte desde ah√≠.\n",
    "    \"\"\"\n",
    "    model_type = model_type or MODEL_TYPE\n",
    "    models_dir = models_dir or MODELS_DIR\n",
    "\n",
    "    # 1) Obtener el modelo listo\n",
    "    best_path = _ensure_best_model_file(model_type)  # usa tu helper\n",
    "    model = tf.keras.models.load_model(best_path)\n",
    "\n",
    "    # 2) Deducir la forma de entrada (T,F)\n",
    "    in_shape = model.inputs[0].shape  # (None, T, F)\n",
    "    T = int(in_shape[1]) if in_shape[1] is not None else SEQ_LEN\n",
    "    Fok = int(in_shape[2]) if in_shape[2] is not None else (F or 0)\n",
    "    assert T > 0 and Fok > 0, f\"Input shape inv√°lido: {in_shape}\"\n",
    "\n",
    "    # 3) Firma de entrada expl√≠cita\n",
    "    spec = [tf.TensorSpec([None, T, Fok], tf.float32, name=\"input\")]\n",
    "    onnx_out = os.path.join(models_dir, f\"best_{model_type}_model.onnx\")\n",
    "\n",
    "    last_err = None\n",
    "    for ops in opset_candidates:\n",
    "        print(f\"[ONNX] Exportando con opset={ops} ...\")\n",
    "\n",
    "        # ---- A) Intento: ConcreteFunction (compatible Keras 3) ----\n",
    "        try:\n",
    "            @tf.function(input_signature=spec)\n",
    "            def _wrapped(x):\n",
    "                return model(x)\n",
    "            concrete = _wrapped.get_concrete_function()\n",
    "\n",
    "            _onnx_model, _ = tf2onnx.convert.from_function(\n",
    "                concrete_function=concrete,\n",
    "                opset=ops,\n",
    "                input_signature=spec,\n",
    "                output_path=onnx_out\n",
    "            )\n",
    "            print(f\"[OK] Exportado (from_function) ‚Üí {onnx_out}\")\n",
    "            return onnx_out, (T, Fok)\n",
    "        except Exception as e_func:\n",
    "            last_err = e_func\n",
    "            print(f\"[WARN] Falla from_function (opset={ops}): {e_func}\")\n",
    "\n",
    "        # ---- B) Fallback: SavedModel ‚Üí ONNX ----\n",
    "        tmpdir = tempfile.mkdtemp(prefix=\"savedmodel_for_onnx_\")\n",
    "        try:\n",
    "            # Keras 3 tiene .export; si no, usamos tf.saved_model.save\n",
    "            try:\n",
    "                model.export(tmpdir)  # Keras 3\n",
    "            except Exception:\n",
    "                tf.saved_model.save(model, tmpdir)  # Keras 2.x compat\n",
    "\n",
    "            _onnx_model, _ = tf2onnx.convert.from_saved_model(\n",
    "                saved_model_dir=tmpdir,\n",
    "                opset=ops,\n",
    "                output_path=onnx_out\n",
    "            )\n",
    "            print(f\"[OK] Exportado (from_saved_model) ‚Üí {onnx_out}\")\n",
    "            return onnx_out, (T, Fok)\n",
    "        except Exception as e_sm:\n",
    "            last_err = (last_err, e_sm)\n",
    "            print(f\"[WARN] Falla from_saved_model (opset={ops}): {e_sm}\")\n",
    "        finally:\n",
    "            shutil.rmtree(tmpdir, ignore_errors=True)\n",
    "\n",
    "    raise RuntimeError(f\"No se pudo exportar a ONNX. √öltimo error: {last_err}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e778ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTEGRACION FINAL: PIPELINE COMPLETO para un v√≠deo subido por el usuario\n",
    "# - Sube v√≠deo del usuario\n",
    "# - Procesa con MediaPipe para keypoints\n",
    "# - Ejecuta an√°lisis b√°sico (features + sugerencias b√°sicas)\n",
    "# - Carga/usa modelo avanzado (LSTM/Transformer entrenado previamente)\n",
    "# - Ejecuta inferencia avanzada (predicci√≥n por secuencias)\n",
    "# - Combina sugerencias (b√°sicas + avanzadas)\n",
    "# - Visualiza resultados (anota v√≠deo)\n",
    "\n",
    "\n",
    "import os, json, math, io, glob, tempfile\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score, precision_recall_curve, roc_curve\n",
    "from joblib import load\n",
    "from google.colab import files\n",
    "\n",
    "# --- Variables base (compatibles con celdas 1‚Äì11) ---\n",
    "try:\n",
    "    BASE\n",
    "except NameError:\n",
    "    BASE = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "\n",
    "try:\n",
    "    MODEL_TYPE\n",
    "except NameError:\n",
    "    MODEL_TYPE = \"lstm\"  # 'lstm' | 'bilstm' | 'transformer'\n",
    "\n",
    "MODELS_DIR  = f\"{BASE}/models\"\n",
    "REPORTS_DIR = f\"{BASE}/reports\"\n",
    "ART_DIR     = f\"{BASE}/artifacts\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)\n",
    "\n",
    "# --- Cargar artefactos del modelo b√°sico (si existen) ---\n",
    "try:\n",
    "    imp          = load(f\"{ART_DIR}/imputer.joblib\")\n",
    "    scaler       = load(f\"{ART_DIR}/scaler.joblib\")\n",
    "    model_basic  = load(f\"{ART_DIR}/model_ovr_logreg.joblib\")\n",
    "    feature_cols = pd.read_csv(f\"{ART_DIR}/feature_cols.csv\", header=None)[0].tolist()\n",
    "    label_names  = pd.read_csv(f\"{ART_DIR}/label_names.csv\", header=None)[0].tolist()\n",
    "    print(\"Loaded basic model artifacts.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load basic model artifacts: {e}\")\n",
    "    imp = None; scaler = None; model_basic = None\n",
    "    feature_cols = []\n",
    "    label_names  = [\"label1\", \"label2\", \"label3\"]  # fallback\n",
    "\n",
    "# --- Unificar label_names con clases del modelo avanzado (si existen) ---\n",
    "classes_json = os.path.join(ART_DIR, \"classes.json\")\n",
    "if os.path.exists(classes_json):\n",
    "    try:\n",
    "        label_names_adv = json.load(open(classes_json))\n",
    "        if isinstance(label_names_adv, list) and len(label_names_adv) > 0:\n",
    "            label_names = label_names_adv\n",
    "            print(f\"Using label_names from classes.json ({len(label_names)})\")\n",
    "    except Exception as e:\n",
    "        print(\"WARN: could not read classes.json:\", e)\n",
    "\n",
    "# --- Mapa de sugerencias ---\n",
    "try:\n",
    "    label_to_text\n",
    "except NameError:\n",
    "    label_to_text = {ln: f\"Sugerencia para {ln}\" for ln in label_names}\n",
    "\n",
    "# --- Utilidades ---\n",
    "def ensure_dir(p): os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def sliding_windows(X, win_len=100, hop=20):\n",
    "    \"\"\"X: (T, F) -> (Nw, win_len, F) + √≠ndices [(s,e),...]. Padding si T<win_len.\"\"\"\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    T, F = X.shape\n",
    "    if T <= 0:\n",
    "        return np.zeros((0, win_len, F), dtype=np.float32), []\n",
    "    if T < win_len:\n",
    "        pad = np.zeros((win_len - T, F), dtype=np.float32)\n",
    "        Xp = np.vstack([X, pad])\n",
    "        return np.expand_dims(Xp, 0), [(0, min(T, win_len))]\n",
    "    idx, ws = [], []\n",
    "    for s in range(0, T - win_len + 1, hop):\n",
    "        e = s + win_len\n",
    "        ws.append(X[s:e])\n",
    "        idx.append((s, e))\n",
    "    return np.stack(ws, axis=0), idx\n",
    "\n",
    "def plot_topk_bars(scores_vec, labels, k=10, title=\"Top etiquetas\"):\n",
    "    scores = np.array(scores_vec).astype(float)\n",
    "    if scores.ndim > 1: scores = scores.mean(axis=0)\n",
    "    k = min(k, len(labels))\n",
    "    idx = np.argsort(scores)[::-1][:k]\n",
    "    plt.figure(figsize=(8, max(4, 0.45*k)))\n",
    "    plt.barh(range(k), scores[idx])\n",
    "    plt.yticks(range(k), [labels[i] for i in idx]); plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"Score\"); plt.title(title); plt.tight_layout(); plt.show()\n",
    "\n",
    "def plot_window_heatmap(win_scores, labels, win_idx, title=\"Heatmap temporal (ventanas x etiquetas)\"):\n",
    "    if win_scores is None or len(win_scores)==0:\n",
    "        print(\"No hay puntuaciones por ventana para heatmap.\")\n",
    "        return\n",
    "    H = np.asarray(win_scores)\n",
    "    plt.figure(figsize=(min(14, 2 + 0.6*H.shape[0]), 0.5*H.shape[1] + 2))\n",
    "    plt.imshow(H.T, aspect=\"auto\", interpolation=\"nearest\")\n",
    "    plt.yticks(range(len(labels)), labels)\n",
    "    xt = [f\"{s}-{e}\" for (s,e) in win_idx]\n",
    "    plt.xticks(range(len(win_idx)), xt, rotation=45, ha='right')\n",
    "    plt.xlabel(\"Ventanas (frames)\"); plt.ylabel(\"Etiquetas\")\n",
    "    plt.title(title); plt.tight_layout(); plt.show()\n",
    "\n",
    "def overlay_text_on_video(video_path, timeline, out_path, max_lines=4):\n",
    "    \"\"\"Escribe sugerencias activas en cada frame y exporta MP4 anotado.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"No se pudo abrir el v√≠deo: {video_path}\")\n",
    "        return None\n",
    "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    FPS = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    vw = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), FPS, (W,H))\n",
    "    t = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        active = []\n",
    "        for seg in timeline:\n",
    "            if int(seg[\"start_f\"]) <= t <= int(seg[\"end_f\"]):\n",
    "                active = seg.get(\"sugerencias\", [])\n",
    "        y0 = 30\n",
    "        for s in active[:max_lines]:\n",
    "            cv2.putText(frame, f\"‚Ä¢ {s}\", (20, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 4, cv2.LINE_AA)\n",
    "            cv2.putText(frame, f\"‚Ä¢ {s}\", (20, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "            y0 += 28\n",
    "        vw.write(frame); t += 1\n",
    "    cap.release(); vw.release()\n",
    "    return out_path\n",
    "\n",
    "def _normalize_combined_suggestions(sug_list, default_conf=0.4, default_source=\"basic_model\"):\n",
    "    \"\"\"Normaliza lista de sugerencias a [{'suggestion','confidence','source'}, ...].\"\"\"\n",
    "    out = []\n",
    "    for s in (sug_list or []):\n",
    "        if isinstance(s, dict):\n",
    "            out.append({\n",
    "                \"suggestion\": str(s.get(\"suggestion\",\"\")),\n",
    "                \"confidence\": float(s.get(\"confidence\", default_conf)),\n",
    "                \"source\": s.get(\"source\", default_source)\n",
    "            })\n",
    "        else:\n",
    "            out.append({\"suggestion\": str(s), \"confidence\": float(default_conf), \"source\": default_source})\n",
    "    return out\n",
    "\n",
    "# --- Entrada / extracci√≥n de v√≠deo ---\n",
    "def upload_video():\n",
    "    \"\"\"Permite al usuario subir un v√≠deo desde su dispositivo (interfaz de Colab).\"\"\"\n",
    "    uploaded = files.upload()\n",
    "    if not uploaded:\n",
    "        print(\"No se subi√≥ ning√∫n archivo.\")\n",
    "        return None\n",
    "    video_name = list(uploaded.keys())[0]\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(video_name)[1]) as temp_video_file:\n",
    "        temp_video_file.write(uploaded[video_name])\n",
    "        video_path = temp_video_file.name\n",
    "    print(f\"V√≠deo '{video_name}' subido y guardado temporalmente en: {video_path}\")\n",
    "    return video_path\n",
    "\n",
    "def process_video_with_mediapipe(video_path, output_dir):\n",
    "    \"\"\"Procesa v√≠deo con MediaPipe Pose y guarda keypoints (33*4 por frame).\"\"\"\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=False, model_complexity=2, enable_segmentation=False, min_detection_confidence=0.5)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"No se pudo abrir el v√≠deo para MediaPipe: {video_path}\")\n",
    "        return None, None\n",
    "    all_keypoints = []; frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb_frame)\n",
    "        if results.pose_landmarks:\n",
    "            frame_keypoints = []\n",
    "            for landmark in results.pose_landmarks.landmark:\n",
    "                frame_keypoints.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "            all_keypoints.append(frame_keypoints)\n",
    "        else:\n",
    "            all_keypoints.append([np.nan] * 33 * 4)\n",
    "        frame_count += 1\n",
    "        if frame_count % 100 == 0:\n",
    "            print(f\"Procesados {frame_count} frames...\")\n",
    "    cap.release()\n",
    "    if not all_keypoints:\n",
    "        print(\"No keypoints extracted from the video.\")\n",
    "        return None, None\n",
    "    keypoints_array = np.array(all_keypoints)\n",
    "    output_path = os.path.join(output_dir, \"custom_video_keypoints.npy\")\n",
    "    np.save(output_path, keypoints_array)\n",
    "    print(f\"Keypoints saved to: {output_path}\")\n",
    "    return keypoints_array, output_path\n",
    "\n",
    "# --- Features coreogr√°ficos b√°sicos con MediaPipe ---\n",
    "def interpolate_nan_1d(y):\n",
    "    y = y.astype(np.float32); T = len(y); idx = np.arange(T); mask = np.isfinite(y)\n",
    "    if mask.sum() == 0: return y\n",
    "    last = np.nan\n",
    "    for i in range(T):\n",
    "        if not np.isfinite(y[i]) and np.isfinite(last): y[i] = last\n",
    "        else: last = y[i]\n",
    "    last = np.nan\n",
    "    for i in range(T-1,-1,-1):\n",
    "        if not np.isfinite(y[i]) and np.isfinite(last): y[i] = last\n",
    "        else: last = y[i]\n",
    "    mask = np.isfinite(y)\n",
    "    if 2 <= mask.sum() < T: y[~mask] = np.interp(idx[~mask], idx[mask], y[mask])\n",
    "    return y\n",
    "\n",
    "def clean_nan_interpolate(K, min_valid_ratio=0.10):\n",
    "    Kc = K.copy(); T,J,D = Kc.shape; used = []\n",
    "    for j in range(J):\n",
    "        valid = np.isfinite(Kc[:,j,:]).all(axis=1)\n",
    "        if valid.mean() < min_valid_ratio: Kc[:,j,:] = np.nan; continue\n",
    "        for d in range(D): Kc[:,j,d] = interpolate_nan_1d(Kc[:,j,d])\n",
    "        if np.isfinite(Kc[:,j,:]).any(): used.append(j)\n",
    "    if not used:\n",
    "        print(\"No hay articulaciones v√°lidas tras limpieza e interpolaci√≥n.\")\n",
    "        return Kc, []\n",
    "    return Kc[:,used,:], used\n",
    "\n",
    "def features_coreograficos_mediapipe(K):\n",
    "    \"\"\"Resumen de features robusto para sugerencias b√°sicas.\"\"\"\n",
    "    T,J,D = K.shape\n",
    "    K_2d = K[:,:,:2]\n",
    "\n",
    "    amp_mean = (np.nanmax(K_2d, axis=0) - np.nanmin(K_2d, axis=0)).mean(axis=0)\n",
    "    amp_x = float(amp_mean[0]); amp_y = float(amp_mean[1])\n",
    "\n",
    "    vel = np.linalg.norm(np.diff(K_2d, axis=0), axis=2)\n",
    "    vel_media = float(np.nanmean(vel)) if vel.size else 0.0\n",
    "\n",
    "    MEDIAPIPE_COCO_PAIRS_SIMPLIFIED = [(11,12), (13,14), (15,16), (23,24), (25,26), (27,28)]\n",
    "    pair_vals=[]\n",
    "    for a,b in MEDIAPIPE_COCO_PAIRS_SIMPLIFIED:\n",
    "        if a < J and b < J:\n",
    "            diff = K_2d[:,a,:] - K_2d[:,b,:]     # [T,2]\n",
    "            d = np.linalg.norm(diff, axis=1)     # [T]\n",
    "            pair_vals.append(np.nanmean(d))\n",
    "    sim_raw = float(np.nanmean(pair_vals)) if pair_vals else np.nan\n",
    "\n",
    "    com = (K[:,23,:2] + K[:,24,:2]) / 2 if J >= 25 else K[:,:,:2].mean(axis=1)\n",
    "    nivel_p10 = float(np.nanpercentile(com[:,1], 10))\n",
    "    nivel_p90 = float(np.nanpercentile(com[:,1], 90))\n",
    "    nivel_rango = float(nivel_p10 - nivel_p90)\n",
    "\n",
    "    disp = np.diff(com,axis=0)\n",
    "    dirs = np.arctan2(disp[:,1], disp[:,0] + 1e-9)\n",
    "    cambios = np.abs(np.diff(dirs))\n",
    "    variedad_dir = float(np.nanmean(cambios)) if len(cambios)>0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"amplitud_x\": amp_x, \"amplitud_y\": amp_y, \"velocidad_media\": vel_media,\n",
    "        \"simetria\": sim_raw, \"nivel_rango\": nivel_rango, \"variedad_direcciones\": variedad_dir,\n",
    "        \"frames\": int(T), \"joints\": int(J), \"dims\": int(D)\n",
    "    }\n",
    "\n",
    "def inferir_desde_features_dict(feats: dict):\n",
    "    \"\"\"Inferencia con pipeline b√°sico (imputer + scaler + OVR-LogReg).\"\"\"\n",
    "    if imp is None or scaler is None or model_basic is None or not feature_cols or not label_names:\n",
    "        print(\"Cannot perform basic inference: missing basic model artifacts or labels/features.\")\n",
    "        return [], []\n",
    "    x = np.array([[feats.get(c, np.nan) for c in feature_cols]], dtype=float)\n",
    "    x_imp = imp.transform(x)\n",
    "    x_scaled = scaler.transform(x_imp)\n",
    "    if hasattr(model_basic, 'predict'):\n",
    "        yhat = model_basic.predict(x_scaled)[0]\n",
    "        predicted_labels = [label_names[i] for i, v in enumerate(yhat) if v==1]\n",
    "        sugerencias = [label_to_text.get(lbl, lbl) for lbl in predicted_labels]\n",
    "        return predicted_labels, sugerencias\n",
    "    else:\n",
    "        print(\"Basic model does not have 'predict'.\")\n",
    "        return [], []\n",
    "\n",
    "def run_basic_analysis(video_path, keypoints_array, output_dir, win_sec=5.0, hop_sec=2.5):\n",
    "    \"\"\"Ejecuta an√°lisis b√°sico por ventanas; devuelve timeline y keypoints procesados.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    FPS = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    cap.release()\n",
    "\n",
    "    T = keypoints_array.shape[0]; J = 33; D = 4\n",
    "    K_raw = keypoints_array.reshape(T, J, D)\n",
    "\n",
    "    Kc, used = clean_nan_interpolate(K_raw, min_valid_ratio=0.10)\n",
    "    if not used:\n",
    "        print(\"No hay articulaciones v√°lidas tras limpieza/interpolaci√≥n.\")\n",
    "        return {\"csv\": None, \"video\": video_path, \"timeline\": [], \"processed_keypoints\": None, \"suggestions\": []}\n",
    "\n",
    "    win = max(1, int(round(win_sec * FPS)))\n",
    "    hop = max(1, int(round(hop_sec * FPS)))\n",
    "    T_clean = len(Kc)\n",
    "\n",
    "    rows = []; timeline = []; suggestions_list = []\n",
    "    for start in range(0, T_clean - 1, hop):\n",
    "        end = min(T_clean - 1, start + win)\n",
    "        if end - start < max(8, int(0.25 * win)): break\n",
    "        Kw = Kc[start:end]\n",
    "        feats = features_coreograficos_mediapipe(Kw)\n",
    "        labels, suggs = inferir_desde_features_dict(feats)\n",
    "\n",
    "        timeline.append({\"start_f\": int(start), \"end_f\": int(end), \"sugerencias\": suggs})\n",
    "        suggestions_list.extend(suggs)\n",
    "\n",
    "        row = {\"start_f\": int(start), \"end_f\": int(end), \"start_s\": start / FPS, \"end_s\": end / FPS}\n",
    "        row.update(feats)\n",
    "        row[\"labels\"] = \"|\".join(labels)\n",
    "        row[\"sugerencias\"] = \"|\".join(suggs)\n",
    "        rows.append(row)\n",
    "\n",
    "    out_csv = os.path.join(output_dir, \"custom_video_suggestions_timeline.csv\")\n",
    "    pd.DataFrame(rows).to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Sugerencias (timeline) guardadas en: {out_csv}\")\n",
    "\n",
    "    return {\n",
    "        \"csv\": out_csv,\n",
    "        \"video\": video_path,\n",
    "        \"timeline\": timeline,\n",
    "        \"processed_keypoints\": Kc,\n",
    "        \"suggestions\": list(set(suggestions_list))\n",
    "    }\n",
    "\n",
    "# --- Modelo avanzado (estructura LSTM Bi) para carga de pesos ---\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "class CoreographyLSTM:\n",
    "    def __init__(self, input_shape=(100,51), num_labels=8):\n",
    "        inp = layers.Input(shape=input_shape)\n",
    "        x = layers.Masking(mask_value=0.0)(inp)\n",
    "        x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
    "        x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "        x = layers.Dense(128, activation=\"relu\")(x)\n",
    "        out = layers.Dense(num_labels, activation=\"sigmoid\")(x)\n",
    "        self.model = models.Model(inp, out)\n",
    "        self.model.compile(optimizer=optimizers.Adam(1e-3),\n",
    "                           loss=\"binary_crossentropy\",\n",
    "                           metrics=[tf.keras.metrics.AUC(name=\"auc\"),\n",
    "                                    tf.keras.metrics.Precision(name=\"precision\"),\n",
    "                                    tf.keras.metrics.Recall(name=\"recall\")])\n",
    "    def predict_sequence(self, seq_2d):\n",
    "        # seq_2d: (T,F) -> ventanas (Nw, win, F), promedio de scores\n",
    "        Xw, idx = sliding_windows(seq_2d, win_len=self.model.input_shape[1], hop=20)\n",
    "        if len(Xw)==0: return np.zeros((self.model.output_shape[-1],), dtype=float)\n",
    "        probs = self.model.predict(Xw, verbose=0)  # (Nw, C)\n",
    "        return probs.mean(axis=0), probs, idx\n",
    "\n",
    "# --- Pipeline Integrado ---\n",
    "def full_analysis_pipeline(video_path, win_sec=5.0, hop_sec=2.5, conf_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Ejecuta el pipeline completo para un v√≠deo custom.\n",
    "    \"\"\"\n",
    "    print(f\"Iniciando pipeline completo para: {video_path}\")\n",
    "    output_dir_process = os.path.join(BASE, \"data/processed/custom_videos\")\n",
    "    ensure_dir(output_dir_process)\n",
    "\n",
    "    # Keypoints con MediaPipe\n",
    "    print(\"1. Extrayendo keypoints con MediaPipe...\")\n",
    "    keypoints_array, keypoints_path = process_video_with_mediapipe(video_path, output_dir_process)\n",
    "    if keypoints_array is None:\n",
    "        print(\"Fallo al extraer keypoints. Abortando pipeline.\")\n",
    "        return None\n",
    "\n",
    "    # An√°lisis b√°sico\n",
    "    print(\"\\n2. Ejecutando an√°lisis b√°sico...\")\n",
    "    basic_results = run_basic_analysis(video_path, keypoints_array, output_dir_process, win_sec=win_sec, hop_sec=hop_sec)\n",
    "    if basic_results.get(\"processed_keypoints\") is None:\n",
    "        print(\"An√°lisis b√°sico no produjo keypoints procesados. Abortando pipeline.\")\n",
    "        return basic_results\n",
    "\n",
    "    #  Cargar modelo\n",
    "    print(\"\\n3. Cargando modelo ...\")\n",
    "    # Prioridad: best_advanced_model.h5 ‚Üí fallback best_{MODEL_TYPE}_model.h5\n",
    "    advanced_model_paths = [\n",
    "        os.path.join(MODELS_DIR, \"best_advanced_model.h5\"),\n",
    "        os.path.join(MODELS_DIR, f\"best_{MODEL_TYPE}_model.h5\")\n",
    "    ]\n",
    "    advanced_model_path = next((p for p in advanced_model_paths if os.path.exists(p)), None)\n",
    "    advanced_model = None\n",
    "\n",
    "    T_processed, J_processed, D_processed = basic_results[\"processed_keypoints\"].shape\n",
    "\n",
    "    # Obtener FPS para fijar tama√±o de ventana temporal\n",
    "    cap_tmp = cv2.VideoCapture(video_path)\n",
    "    fps_tmp = cap_tmp.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    cap_tmp.release()\n",
    "    assumed_input_shape = (int(win_sec * fps_tmp), J_processed * D_processed)\n",
    "    assumed_num_labels = len(label_names)\n",
    "\n",
    "    try:\n",
    "        if advanced_model_path is not None:\n",
    "            print(f\"Using CoreographyLSTM structure for weights: {os.path.basename(advanced_model_path)}\")\n",
    "            advanced_model_keras = CoreographyLSTM(input_shape=assumed_input_shape, num_labels=assumed_num_labels).model\n",
    "            advanced_model_keras.load_weights(advanced_model_path)\n",
    "            advanced_model = advanced_model_keras\n",
    "            print(\"Advanced model loaded.\")\n",
    "        else:\n",
    "            print(\"No advanced model weights found. Skipping advanced analysis.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load advanced model: {e}\")\n",
    "        print(\"Skipping advanced analysis.\")\n",
    "        advanced_model = None\n",
    "\n",
    "    #  Preparar estructura de resultados combinados\n",
    "    combined_results = {\n",
    "        \"basic_analysis\": basic_results,\n",
    "        \"advanced_prediction_mean\": None,\n",
    "        \"window_scores\": None,\n",
    "        \"window_index\": None,\n",
    "        \"combined_suggestions\": basic_results.get(\"suggestions\", []),  # strings al principio\n",
    "        \"trained_now\": False\n",
    "    }\n",
    "    combined_results[\"combined_suggestions\"] = _normalize_combined_suggestions(\n",
    "        combined_results.get(\"combined_suggestions\", [])\n",
    "    )\n",
    "\n",
    "    # Inferencia sobre el  modelo\n",
    "    if advanced_model:\n",
    "        print(\"\\n4. Ejecutando inferencia avanzada...\")\n",
    "        Kc = basic_results[\"processed_keypoints\"]\n",
    "        if Kc.ndim == 3:\n",
    "            T_kc, J_kc, D_kc = Kc.shape\n",
    "            X_fit_advanced = Kc.reshape(T_kc, J_kc * D_kc)\n",
    "        else:\n",
    "            X_fit_advanced = Kc\n",
    "\n",
    "        # Alinear dimensi√≥n de features\n",
    "        model_input_features = advanced_model.input_shape[-1]\n",
    "        if X_fit_advanced.shape[1] < model_input_features:\n",
    "            pad = np.zeros((X_fit_advanced.shape[0], model_input_features - X_fit_advanced.shape[1]), dtype=np.float32)\n",
    "            X_fit_aligned = np.hstack([X_fit_advanced, pad])\n",
    "        elif X_fit_advanced.shape[1] > model_input_features:\n",
    "            X_fit_aligned = X_fit_advanced[:, :model_input_features]\n",
    "        else:\n",
    "            X_fit_aligned = X_fit_advanced\n",
    "\n",
    "        # Ventanas deslizantes\n",
    "        win_len_model = advanced_model.input_shape[1]\n",
    "        Xw, idx = sliding_windows(X_fit_aligned, win_len=win_len_model, hop=max(5, win_len_model//5))\n",
    "\n",
    "        if len(Xw) > 0:\n",
    "            yw = advanced_model.predict(Xw, verbose=0)  # (Nseq, C)\n",
    "            y_vec = yw.mean(axis=0)                     # (C,)\n",
    "            combined_results[\"advanced_prediction_mean\"] = y_vec.tolist()\n",
    "            combined_results[\"window_scores\"] = yw.tolist()\n",
    "            combined_results[\"window_index\"] = idx\n",
    "\n",
    "            # Fusionar sugerencias\n",
    "            print(\"\\n5. Combinando sugerencias...\")\n",
    "            # Arrancamos con las ya normalizadas (b√°sicas)\n",
    "            sug = list(combined_results[\"combined_suggestions\"])\n",
    "            # A√±adir avanzadas por umbral global\n",
    "            for lbl_idx, s in enumerate(y_vec):\n",
    "                if s >= conf_threshold and lbl_idx < len(label_names):\n",
    "                    sug_text = label_to_text.get(label_names[lbl_idx], label_names[lbl_idx])\n",
    "                    if not any(d.get(\"suggestion\") == sug_text for d in sug):\n",
    "                        sug.append({\"suggestion\": sug_text, \"confidence\": float(s), \"source\": \"advanced_model\"})\n",
    "            # Orden final\n",
    "            combined_results[\"combined_suggestions\"] = sorted(sug, key=lambda x: x.get(\"confidence\", 0.0), reverse=True)\n",
    "\n",
    "            # Visualizaciones (Top etiquetas + Heatmap)\n",
    "            print(\"\\n6. Visualizaciones...\")\n",
    "            plot_topk_bars(y_vec, label_names, k=min(12, len(label_names)), title=\"Top etiquetas (modelo avanzado)\")\n",
    "            plot_window_heatmap(yw, label_names, idx, title=\"Heatmap temporal (modelo avanzado)\")\n",
    "        else:\n",
    "            print(\"No se pudieron construir ventanas para el modelo avanzado. Saltando inferencia avanzada.\")\n",
    "\n",
    "    #  Generar v√≠deo anotado\n",
    "    print(\"\\n7. Generando v√≠deo anotado...\")\n",
    "    timeline_combined = []\n",
    "    basic_timeline = basic_results.get(\"timeline\", [])\n",
    "    if basic_timeline:\n",
    "        # Usa top-K globales por ventana (simple)\n",
    "        top_k_texts = [d[\"suggestion\"] for d in combined_results[\"combined_suggestions\"][:4]]\n",
    "        for basic_win in basic_timeline:\n",
    "            start_f = int(basic_win[\"start_f\"]); end_f = int(basic_win[\"end_f\"])\n",
    "            timeline_combined.append({\"start_f\": start_f, \"end_f\": end_f, \"sugerencias\": list(top_k_texts)})\n",
    "    elif combined_results.get(\"window_index\"):\n",
    "        # Si no hay l√≠nea base, usa los √≠ndices del modelo avanzado\n",
    "        idx = combined_results[\"window_index\"]\n",
    "        win_scores = combined_results.get(\"window_scores\")\n",
    "        for k, (s, e) in enumerate(idx):\n",
    "            s = int(s); e = int(e)\n",
    "            active_suggs_text = []\n",
    "            if win_scores and len(win_scores) > k:\n",
    "                # Umbral por ventana (simple)\n",
    "                arr = np.array(win_scores[k], dtype=np.float32)  # (C,)\n",
    "                j_idx = np.where(arr >= conf_threshold)[0]\n",
    "                active_suggs_text = [label_to_text.get(label_names[j], label_names[j]) for j in j_idx if j < len(label_names)]\n",
    "            if not active_suggs_text:\n",
    "                active_suggs_text = [d[\"suggestion\"] for d in combined_results[\"combined_suggestions\"][:4]]\n",
    "            timeline_combined.append({\"start_f\": s, \"end_f\": e, \"sugerencias\": active_suggs_text[:4]})\n",
    "    else:\n",
    "        print(\"No hay timeline de b√°sico ni avanzado. Saltando anotaci√≥n de v√≠deo.\")\n",
    "        combined_results[\"annotated_video\"] = None\n",
    "        print(\"\\nPipeline completo finalizado (sin v√≠deo anotado).\")\n",
    "        return combined_results\n",
    "\n",
    "    out_mp4 = os.path.join(REPORTS_DIR, f\"custom_video_full_analysis_annotated.mp4\")\n",
    "    annotated_video_path = overlay_text_on_video(video_path, timeline_combined, out_mp4)\n",
    "    combined_results[\"annotated_video\"] = annotated_video_path\n",
    "    print(f\"V√≠deo anotado generado en: {annotated_video_path}\")\n",
    "\n",
    "    #  Guardar resumen\n",
    "    print(\"\\n8. Guardando resultados combinados...\")\n",
    "    summary_path = os.path.join(REPORTS_DIR, \"full_analysis_summary.json\")\n",
    "    summary_data = {\n",
    "        \"video_path\": video_path,\n",
    "        \"basic_analysis_csv\": basic_results.get(\"csv\"),\n",
    "        \"annotated_video\": combined_results.get(\"annotated_video\"),\n",
    "        \"combined_suggestions\": combined_results.get(\"combined_suggestions\"),\n",
    "        \"advanced_prediction_mean\": combined_results.get(\"advanced_prediction_mean\"),\n",
    "        \"trained_now\": combined_results.get(\"trained_now\", False)\n",
    "    }\n",
    "    with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary_data, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"Resumen del an√°lisis guardado en: {summary_path}\")\n",
    "\n",
    "    print(\"\\nPipeline completo finalizado.\")\n",
    "    return combined_results\n",
    "\n",
    "# --- Ejecutar el pipeline completo ---\n",
    "print(\"Por favor, sube un v√≠deo custom para iniciar el pipeline.\")\n",
    "try:\n",
    "    custom_video_path = upload_video()\n",
    "    if custom_video_path and os.path.exists(custom_video_path):\n",
    "        print(f\"\\nEjecutando pipeline completo para: {custom_video_path}\")\n",
    "        final_results = full_analysis_pipeline(custom_video_path)\n",
    "\n",
    "        print(\"\\n=== Resultados Finales ===\")\n",
    "        if final_results:\n",
    "            print(\"Sugerencias Combinadas:\")\n",
    "            if final_results.get(\"combined_suggestions\"):\n",
    "                for i, sug in enumerate(final_results[\"combined_suggestions\"], 1):\n",
    "                    print(f\"{i}. {sug.get('suggestion', 'N/A')} (Confianza: {sug.get('confidence', np.nan):.2f}) [Fuente: {sug.get('source', 'N/A')}]\")\n",
    "            else:\n",
    "                print(\"No combined suggestions generated.\")\n",
    "\n",
    "            if final_results.get(\"annotated_video\"):\n",
    "                print(\"\\nV√≠deo anotado disponible en:\", final_results[\"annotated_video\"])\n",
    "            else:\n",
    "                print(\"\\nV√≠deo anotado no generado.\")\n",
    "\n",
    "            # Limpiar el archivo de v√≠deo temporal\n",
    "            if custom_video_path.startswith(tempfile.gettempdir()):\n",
    "                os.remove(custom_video_path)\n",
    "                print(f\"Archivo temporal de v√≠deo eliminado: {custom_video_path}\")\n",
    "        else:\n",
    "            print(\"El pipeline completo no se ejecut√≥ correctamente.\")\n",
    "    else:\n",
    "        print(\"No se subi√≥ ning√∫n v√≠deo o el archivo no se encontr√≥.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurri√≥ un error durante la ejecuci√≥n del pipeline completo: {e}\")\n",
    "    if 'custom_video_path' in locals() and custom_video_path and os.path.exists(custom_video_path) and custom_video_path.startswith(tempfile.gettempdir()):\n",
    "        os.remove(custom_video_path)\n",
    "        print(f\"Archivo temporal de v√≠deo eliminado por error: {custom_video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706950b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GUARDAR MODELO EN /models ===\n",
    "\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline as SkPipeline\n",
    "\n",
    "# Rutas base\n",
    "BASE        = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "ART         = f\"{BASE}/artifacts\"\n",
    "MODELS_DIR  = f\"{BASE}/models\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# Cargar objetos desde memoria o desde /artifacts\n",
    "\n",
    "try:\n",
    "    imp      # SimpleImputer ya en memoria\n",
    "    scaler   # RobustScaler ya en memoria\n",
    "    clf      # OneVsRest(LogReg) ya en memoria\n",
    "except NameError:\n",
    "    # Si no est√°n en el workspace actual, cargamos desde disco\n",
    "    imp_path    = f\"{ART}/imputer.joblib\"\n",
    "    scaler_path = f\"{ART}/scaler.joblib\"\n",
    "    clf_path    = f\"{ART}/model_ovr_logreg.joblib\"\n",
    "\n",
    "    assert os.path.exists(imp_path),    f\"Falta: {imp_path}\"\n",
    "    assert os.path.exists(scaler_path), f\"Falta: {scaler_path}\"\n",
    "    assert os.path.exists(clf_path),    f\"Falta: {clf_path}\"\n",
    "\n",
    "    imp    = joblib.load(imp_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    clf    = joblib.load(clf_path)\n",
    "\n",
    "\n",
    "# Cargar columnas de features y nombres de etiquetas\n",
    "\n",
    "try:\n",
    "    feature_cols\n",
    "except NameError:\n",
    "    feat_path = f\"{ART}/feature_cols.csv\"\n",
    "    assert os.path.exists(feat_path), f\"Falta: {feat_path}\"\n",
    "    feature_cols = pd.read_csv(feat_path, header=None)[0].tolist()\n",
    "\n",
    "try:\n",
    "    label_names\n",
    "except NameError:\n",
    "    labels_path = f\"{ART}/label_names.csv\"\n",
    "    assert os.path.exists(labels_path), f\"Falta: {labels_path}\"\n",
    "    label_names = pd.read_csv(labels_path, header=None)[0].tolist()\n",
    "\n",
    "\n",
    "# Construir Pipeline y guardar\n",
    "\n",
    "pipe = SkPipeline([\n",
    "    (\"imputer\", imp),     # SimpleImputer ya ajustado\n",
    "    (\"scaler\",  scaler),  # RobustScaler ya ajustado\n",
    "    (\"clf\",     clf)      # OneVsRest(LogisticRegression) ya ajustado\n",
    "])\n",
    "\n",
    "pipe_path = f\"{MODELS_DIR}/pipeline_ovr_logreg.joblib\"\n",
    "joblib.dump(pipe, pipe_path)\n",
    "print(f\" Pipeline guardado en: {pipe_path}\")\n",
    "\n",
    "# Metadatos del pipeline\n",
    "meta = {\n",
    "    \"sklearn_version\": sklearn.__version__,\n",
    "    \"model_path\": pipe_path,\n",
    "    \"onnx_path\": None,  # Export no realizado en esta celda\n",
    "    \"feature_cols\": list(feature_cols),\n",
    "    \"label_names\": list(label_names),\n",
    "    \"notes\": \"Pipeline con SimpleImputer + RobustScaler + OneVsRest(LogReg) entrenado.\"\n",
    "}\n",
    "meta_path = f\"{MODELS_DIR}/pipeline_metadata.json\"\n",
    "with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2, ensure_ascii=False)\n",
    "print(f\" Metadatos guardados en: {meta_path}\")\n",
    "\n",
    "\n",
    "#  Ejemplo de carga r√°pida y prueba de inferencia (opcional)\n",
    "\n",
    "# Si X_raw no existe en el workspace, intenta cargar el CSV de features;\n",
    "# si no existe o falta alguna columna, no ejecuta la demo.\n",
    "try:\n",
    "    X_raw\n",
    "except NameError:\n",
    "    X_raw = None\n",
    "\n",
    "CSV = f\"{BASE}/data/processed/aistpp/features_coreograficos.csv\"\n",
    "if X_raw is None and os.path.exists(CSV):\n",
    "    try:\n",
    "        df = pd.read_csv(CSV)\n",
    "        missing = [c for c in feature_cols if c not in df.columns]\n",
    "        if missing:\n",
    "            print(f\"No se puede crear X_raw: faltan {len(missing)} columnas en el CSV (ej: {missing[:5]})\")\n",
    "        else:\n",
    "            X_raw = df[feature_cols].copy()\n",
    "    except Exception as e:\n",
    "        print(f\" No se pudo cargar {CSV}: {e}\")\n",
    "\n",
    "# Carga el pipeline y, si hay X_raw, prueba la inferencia\n",
    "pipe = joblib.load(pipe_path)\n",
    "\n",
    "if X_raw is not None:\n",
    "    try:\n",
    "        y_pred  = pipe.predict(X_raw)        # 0/1 por etiqueta\n",
    "        y_proba = pipe.predict_proba(X_raw)  # (n_samples, n_classes)\n",
    "        print(\"Pred shape:\", y_pred.shape, \"| Proba shape:\", y_proba.shape)\n",
    "    except Exception as e:\n",
    "        print(f\" Error en inferencia de ejemplo: {e}\")\n",
    "else:\n",
    "    print(\" Ejemplo de inferencia omitido (no hay X_raw). \"\n",
    "          \"Carga un DataFrame y selecciona feature_cols para probar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bdef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Construir ART/kp_windows.npz desde AIST++\n",
    "# Usa tus funciones: load_aist_data() y prepare_sequences()\n",
    "# Salida: artifacts/kp_windows.npz con:\n",
    "#   - 'kp'      -> [N, T, K, D]  (D=2 √≥ 3, seg√∫n dataset)\n",
    "#   - 'y'       -> [N] enteros (clase por ventana)\n",
    "#   - 'classes' -> lista de nombres de clase\n",
    "#   - 'mask'    -> [N, T, K] (opcional, 1 si KP finito en todos los dims)\n",
    "\n",
    "import os, json, numpy as np\n",
    "\n",
    "# --- Rutas ---\n",
    "BASE = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "ART  = f\"{BASE}/artifacts\"\n",
    "os.makedirs(ART, exist_ok=True)\n",
    "\n",
    "# --- Chequeo de dependencias (deben existir en celdas previas) ---\n",
    "for fn in (\"load_aist_data\", \"prepare_sequences\"):\n",
    "    assert fn in globals(), f\"‚ùå Falta la funci√≥n '{fn}'. Ejecuta las celdas donde se defini√≥.\"\n",
    "\n",
    "# --- Par√°metros (usa los mismos entrenados) ---\n",
    "SEQ_LEN = globals().get(\"SEQ_LEN\", 30)\n",
    "HOP     = globals().get(\"HOP\", 15)\n",
    "\n",
    "print(f\"[INFO] Usando SEQ_LEN={SEQ_LEN}, HOP={HOP}\")\n",
    "\n",
    "# Cargar clips crudos (lista de arrays (T,J,D)) + etiquetas y nombres\n",
    "kp_list, y_list, label_names = load_aist_data()\n",
    "assert len(kp_list) > 0, \"‚ùå No hay clips en AIST++.\"\n",
    "J, D = kp_list[0].shape[1], kp_list[0].shape[2]\n",
    "print(f\"[DATA] Clips: {len(kp_list)} | J={J} | D={D}\")\n",
    "\n",
    "# Crear ventanas (devuelve X:[N,T,J*D] aplanado y y:[N,C])\n",
    "X_flat, y_oh = prepare_sequences(kp_list, y_list, seq_len=SEQ_LEN, hop=HOP)\n",
    "N, T = X_flat.shape[0], X_flat.shape[1]\n",
    "print(f\"[SEQ] Ventanas: N={N}, T={T}, feat={X_flat.shape[2]}  (esperado J*D={J*D})\")\n",
    "assert X_flat.shape[2] == J * D, \"‚ùå El n√∫mero de features no coincide con J*D. Revisa SEQ_LEN/HOP o los datos.\"\n",
    "\n",
    "# Re-dar forma: [N, T, J*D] -> [N, T, J, D]\n",
    "kp_windows = X_flat.reshape(N, T, J, D).astype(np.float32)\n",
    "\n",
    "# Etiquetas enteras por ventana y m√°scara opcional\n",
    "y_int = np.argmax(y_oh, axis=1).astype(np.int64)  # [N]\n",
    "mask  = np.isfinite(kp_windows).all(axis=-1).astype(np.uint8)  # [N,T,K]\n",
    "\n",
    "# Guardar .npz con el formato esperado por tu loader\n",
    "out_npz = f\"{ART}/kp_windows.npz\"\n",
    "np.savez_compressed(\n",
    "    out_npz,\n",
    "    kp=kp_windows,                  # [N,T,K,D]\n",
    "    y=y_int,                        # [N]\n",
    "    classes=np.array(label_names, dtype=object),\n",
    "    mask=mask                       # [N,T,K] (opcional)\n",
    ")\n",
    "print(f\"[OK] Guardado: {out_npz}\")\n",
    "print(f\"     kp: {kp_windows.shape} | y: {y_int.shape} | classes: {len(label_names)} | mask: {mask.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dea8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalizaci√≥n de keypoints por ventana\n",
    "#  - Carga kp si no existe en memoria\n",
    "#  - Devuelve kp_norm [N,T,K,2] y mask_kp [N,T,K]\n",
    "#  - Guarda  ART/kp_windows_norm.npz\n",
    "\n",
    "import os, json\n",
    "import numpy as np\n",
    "\n",
    "# --- Rutas por defecto si no existen en el entorno ---\n",
    "try:\n",
    "    ART\n",
    "except NameError:\n",
    "    BASE = \"/content/drive/MyDrive/asistente_coreografico\"\n",
    "    ART  = f\"{BASE}/artifacts\"\n",
    "os.makedirs(ART, exist_ok=True)\n",
    "\n",
    "# --- Loader m√≠nimo, compatible con tus formatos previos ---\n",
    "def _try_load_keypoints(art_dir):\n",
    "    npz_path = f\"{art_dir}/kp_windows.npz\"\n",
    "    if os.path.exists(npz_path):\n",
    "        data = np.load(npz_path, allow_pickle=True)\n",
    "        kp = data[\"kp\"]                         # [N,T,K,2/3]\n",
    "        y  = data[\"y\"] if \"y\" in data else None\n",
    "        mask = data[\"mask\"] if \"mask\" in data else None\n",
    "        classes = data[\"classes\"].tolist() if \"classes\" in data else None\n",
    "        return kp, y, mask, classes\n",
    "    npy_path = f\"{art_dir}/kp_windows.npy\"\n",
    "    if os.path.exists(npy_path):\n",
    "        kp = np.load(npy_path, allow_pickle=True)\n",
    "        y_path = f\"{art_dir}/y_labels.npy\"\n",
    "        y = np.load(y_path) if os.path.exists(y_path) else None\n",
    "        classes_path = f\"{art_dir}/classes.json\"\n",
    "        classes = json.load(open(classes_path)) if os.path.exists(classes_path) else None\n",
    "        return kp, y, None, classes\n",
    "    raise FileNotFoundError(\"No encuentro ART/kp_windows.(npz|npy). Genera primero las ventanas.\")\n",
    "\n",
    "# --- Si kp no est√° en memoria, lo cargamos ---\n",
    "try:\n",
    "    kp  # variable ya existente\n",
    "except NameError:\n",
    "    kp, y, mask_file, classes = _try_load_keypoints(ART)\n",
    "else:\n",
    "    # si ya exist√≠a, ponemos None para no reusar m√°scara externa accidentalmente\n",
    "    mask_file = None\n",
    "    classes = None\n",
    "    y = None\n",
    "\n",
    "# --- Normalizaci√≥n: centra y escala robusto por ventana ---\n",
    "# √çndices opcionales (si los supieras); aqu√≠ usamos centrado/escala robustos\n",
    "IDX_PELVIS = None\n",
    "IDX_L_SHO  = None\n",
    "IDX_L_HIP  = None\n",
    "\n",
    "def compute_mask_and_xy(kp_arr):\n",
    "    # kp_arr: [N,T,K,2] o [N,T,K,3]\n",
    "    if kp_arr.shape[-1] == 3:\n",
    "        xy   = kp_arr[..., :2]\n",
    "        conf = kp_arr[..., 2]\n",
    "        mask = (conf > 0.05).astype(np.float32)\n",
    "    else:\n",
    "        xy   = kp_arr\n",
    "        mask = (~np.isnan(kp_arr[..., 0])).astype(np.float32)\n",
    "    return xy.astype(np.float32), mask\n",
    "\n",
    "def robust_center_scale(xy, mask):\n",
    "    # xy: [N,T,K,2], mask: [N,T,K]\n",
    "    N, T, K, _ = xy.shape\n",
    "    out  = xy.copy()\n",
    "    m_out = mask.copy()\n",
    "    for i in range(N):\n",
    "        for t in range(T):\n",
    "            valid = m_out[i, t] > 0.5\n",
    "            if not np.any(valid):\n",
    "                continue\n",
    "            pts = out[i, t, valid, :]\n",
    "            center = np.median(pts, axis=0, keepdims=True)     # [1,2]\n",
    "            out[i, t, :, :] -= center\n",
    "            d = np.linalg.norm(pts - center, axis=1)\n",
    "            scale = np.percentile(d, 90) if d.size > 0 else 1.0\n",
    "            if scale < 1e-3:\n",
    "                scale = 1.0\n",
    "            out[i, t, :, :] /= scale\n",
    "    return out, m_out\n",
    "\n",
    "#  Extrae xy y m√°scara inferida\n",
    "xy, mask_kp = compute_mask_and_xy(kp)\n",
    "\n",
    "#  Si el archivo tra√≠a 'mask', se fuciona (AND l√≥gico)\n",
    "if 'mask_file' in locals() and mask_file is not None:\n",
    "    mask_kp = (mask_kp * (mask_file > 0.5).astype(np.float32))\n",
    "\n",
    "# Normaliza\n",
    "kp_norm, mask_kp = robust_center_scale(xy, mask_kp)\n",
    "\n",
    "print(\"[OK] Normalizaci√≥n completada\")\n",
    "print(\"kp_norm:\", kp_norm.shape, \"| mask_kp:\", mask_kp.shape, \"| D(norm)=\", kp_norm.shape[-1])\n",
    "\n",
    "# Guardar normalizados para etapas siguientes ---\n",
    "save_norm = True\n",
    "if save_norm:\n",
    "    out = {\"kp\": kp_norm, \"mask\": mask_kp}\n",
    "    if y is not None:\n",
    "        out[\"y\"] = y\n",
    "    if classes is not None:\n",
    "        out[\"classes\"] = np.array(classes, dtype=object)\n",
    "    out_path = f\"{ART}/kp_windows_norm.npz\"\n",
    "    np.savez_compressed(out_path, **out)\n",
    "    print(f\"[OK] Guardado: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292989fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _align_features_df_any(df_like, cols):\n",
    "    \"\"\"DataFrame con columnas EXACTAS en 'cols' (orden), faltantes -> NaN.\"\"\"\n",
    "    if isinstance(df_like, pd.DataFrame):\n",
    "        for c in cols:\n",
    "            if c not in df_like.columns:\n",
    "                df_like[c] = np.nan\n",
    "        return df_like[cols]\n",
    "    elif isinstance(df_like, (dict, pd.Series)):\n",
    "        return pd.DataFrame([{c: df_like.get(c, np.nan) for c in cols}])[cols]\n",
    "    elif isinstance(df_like, np.ndarray):\n",
    "        # si viene ndarray con el n¬∫ correcto de columnas, lo envolvemos\n",
    "        if df_like.ndim != 2:\n",
    "            raise ValueError(f\"Esperaba 2D array, got shape {df_like.shape}\")\n",
    "        if len(cols) != df_like.shape[1]:\n",
    "            raise ValueError(f\"Las dimensiones no coinciden: X.shape[1]={df_like.shape[1]} vs len(feature_cols)={len(cols)}\")\n",
    "        return pd.DataFrame(df_like, columns=cols)\n",
    "    else:\n",
    "        raise ValueError(\"Formato no soportado para df_like\")\n",
    "\n",
    "def try_load_teacher(ART, y, C, kp_norm=None, feature_cols=None):\n",
    "    \"\"\"\n",
    "    Prioridad:\n",
    "      1) ART/teacher_probas.npy\n",
    "      2) Si hay imp+scaler+clf y features X_*.npy -> predict_proba\n",
    "      3) Si NO hay X_*.npy: construir un DF con columnas=feature_cols y NaN (imputer rellena);\n",
    "         opcionalmente a√±adir stats simples desde kp_norm si existe.\n",
    "      4) Fallback final: label smoothing desde y (single-label o multi-label).\n",
    "    \"\"\"\n",
    "    if feature_cols is None or len(feature_cols) == 0:\n",
    "        raise RuntimeError(\"feature_cols no est√° disponible; carga ART/feature_cols.csv antes.\")\n",
    "\n",
    "    p_teacher_path = f\"{ART}/teacher_probas.npy\"\n",
    "    if os.path.exists(p_teacher_path):\n",
    "        P = np.load(p_teacher_path)\n",
    "        print(\"[OK] Cargadas teacher_probas.npy:\", P.shape)\n",
    "        return P\n",
    "\n",
    "    imp_path, scaler_path, clf_path = f\"{ART}/imputer.joblib\", f\"{ART}/scaler.joblib\", f\"{ART}/model_ovr_logreg.joblib\"\n",
    "    has_pipeline = all(os.path.exists(p) for p in [imp_path, scaler_path, clf_path])\n",
    "\n",
    "    if has_pipeline:\n",
    "        imp    = joblib.load(imp_path)\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        clf    = joblib.load(clf_path)\n",
    "\n",
    "        # 2a) ¬øExisten features precomputadas del profesor?\n",
    "        for c in (f\"{ART}/X_fusion.npy\", f\"{ART}/X_feats.npy\", f\"{ART}/features.npy\"):\n",
    "            if os.path.exists(c):\n",
    "                X_raw = np.load(c)\n",
    "                if X_raw.shape[1] != len(feature_cols):\n",
    "                    print(f\"[WARN] {os.path.basename(c)} tiene {X_raw.shape[1]} cols y el pipeline espera {len(feature_cols)}. Ignoro y genero alineado.\")\n",
    "                    break\n",
    "                X_df = _align_features_df_any(X_raw, feature_cols)\n",
    "                Ximp = imp.transform(X_df); Xs = scaler.transform(Ximp)\n",
    "                P = clf.predict_proba(Xs).astype(np.float32)\n",
    "                np.save(p_teacher_path, P)\n",
    "                print(\"[OK] Teacher probas generadas desde features guardadas:\", P.shape)\n",
    "                return P\n",
    "        # 2b) No hay X_*.npy v√°lidas: construir DF vac√≠o alineado y (opcional) inyectar stats simples\n",
    "        N_guess = None\n",
    "        feats_dict = {col: np.nan for col in feature_cols}  # plantilla por fila\n",
    "        rows = []\n",
    "\n",
    "        if kp_norm is not None:\n",
    "            # kp_norm: [N,T,K,2] -> N filas\n",
    "            N_guess = kp_norm.shape[0]\n",
    "            # estad√≠sticas simples opcionales (si te suenan nombres en feature_cols, a√±ade aqu√≠ los c√°lculos)\n",
    "            # p.ej., si existe una columna llamada \"mean_x\", \"mean_y\", etc., podr√≠as mapear algo:\n",
    "            # (dejamos NaN por defecto para que el imputer rellene)\n",
    "            for i in range(N_guess):\n",
    "                rows.append(feats_dict.copy())\n",
    "        else:\n",
    "            # si no tenemos kp_norm, al menos intenta deducir N de y\n",
    "            if y is not None:\n",
    "                N_guess = len(y)\n",
    "                rows = [feats_dict.copy() for _ in range(N_guess)]\n",
    "            else:\n",
    "                raise RuntimeError(\"No hay features del profesor ni kp_norm ni y para construir P_teacher.\")\n",
    "\n",
    "        X_df = pd.DataFrame(rows, columns=feature_cols)\n",
    "        Ximp = imp.transform(X_df); Xs = scaler.transform(Ximp)\n",
    "        P = clf.predict_proba(Xs).astype(np.float32)\n",
    "        np.save(p_teacher_path, P)\n",
    "        print(\"[OK] Teacher probas generadas desde DF alineado con imputer:\", P.shape)\n",
    "        return P\n",
    "\n",
    "    # 3) Fallback final: label smoothing a partir de y\n",
    "    if y is None:\n",
    "        raise RuntimeError(\"No hay teacher_probas, ni pipeline cl√°sico, ni y para fallback.\")\n",
    "    y_arr = np.asarray(y)\n",
    "    if y_arr.ndim == 1:  # single-label (clase entera por muestra)\n",
    "        C_fbk = int(C) if C is not None else int(np.max(y_arr) + 1)\n",
    "        eps = 0.1\n",
    "        P = np.full((len(y_arr), C_fbk), eps/(C_fbk-1), dtype=np.float32)\n",
    "        P[np.arange(len(y_arr)), y_arr.astype(int)] = 1.0 - eps\n",
    "    else:  # multilabel (N,C)\n",
    "        eps = 0.1\n",
    "        P = (1.0 - eps) * y_arr.astype(np.float32) + eps * (1.0 - y_arr.astype(np.float32)) / max(1, y_arr.shape[1]-1)\n",
    "    print(\"[OK] Teacher probas fallback (label smoothing):\", P.shape)\n",
    "    return P\n",
    "\n",
    "# ==== USO ====\n",
    "# Requiere: ART, feature_cols, y (opcional), C (opcional), kp_norm (opcional)\n",
    "P_teacher = try_load_teacher(ART, y, C, kp_norm=kp_norm, feature_cols=feature_cols)\n",
    "\n",
    "# Alinear N con kp_norm si difiere\n",
    "N_pt, N_kp = P_teacher.shape[0], kp_norm.shape[0]\n",
    "if N_pt != N_kp:\n",
    "    N_min = min(N_pt, N_kp)\n",
    "    print(f\"[WARN] N mismatch entre teacher ({N_pt}) y kp_norm ({N_kp}); recorto a {N_min}.\")\n",
    "    P_teacher = P_teacher[:N_min]\n",
    "    kp_norm   = kp_norm[:N_min]\n",
    "    if isinstance(y, np.ndarray):\n",
    "        y = y[:N_min]\n",
    "\n",
    "C = P_teacher.shape[1]\n",
    "print(\"Clases (C):\", C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed629478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset y splits\n",
    "# Entrada estudiante: secuencia [T, K*2] (aplanamos K,2)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "#  Inferir N, T, K a partir de kp_norm\n",
    "assert 'kp_norm' in globals(), \"kp_norm no est√° en memoria.\"\n",
    "assert kp_norm.ndim == 4, f\"kp_norm debe ser [N,T,K,D], recibido {kp_norm.shape}\"\n",
    "\n",
    "N, T, K, D = kp_norm.shape\n",
    "if D >= 2:\n",
    "    # nos quedamos con (x,y) si viniera [x,y,(z/conf)]\n",
    "    kp_xy = kp_norm[..., :2]\n",
    "else:\n",
    "    raise ValueError(f\"√öltima dimensi√≥n de kp_norm debe ser ‚â•2 (x,y). Recibido D={D}\")\n",
    "\n",
    "# Construir X_seq = [N, T, K*2]\n",
    "X_seq = kp_xy.reshape(N, T, K * 2).astype(np.float32)\n",
    "\n",
    "# Alinear longitudes con P_teacher si hiciera falta\n",
    "assert 'P_teacher' in globals(), \"P_teacher no est√° en memoria; genera/ carga las probabilidades del profesor.\"\n",
    "if len(P_teacher) != N:\n",
    "    n_min = min(N, len(P_teacher))\n",
    "    print(f\"[WARN] N mismatch (kp_norm={N}, P_teacher={len(P_teacher)}). Recorto a {n_min}.\")\n",
    "    X_seq = X_seq[:n_min]\n",
    "    kp_xy = kp_xy[:n_min]\n",
    "    P_teacher = P_teacher[:n_min]\n",
    "    if 'y' in globals() and y is not None:\n",
    "        y = y[:n_min]\n",
    "    N = n_min  # actualizar\n",
    "\n",
    "# Etiqueta dura para estratificaci√≥n\n",
    "if 'y' in globals() and y is not None:\n",
    "    y_arr = np.asarray(y)\n",
    "    if y_arr.ndim == 2:        # multilabel -> tomamos argmax como proxy\n",
    "        y_hard = np.argmax(y_arr, axis=1).astype(int)\n",
    "    else:                      # single label\n",
    "        y_hard = y_arr.astype(int)\n",
    "else:\n",
    "    y_hard = np.argmax(P_teacher, axis=1).astype(int)\n",
    "\n",
    "# Elegir n_splits seguro (cada clase debe tener ‚â• n_splits muestras)\n",
    "SEED = globals().get('SEED', 42)\n",
    "counts = np.bincount(y_hard)\n",
    "min_per_class = counts[counts > 0].min() if np.any(counts > 0) else 0\n",
    "n_splits = min(5, int(min_per_class)) if min_per_class >= 2 else 2\n",
    "\n",
    "# Si solo hay una clase o no hay suficientes muestras por clase, usar ShuffleSplit estratificado\n",
    "if len(np.unique(y_hard)) < 2 or min_per_class < 2:\n",
    "    print(\"[INFO] Estratificaci√≥n no viable (clases insuficientes). Uso StratifiedShuffleSplit con test_size=0.2.\")\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "    tr_idx, va_idx = next(sss.split(X_seq, y_hard))\n",
    "else:\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    tr_idx, va_idx = next(skf.split(X_seq, y_hard))\n",
    "\n",
    "# Construir splits\n",
    "X_tr, X_va = X_seq[tr_idx], X_seq[va_idx]\n",
    "y_tr, y_va = y_hard[tr_idx], y_hard[va_idx]\n",
    "P_tr, P_va = P_teacher[tr_idx], P_teacher[va_idx]\n",
    "\n",
    "print(\"X_tr:\", X_tr.shape, \"| X_va:\", X_va.shape, \"| P_tr:\", P_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a758ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Modelo estudiante: BiGRU + MLP  (KD = alpha*KL + (1-alpha)*CE)\n",
    "# - Entrada: [B, T, D], D = K*2\n",
    "# - Salida : [B, C]\n",
    "# - Alinea clases: etiquetas y teacher_probs coherentes\n",
    "# =========================================================\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from inspect import signature\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ---------- Comprobaciones previas ----------\n",
    "need = ['X_tr','X_va','y_tr','y_va','P_tr','P_va']\n",
    "missing = [n for n in need if n not in globals()]\n",
    "if missing:\n",
    "    raise NameError(f\"Faltan variables previas {missing}. Ejecuta antes el paso de split/estratificaci√≥n.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ---------- Alineaci√≥n de clases (evita 'Target out of bounds') ----------\n",
    "def normalize_labels(y):\n",
    "    y = np.asarray(y)\n",
    "    if y.ndim != 1:\n",
    "        # si llega one-hot / multilabel, tomar argmax como etiqueta dura\n",
    "        y = np.argmax(y, axis=1)\n",
    "    y = y.astype(np.int64)\n",
    "    uniq = np.unique(y)\n",
    "    # si las clases empiezan en 1 (o >0), desplaza a 0..C-1\n",
    "    if 0 not in uniq:\n",
    "        y = y - uniq.min()\n",
    "    return y\n",
    "\n",
    "def pad_probs(P, C_eff):\n",
    "    P = np.asarray(P, dtype=np.float32)\n",
    "    if P.shape[1] == C_eff:\n",
    "        return P\n",
    "    P_pad = np.zeros((P.shape[0], C_eff), dtype=np.float32)\n",
    "    P_pad[:, :P.shape[1]] = P\n",
    "    return P_pad\n",
    "\n",
    "y_tr = normalize_labels(y_tr)\n",
    "y_va = normalize_labels(y_va)\n",
    "\n",
    "# N√∫mero de clases efectivo: que quepan todas las etiquetas y las columnas de P\n",
    "C_eff = int(max(P_tr.shape[1], P_va.shape[1], y_tr.max()+1, y_va.max()+1))\n",
    "P_tr = pad_probs(P_tr, C_eff)\n",
    "P_va = pad_probs(P_va, C_eff)\n",
    "\n",
    "# D_in y C desde los splits (evita depender de T/K globales)\n",
    "D_in = int(np.prod(X_tr.shape[2:]))  # asume X_tr shape [N, T, D]\n",
    "C    = C_eff\n",
    "\n",
    "# MODELS_DIR por si no existe en el entorno\n",
    "MODELS_DIR = globals().get(\"MODELS_DIR\", \"./models\")\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# ---------- Modelo ----------\n",
    "class StudentBiGRU(nn.Module):\n",
    "    def __init__(self, d_in, hidden=192, layers=1, num_classes=8, dropout=0.15):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=d_in, hidden_size=hidden, num_layers=layers,\n",
    "            batch_first=True, bidirectional=True,\n",
    "            dropout=0.0 if layers == 1 else dropout\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden*2, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, num_classes)\n",
    "        )\n",
    "    def forward(self, x):          # x: [B,T,D]\n",
    "        out, _ = self.gru(x)       # [B,T,2H]\n",
    "        h = out.mean(dim=1)        # average pooling temporal\n",
    "        return self.head(h)        # [B,C]\n",
    "\n",
    "model = StudentBiGRU(d_in=D_in, hidden=192, layers=1, num_classes=C, dropout=0.15).to(device)\n",
    "\n",
    "# ---------- DataLoaders ----------\n",
    "BATCH = 128\n",
    "\n",
    "def make_loader(X, y, P, train=True):\n",
    "    X_t = torch.tensor(X, dtype=torch.float32)\n",
    "    y_t = torch.tensor(y, dtype=torch.long)\n",
    "    P_t = torch.tensor(P, dtype=torch.float32)\n",
    "    ds  = TensorDataset(X_t, y_t, P_t)\n",
    "    return DataLoader(ds, batch_size=BATCH, shuffle=train, drop_last=False)\n",
    "\n",
    "dl_tr = make_loader(X_tr, y_tr, P_tr, train=True)\n",
    "dl_va = make_loader(X_va, y_va, P_va, train=False)\n",
    "\n",
    "# ---------- P√©rdidas y Optimizador ----------\n",
    "ce     = nn.CrossEntropyLoss()\n",
    "kl     = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "T_temp = 2.5\n",
    "alpha  = 0.7\n",
    "\n",
    "opt   = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# Scheduler ReduceLROnPlateau compatible con versiones sin 'verbose'\n",
    "def make_plateau_scheduler(optimizer, mode=\"min\", factor=0.5, patience=3, min_lr=0.0, threshold=1e-4, cooldown=0):\n",
    "    params = signature(optim.lr_scheduler.ReduceLROnPlateau.__init__).parameters\n",
    "    if 'verbose' in params:\n",
    "        return optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=mode, factor=factor, patience=patience,\n",
    "            threshold=threshold, cooldown=cooldown, min_lr=min_lr, verbose=True\n",
    "        )\n",
    "    else:\n",
    "        return optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=mode, factor=factor, patience=patience,\n",
    "            threshold=threshold, cooldown=cooldown, min_lr=min_lr\n",
    "        )\n",
    "\n",
    "sched = make_plateau_scheduler(opt, mode=\"min\", factor=0.5, patience=3)\n",
    "\n",
    "# ---------- Utilidades KD ----------\n",
    "def _row_normalize(p, eps=1e-8):\n",
    "    \"\"\"Normaliza por fila para que la KL tenga un target v√°lido (suma=1).\"\"\"\n",
    "    p = p.clone()\n",
    "    s = p.sum(dim=1, keepdim=True)\n",
    "    p = p / (s + eps)\n",
    "    mask_zero = (s.squeeze(1) < eps)\n",
    "    if mask_zero.any():\n",
    "        p[mask_zero] = 1.0 / p.shape[1]\n",
    "    return p\n",
    "\n",
    "# ---------- Train / Eval ----------\n",
    "def train_one_epoch(model, dl, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = total_ce = total_kd = total_n = 0.0\n",
    "    for Xb, yb, Pb in dl:\n",
    "        Xb, yb, Pb = Xb.to(device), yb.to(device), Pb.to(device)\n",
    "        Pb_soft = _row_normalize(Pb)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(Xb)                              # [B,C]\n",
    "        loss_ce = ce(logits, yb)\n",
    "        log_qT  = F.log_softmax(logits / T_temp, dim=1)\n",
    "        loss_kd = kl(log_qT, Pb_soft) * (T_temp ** 2)\n",
    "\n",
    "        loss = alpha * loss_kd + (1.0 - alpha) * loss_ce\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bsz = Xb.size(0)\n",
    "        total_loss += loss.item()    * bsz\n",
    "        total_ce   += loss_ce.item() * bsz\n",
    "        total_kd   += loss_kd.item() * bsz\n",
    "        total_n    += bsz\n",
    "\n",
    "    return total_loss/max(1,total_n), total_ce/max(1,total_n), total_kd/max(1,total_n)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dl, device):\n",
    "    model.eval()\n",
    "    total_loss = total_ce = total_kd = total_n = 0.0\n",
    "    correct = 0\n",
    "    for Xb, yb, Pb in dl:\n",
    "        Xb, yb, Pb = Xb.to(device), yb.to(device), Pb.to(device)\n",
    "        Pb_soft = _row_normalize(Pb)\n",
    "\n",
    "        logits = model(Xb)\n",
    "        loss_ce = ce(logits, yb)\n",
    "        log_qT  = F.log_softmax(logits / T_temp, dim=1)\n",
    "        loss_kd = kl(log_qT, Pb_soft) * (T_temp ** 2)\n",
    "        loss = alpha * loss_kd + (1.0 - alpha) * loss_ce\n",
    "\n",
    "        bsz = Xb.size(0)\n",
    "        total_loss += loss.item()    * bsz\n",
    "        total_ce   += loss_ce.item() * bsz\n",
    "        total_kd   += loss_kd.item() * bsz\n",
    "        total_n    += bsz\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "\n",
    "    acc = correct / max(1,total_n)\n",
    "    return total_loss/max(1,total_n), total_ce/max(1,total_n), total_kd/max(1,total_n), acc\n",
    "\n",
    "# ---------- Loop principal ----------\n",
    "EPOCHS = 25\n",
    "best_va = float('inf')\n",
    "best_path = os.path.join(MODELS_DIR, \"student_bigru_best.pt\")\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    tr_loss, tr_ce, tr_kd = train_one_epoch(model, dl_tr, opt, device)\n",
    "    va_loss, va_ce, va_kd, va_acc = evaluate(model, dl_va, device)\n",
    "\n",
    "    # Reducir LR seg√∫n validaci√≥n\n",
    "    sched.step(va_loss)\n",
    "    current_lr = opt.param_groups[0]['lr']\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"TR {tr_loss:.4f} (CE {tr_ce:.4f} | KD {tr_kd:.4f}) | \"\n",
    "          f\"VA {va_loss:.4f} (CE {va_ce:.4f} | KD {va_kd:.4f}) | \"\n",
    "          f\"ACC {va_acc:.3f} | LR {current_lr:.2e}\")\n",
    "\n",
    "    # Guardar mejor checkpoint por VA loss\n",
    "    if va_loss < best_va:\n",
    "        best_va = va_loss\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "        print(\"  ‚Ü≥ guardado best checkpoint:\", best_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Inferencia 1 ventana con StudentBiGRU (robusto)\n",
    "# - Autodetecta rutas, clases y dimensiones\n",
    "# - Sin dependencias de ART, C, kp globales\n",
    "# ============================================\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---------- Rutas del proyecto ----------\n",
    "BASE = globals().get(\"BASE\", \"/content/drive/MyDrive/asistente_coreografico\")\n",
    "ART  = globals().get(\"ART\",  f\"{BASE}/artifacts\")\n",
    "MOD  = globals().get(\"MOD\",  f\"{BASE}/models\")\n",
    "os.makedirs(ART, exist_ok=True)\n",
    "os.makedirs(MOD, exist_ok=True)\n",
    "\n",
    "# ---------- Modelo ----------\n",
    "class StudentBiGRU(nn.Module):\n",
    "    def __init__(self, d_in, num_classes, hidden=192, layers=1, dropout=0.15):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=d_in, hidden_size=hidden, num_layers=layers,\n",
    "            batch_first=True, bidirectional=True,\n",
    "            dropout=0.0 if layers == 1 else dropout\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden*2, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, num_classes)\n",
    "        )\n",
    "    def forward(self, x):                 # x: [B,T,D]\n",
    "        y, _ = self.gru(x)                # [B,T,2H]\n",
    "        h = y.mean(dim=1)                 # media temporal\n",
    "        return self.head(h)               # [B,C]\n",
    "\n",
    "# ---------- Normalizaci√≥n de una ventana ----------\n",
    "def normalize_one_window(kp_window: np.ndarray) -> np.ndarray:\n",
    "    xy = kp_window[..., :2].astype(np.float32)\n",
    "    if kp_window.shape[-1] == 3:\n",
    "        conf = kp_window[..., 2]\n",
    "        mask = (conf > 0.05).astype(np.float32)\n",
    "    else:\n",
    "        mask = (~np.isnan(xy[..., 0])).astype(np.float32)\n",
    "    pts = xy[mask > 0.5].reshape(-1, 2)\n",
    "    if len(pts) == 0:\n",
    "        return np.zeros_like(xy, dtype=np.float32)\n",
    "    center = np.median(pts, axis=0, keepdims=True)\n",
    "    d = np.linalg.norm(pts - center, axis=1)\n",
    "    scale = np.percentile(d, 90) if len(d) else 1.0\n",
    "    if scale < 1e-3: scale = 1.0\n",
    "    return (xy - center) / scale\n",
    "\n",
    "# ---------- Localizar checkpoint del estudiante ----------\n",
    "def find_student_checkpoint() -> str:\n",
    "    # 1) variable global\n",
    "    path = globals().get(\"STUDENT_PT\", f\"{MOD}/student_kp.pt\")\n",
    "    if os.path.exists(path):\n",
    "        return path\n",
    "    # 2) fallback t√≠pico\n",
    "    alt = f\"{MOD}/student_bigru_best.pt\"\n",
    "    if os.path.exists(alt):\n",
    "        print(f\"[WARN] No existe {path}. Uso alternativo: {alt}\")\n",
    "        return alt\n",
    "    # 3) el m√°s reciente con patr√≥n razonable\n",
    "    cands = sorted(Path(MOD).glob(\"*.pt\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    for p in cands:\n",
    "        if \"student\" in p.name or \"bigru\" in p.name:\n",
    "            print(f\"[WARN] Uso checkpoint m√°s reciente: {p}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7136bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# - Validaci√≥n + Export\n",
    "# - Alinea versiones sklearn\n",
    "# - Carga dataset/artefactos del proyecto\n",
    "# - Corre inferencia y genera sugerencias\n",
    "# - Reexporta artefactos consistentes para la app (/artifacts)\n",
    "# - Emite timeline.csv y suggestions.csv\n",
    "# ============================================\n",
    "\n",
    "# ---------- 0) Dependencias y versiones ----------\n",
    "import sys, os, json, time, glob, math, warnings, textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "# Fija versiones coherentes con tus artefactos entrenados\n",
    "# (ajusta si fuera necesario en tu entorno de Colab)\n",
    "!pip -q install \"scikit-learn==1.7.1\" \"joblib==1.4.2\" \"numpy==1.26.4\" \"pandas==2.2.2\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline as SkPipeline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------- 1) Rutas del proyecto ----------\n",
    "BASE = \"/content/drive/MyDrive/asistente_coreografico\"  # <- AJUSTA si usas otra carpeta\n",
    "ART  = f\"{BASE}/artifacts\"\n",
    "MOD  = f\"{BASE}/models\"\n",
    "DATA = f\"{BASE}/data\"\n",
    "\n",
    "os.makedirs(ART, exist_ok=True)\n",
    "os.makedirs(MOD, exist_ok=True)\n",
    "os.makedirs(f\"{BASE}/reports\", exist_ok=True)\n",
    "\n",
    "print(f\"[RUTAS]\\nBASE={BASE}\\nART={ART}\\nMOD={MOD}\\nDATA={DATA}\")\n",
    "\n",
    "# ---------- 2) Localizaci√≥n de dataset / features ----------\n",
    "# Intentamos detectar caracter√≠sticas usadas en el entrenamiento anterior.\n",
    "# Soporta m√∫ltiples formatos (npz, parquet, csv) para ser robusto.\n",
    "def find_first(*patterns):\n",
    "    for pat in patterns:\n",
    "        matches = sorted(glob.glob(pat))\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    return None\n",
    "\n",
    "FEATS_NPZ   = find_first(f\"{DATA}/processed/*feats*.npz\", f\"{DATA}/*feats*.npz\")\n",
    "FEATS_NPY   = find_first(f\"{DATA}/processed/*feats*.npy\", f\"{DATA}/*feats*.npy\")\n",
    "FEATS_PARQ  = find_first(f\"{DATA}/processed/*feats*.parquet\")\n",
    "FEATS_CSV   = find_first(f\"{DATA}/processed/*feats*.csv\")\n",
    "WINS_JSON   = find_first(f\"{DATA}/processed/*windows*.json\", f\"{DATA}/*windows*.json\")\n",
    "WINS_CSV    = find_first(f\"{DATA}/processed/*windows*.csv\", f\"{DATA}/*windows*.csv\")\n",
    "\n",
    "print(\"[DATASET DETECTADO]\")\n",
    "print(\"  FEATS_NPZ :\", FEATS_NPZ)\n",
    "print(\"  FEATS_NPY :\", FEATS_NPY)\n",
    "print(\"  FEATS_PARQ:\", FEATS_PARQ)\n",
    "print(\"  FEATS_CSV :\", FEATS_CSV)\n",
    "print(\"  WINS_JSON :\", WINS_JSON)\n",
    "print(\"  WINS_CSV  :\", WINS_CSV)\n",
    "\n",
    "def load_features_and_windows():\n",
    "    # --- Carga features ---\n",
    "    X = None\n",
    "    if FEATS_NPZ:\n",
    "        arr = np.load(FEATS_NPZ, allow_pickle=True)\n",
    "        X = arr[\"X\"] if \"X\" in arr else list(arr.values())[0]\n",
    "    elif FEATS_NPY:\n",
    "        X = np.load(FEATS_NPY, allow_pickle=True)\n",
    "    elif FEATS_PARQ:\n",
    "        df = pd.read_parquet(FEATS_PARQ)\n",
    "        X = df.values\n",
    "    elif FEATS_CSV:\n",
    "        df = pd.read_csv(FEATS_CSV)\n",
    "        X = df.values\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No se encontraron features (npz/npy/parquet/csv).\")\n",
    "\n",
    "    # --- Carga ventanas ---\n",
    "    if WINS_JSON:\n",
    "        with open(WINS_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "            wins = json.load(f)\n",
    "    elif WINS_CSV:\n",
    "        wdf = pd.read_csv(WINS_CSV)\n",
    "        # Normalizaci√≥n esperada: columnas t0, t1\n",
    "        wins = wdf.to_dict(orient=\"records\")\n",
    "    else:\n",
    "        # Si no hay \"windows\" guardadas, creamos ventanas sint√©ticas 1s seguidas.\n",
    "        wins = [{\"t0\": float(i), \"t1\": float(i+1)} for i in range(len(X))]\n",
    "\n",
    "    # Aseguramos listas/np arrays\n",
    "    X = np.array(X)\n",
    "    if isinstance(wins, dict):\n",
    "        wins = [wins]\n",
    "    return X, wins\n",
    "\n",
    "X, windows = load_features_and_windows()\n",
    "print(f\"[OK] X shape = {X.shape} | windows = {len(windows)}\")\n",
    "\n",
    "# ---------- 3) Carga de artefactos de entrenamiento ----------\n",
    "# Esperamos estos ficheros (aj√∫stalos si tus nombres cambian):\n",
    "IMP_PATH   = f\"{ART}/imputer.joblib\"\n",
    "SCL_PATH   = f\"{ART}/scaler.joblib\"\n",
    "CLF_PATH   = f\"{ART}/model_ovr_logreg.joblib\"  # o el que tengas\n",
    "LBL_PATH   = f\"{ART}/labels.json\"              # lista de etiquetas\n",
    "THR_PATH   = f\"{ART}/thresholds.json\"          # map etiqueta->umbral (float)\n",
    "\n",
    "assert os.path.exists(IMP_PATH), f\"Falta: {IMP_PATH}\"\n",
    "assert os.path.exists(SCL_PATH), f\"Falta: {SCL_PATH}\"\n",
    "assert os.path.exists(CLF_PATH), f\"Falta: {CLF_PATH}\"\n",
    "\n",
    "imp    = joblib.load(IMP_PATH)\n",
    "scaler = joblib.load(SCL_PATH)\n",
    "clf    = joblib.load(CLF_PATH)\n",
    "\n",
    "labels_list = []\n",
    "if os.path.exists(LBL_PATH):\n",
    "    with open(LBL_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        labels_list = json.load(f)\n",
    "\n",
    "thr_map = {}\n",
    "if os.path.exists(THR_PATH):\n",
    "    with open(THR_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        thr_map = json.load(f)\n",
    "\n",
    "print(f\"[ARTEFACTOS] labels={len(labels_list)} | thresholds={len(thr_map)}\")\n",
    "\n",
    "# ---------- 4) Clasificaci√≥n y umbrales ----------\n",
    "# pred_prob -> aplica umbrales por etiqueta si existen; si no, usa 'thr_default'\n",
    "def predict_labels_batch(X_batch, thr_default=0.5):\n",
    "    # Pipeline simple y robusto con imputer + scaler + clf\n",
    "    X_imp = imp.transform(X_batch)\n",
    "    X_std = scaler.transform(X_imp)\n",
    "\n",
    "    # Probabilidades por clase (OneVsRestClassifier / LogisticRegressionCV)\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        P = clf.predict_proba(X_std)\n",
    "    else:\n",
    "        # Fallback a decision_function si no hay predict_proba\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            dec = clf.decision_function(X_std)\n",
    "            # Sigmoide para pseudo-probas\n",
    "            P = 1.0 / (1.0 + np.exp(-dec))\n",
    "        else:\n",
    "            raise RuntimeError(\"El clasificador no soporta predict_proba ni decision_function.\")\n",
    "\n",
    "    # P shape: (N, C)\n",
    "    N, C = P.shape\n",
    "    out_labels = []\n",
    "    out_scores = []\n",
    "    for i in range(N):\n",
    "        labels_i, scores_i = [], []\n",
    "        for c in range(C):\n",
    "            label_name = labels_list[c] if c < len(labels_list) else f\"class_{c}\"\n",
    "            thr = float(thr_map.get(label_name, thr_default)) if thr_map else thr_default\n",
    "            if P[i, c] >= thr:\n",
    "                labels_i.append(label_name)\n",
    "                scores_i.append(float(P[i, c]))\n",
    "        out_labels.append(labels_i)\n",
    "        out_scores.append(scores_i)\n",
    "    return out_labels, out_scores\n",
    "\n",
    "# ---------- 5) Motor de sugerencias ----------\n",
    "# Define aqu√≠ el mismo mapping que usas en el Colab/app\n",
    "SUGGESTIONS_MAP = {\n",
    "    # \"etiqueta\": \"texto de sugerencia\"\n",
    "    \"alineacion_brazos\": \"Ajusta la alineaci√≥n de codos y mu√±ecas en √°ngulos complementarios al torso para ganar limpieza.\",\n",
    "    \"centro_gravedad\": \"Rebaja el centro de gravedad al inicio del giro y estabiliza el core antes del impulso.\",\n",
    "    \"transferencia_peso\": \"Marca un micro-pli√© al transferir peso para amortiguar y mantener el eje.\",\n",
    "    \"mirada_foco\": \"Define un foco visual claro antes del desplazamiento para orientar direccionalidad.\",\n",
    "    \"sincronizacion_grupo\": \"Escucha el phrasing com√∫n y ancla entradas en los tiempos fuertes para cohesi√≥n.\",\n",
    "    \"extensiones_linea\": \"Extiende dedos y empeines para completar la l√≠nea hasta el extremo distal.\",\n",
    "    \"dinamica_contrastes\": \"Introduce contraste de din√°micas (sostenido vs. acento) para clarificar intenci√≥n.\",\n",
    "    \"respiracion_fraseo\": \"Apoya la musicalidad con respiraci√≥n en anacrusas y cierres para articular el fraseo.\",\n",
    "    \"espacial_path\": \"Optimiza el path espacial evitando zigzags no intencionales; usa diagonales limpias.\",\n",
    "    \"aterrizaje_silencioso\": \"Aterriza con metatarso-suelo progresivo para minimizar ruido y proteger articulaciones.\",\n",
    "}\n",
    "\n",
    "def suggestions_from_labels(labels):\n",
    "    sugs = []\n",
    "    for lb in labels:\n",
    "        if lb in SUGGESTIONS_MAP:\n",
    "            sugs.append(SUGGESTIONS_MAP[lb])\n",
    "    # Si no hubo match exacto, ofrece un comod√≠n si te interesa:\n",
    "    if not sugs and labels:\n",
    "        sugs.append(\"Refina el eje postural y verifica la alineaci√≥n cabeza-hombros-cadera en la transici√≥n.\")\n",
    "    return sugs\n",
    "\n",
    "# ---------- 6) Inferencia sobre el dataset y export ----------\n",
    "def run_full_inference_and_export(X, windows, thr_default=0.5, out_dir=BASE):\n",
    "    t0 = time.time()\n",
    "    out_rows = []\n",
    "    Y_labels, Y_scores = predict_labels_batch(X, thr_default=thr_default)\n",
    "\n",
    "    for i, (lbls, scs) in enumerate(zip(Y_labels, Y_scores)):\n",
    "        w = windows[i] if i < len(windows) else {}\n",
    "        t_start = float(w.get(\"t0\", i*1.0))\n",
    "        t_end   = float(w.get(\"t1\", (i+1)*1.0))\n",
    "        sug = suggestions_from_labels(lbls)\n",
    "\n",
    "        out_rows.append({\n",
    "            \"win_id\": i,\n",
    "            \"t_start\": t_start,\n",
    "            \"t_end\": t_end,\n",
    "            \"labels\": \",\".join(lbls),\n",
    "            \"scores\": \",\".join([f\"{s:.4f}\" for s in scs]),\n",
    "            \"suggestions\": \" | \".join(sug)\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(out_rows)\n",
    "    timeline_csv   = f\"{out_dir}/reports/timeline.csv\"\n",
    "    suggs_csv      = f\"{out_dir}/reports/suggestions.csv\"\n",
    "    df.to_csv(timeline_csv, index=False, encoding=\"utf-8\")\n",
    "    df[[\"win_id\",\"t_start\",\"t_end\",\"suggestions\"]].to_csv(suggs_csv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    # Exporta un \"bundle\" de control de versiones para la app:\n",
    "    versions = {\n",
    "        \"scikit_learn\": \"1.7.1\",\n",
    "        \"joblib\": \"1.4.2\",\n",
    "        \"numpy\": \"1.26.4\",\n",
    "        \"pandas\": \"2.2.2\",\n",
    "        \"created_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    }\n",
    "    with open(f\"{ART}/versions.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(versions, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # Garantiza labels.json y thresholds.json para la app\n",
    "    if labels_list:\n",
    "        with open(f\"{ART}/labels.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(labels_list, f, ensure_ascii=False, indent=2)\n",
    "    if thr_map:\n",
    "        with open(f\"{ART}/thresholds.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(thr_map, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(f\"[OK] Exportados:\\n  {timeline_csv}\\n  {suggs_csv}\\nTiempo: {dt:.2f}s | filas={len(df)}\")\n",
    "    return df\n",
    "\n",
    "df = run_full_inference_and_export(X, windows, thr_default=0.5, out_dir=BASE)\n",
    "display(df.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
